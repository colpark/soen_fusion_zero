{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TCN Disruption Prediction — Evaluation\n",
        "\n",
        "Loads the best checkpoint and performs a thorough evaluation on the **test** split:\n",
        "\n",
        "1. **Global metrics** — loss, accuracy, F1, precision, recall across thresholds\n",
        "2. **ROC & Precision-Recall curves**\n",
        "3. **Confusion matrix** at the optimal threshold\n",
        "4. **Per-shot analysis** — which shots are well-predicted vs. missed\n",
        "5. **Prediction time-series** — overlay predictions vs. targets for individual subsequences\n",
        "6. **Prediction distribution** — histogram of model outputs for positive vs. negative timesteps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.parametrizations import weight_norm\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "from dataset_ecei_tcn import ECEiTCNDataset, create_loaders\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n",
        "\n",
        "Must match the training config exactly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Data (SciServer paths) ────────────────────────────────────────────\n",
        "ROOT           = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/dsrpt'\n",
        "DECIMATED_ROOT = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/dsrpt_decimated'\n",
        "CLEAR_ROOT     = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/clear'\n",
        "CLEAR_DECIMATED_ROOT = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/clear_decimated'\n",
        "\n",
        "DATA_STEP       = 10\n",
        "TWARN           = 300_000\n",
        "BASELINE_LEN    = 40_000\n",
        "NSUB            = 781_250\n",
        "\n",
        "BATCH_SIZE      = 12\n",
        "NUM_WORKERS     = 4\n",
        "\n",
        "# ── Model ─────────────────────────────────────────────────────────────\n",
        "INPUT_CHANNELS  = 160\n",
        "N_CLASSES       = 1\n",
        "LEVELS          = 4\n",
        "NHID            = 80\n",
        "KERNEL_SIZE     = 15\n",
        "DILATION_BASE   = 10\n",
        "DROPOUT         = 0.1\n",
        "\n",
        "# Point to the correct checkpoint directory:\n",
        "#   'checkpoints_tcn'      — single-GPU training (train_tcn.ipynb)\n",
        "#   'checkpoints_tcn_ddp'  — multi-GPU DDP training (train_tcn_ddp.py)\n",
        "CHECKPOINT_DIR  = Path('checkpoints_tcn_ddp')\n",
        "CHECKPOINT_PATH = CHECKPOINT_DIR / 'best.pt'   # change to 'last.pt' if desired\n",
        "\n",
        "EVAL_SPLIT      = 'test'   # which split to evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. TCN Model definition\n",
        "\n",
        "Identical to `train_tcn.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super().__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(\n",
        "            n_inputs, n_outputs, kernel_size,\n",
        "            stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(\n",
        "            n_outputs, n_outputs, kernel_size,\n",
        "            stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "            self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, dilation_size=2,\n",
        "                 kernel_size=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        if np.isscalar(dilation_size):\n",
        "            dilation_size = [dilation_size ** i for i in range(num_levels)]\n",
        "        for i in range(num_levels):\n",
        "            in_ch = num_inputs if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers.append(TemporalBlock(\n",
        "                in_ch, out_ch, kernel_size, stride=1,\n",
        "                padding=(kernel_size - 1) * dilation_size[i],\n",
        "                dilation=dilation_size[i], dropout=dropout))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels,\n",
        "                 kernel_size, dropout, dilation_size):\n",
        "        super().__init__()\n",
        "        self.tcn = TemporalConvNet(\n",
        "            input_size, num_channels,\n",
        "            kernel_size=kernel_size, dropout=dropout,\n",
        "            dilation_size=dilation_size)\n",
        "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.tcn(x)\n",
        "        o = self.linear(y.permute(0, 2, 1))\n",
        "        return torch.sigmoid(o.squeeze(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def calc_receptive_field(kernel_size, dilation_sizes):\n",
        "    return 1 + 2 * (kernel_size - 1) * int(np.sum(dilation_sizes))\n",
        "\n",
        "\n",
        "def build_model(input_channels, n_classes, levels, nhid,\n",
        "                kernel_size, dilation_base, dropout, nrecept_target=30_000):\n",
        "    channel_sizes = [nhid] * levels\n",
        "    base_dilations = [dilation_base ** i for i in range(levels - 1)]\n",
        "    rf_without_last = calc_receptive_field(kernel_size, base_dilations)\n",
        "    last_dilation = int(np.ceil(\n",
        "        (nrecept_target - rf_without_last) / (2.0 * (kernel_size - 1))))\n",
        "    last_dilation = max(last_dilation, 1)\n",
        "    dilation_sizes = base_dilations + [last_dilation]\n",
        "    nrecept = calc_receptive_field(kernel_size, dilation_sizes)\n",
        "\n",
        "    model = TCN(input_channels, n_classes, channel_sizes,\n",
        "                kernel_size=kernel_size, dropout=dropout,\n",
        "                dilation_size=dilation_sizes)\n",
        "    n_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f'Dilation sizes : {dilation_sizes}')\n",
        "    print(f'Receptive field: {nrecept:,} samples')\n",
        "    print(f'Parameters     : {n_params:,}')\n",
        "    return model, nrecept\n",
        "\n",
        "\n",
        "model, NRECEPT = build_model(\n",
        "    INPUT_CHANNELS, N_CLASSES, LEVELS, NHID,\n",
        "    KERNEL_SIZE, DILATION_BASE, DROPOUT,\n",
        "    nrecept_target=30_000,\n",
        ")\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "STRIDE = (NSUB // DATA_STEP - NRECEPT + 1) * DATA_STEP\n",
        "print(f'Stride (raw)   : {STRIDE:,}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "assert CHECKPOINT_PATH.exists(), f'Checkpoint not found: {CHECKPOINT_PATH}'\n",
        "\n",
        "ckpt = torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=False)\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "model.eval()\n",
        "\n",
        "ckpt_epoch = ckpt.get('epoch', '?')\n",
        "ckpt_f1    = ckpt.get('best_f1', float('nan'))\n",
        "ckpt_th    = ckpt.get('threshold', 0.5)\n",
        "ckpt_nrecept = ckpt.get('nrecept', NRECEPT)\n",
        "\n",
        "print(f'Loaded checkpoint: {CHECKPOINT_PATH}')\n",
        "print(f'  epoch      = {ckpt_epoch}')\n",
        "print(f'  best F1    = {ckpt_f1:.4f}')\n",
        "print(f'  threshold  = {ckpt_th:.2f}')\n",
        "print(f'  nrecept    = {ckpt_nrecept:,}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load dataset & build evaluation loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import inspect\n",
        "_sig = inspect.signature(ECEiTCNDataset.__init__)\n",
        "_kw = dict(\n",
        "    root=ROOT,\n",
        "    decimated_root=DECIMATED_ROOT,\n",
        "    Twarn=TWARN,\n",
        "    baseline_length=BASELINE_LEN,\n",
        "    data_step=DATA_STEP,\n",
        "    nsub=NSUB,\n",
        "    stride=STRIDE,\n",
        "    normalize=True,\n",
        ")\n",
        "if 'clear_root' in _sig.parameters:\n",
        "    _kw['clear_root'] = CLEAR_ROOT\n",
        "    _kw['clear_decimated_root'] = CLEAR_DECIMATED_ROOT\n",
        "ds = ECEiTCNDataset(**_kw)\n",
        "ds.summary()\n",
        "\n",
        "eval_idx = ds.get_split_indices(EVAL_SPLIT)\n",
        "print(f'\\nEvaluating on split={EVAL_SPLIT!r}: {len(eval_idx)} subsequences')\n",
        "n_dis = int(ds.seq_has_disrupt[eval_idx].sum())\n",
        "print(f'  {n_dis} disruptive, {len(eval_idx) - n_dis} clear')\n",
        "\n",
        "eval_subset = Subset(ds, eval_idx)\n",
        "eval_loader = DataLoader(\n",
        "    eval_subset,\n",
        "    batch_size  = BATCH_SIZE,\n",
        "    shuffle     = False,\n",
        "    num_workers = NUM_WORKERS,\n",
        "    pin_memory  = True,\n",
        "    drop_last   = False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Collect all predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_preds   = []   # model sigmoid outputs  (per-timestep, valid region only)\n",
        "all_targets = []   # binary labels           (per-timestep, valid region only)\n",
        "all_preds_full   = []  # full subsequence predictions\n",
        "all_targets_full = []  # full subsequence targets\n",
        "\n",
        "# Per-subsequence metadata for later per-shot aggregation\n",
        "subseq_shot_ids  = []  # which shot each subseq belongs to\n",
        "subseq_starts    = []  # start index in data-file space\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, target, _weight in tqdm(eval_loader, desc='Inference'):\n",
        "        B = X.shape[0]\n",
        "        X_flat = X.view(B, -1, X.shape[-1]).to(DEVICE)\n",
        "        output = model(X_flat).cpu()\n",
        "\n",
        "        # valid region (after receptive field warm-up)\n",
        "        out_v = output[:, NRECEPT - 1:]\n",
        "        tgt_v = target[:, NRECEPT - 1:]\n",
        "\n",
        "        all_preds.append(out_v.numpy())\n",
        "        all_targets.append(tgt_v.numpy())\n",
        "        all_preds_full.append(output.numpy())\n",
        "        all_targets_full.append(target.numpy())\n",
        "\n",
        "# Flatten valid-region predictions into 1-D arrays\n",
        "all_preds   = np.concatenate([p.reshape(-1) for p in all_preds])\n",
        "all_targets = np.concatenate([t.reshape(-1) for t in all_targets])\n",
        "\n",
        "# Keep full-subsequence predictions as list of (B, T) arrays\n",
        "all_preds_full   = np.concatenate(all_preds_full,   axis=0)  # (N_subseqs, T_sub)\n",
        "all_targets_full = np.concatenate(all_targets_full, axis=0)  # (N_subseqs, T_sub)\n",
        "\n",
        "# Map each eval subsequence back to its shot\n",
        "for i, global_idx in enumerate(eval_idx):\n",
        "    subseq_shot_ids.append(ds.shots[ds.seq_shot_idx[global_idx]])\n",
        "    subseq_starts.append(ds.seq_start[global_idx])\n",
        "subseq_shot_ids = np.array(subseq_shot_ids)\n",
        "subseq_starts   = np.array(subseq_starts)\n",
        "\n",
        "n_pos = int((all_targets == 1).sum())\n",
        "n_neg = int((all_targets == 0).sum())\n",
        "print(f'\\nTotal timesteps (valid region): {len(all_targets):,}')\n",
        "print(f'  Positive (disruptive): {n_pos:,} ({n_pos/len(all_targets)*100:.1f}%)')\n",
        "print(f'  Negative (clear)     : {n_neg:,} ({n_neg/len(all_targets)*100:.1f}%)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5b. Subsequence-level prediction (majority voting)\n",
        "\n",
        "Utility to get **one prediction per subsequence** by aggregating per-timestep outputs (majority vote or mean-threshold). Works the same on SciServer and main branches — no path or branch logic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def subsequence_prediction_majority_vote(\n",
        "    preds_full,\n",
        "    threshold=0.5,\n",
        "    valid_start=None,\n",
        "    method='mean',\n",
        "):\n",
        "    \"\"\"\n",
        "    Get one prediction per subsequence by majority voting over timesteps.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    preds_full : np.ndarray\n",
        "        Shape (N_subseqs, T_sub), model sigmoid outputs per timestep.\n",
        "    threshold : float\n",
        "        Used to binarize (method='mean': mean >= threshold -> 1) or\n",
        "        per-timestep vote (method='majority': fraction of timesteps >= threshold).\n",
        "    valid_start : int or None\n",
        "        Index where valid region starts (e.g. NRECEPT - 1). If None, use full sequence.\n",
        "    method : str\n",
        "        'mean' — subseq label = 1 if mean(preds) >= threshold else 0.\n",
        "        'majority' — subseq label = mode of (preds >= threshold) over time (strict majority).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pred_subseq : np.ndarray\n",
        "        Shape (N_subseqs,) int 0/1, one prediction per subsequence.\n",
        "    \"\"\"\n",
        "    if valid_start is not None:\n",
        "        preds = preds_full[:, valid_start:]  # (N, T_valid)\n",
        "    else:\n",
        "        preds = preds_full\n",
        "\n",
        "    if method == 'mean':\n",
        "        mean_per_sub = preds.mean(axis=-1)\n",
        "        pred_subseq = (mean_per_sub >= threshold).astype(np.int64)\n",
        "    elif method == 'majority':\n",
        "        binary = (preds >= threshold).astype(np.int64)\n",
        "        pred_subseq = (binary.mean(axis=-1) > 0.5).astype(np.int64)\n",
        "    else:\n",
        "        raise ValueError(f\"method must be 'mean' or 'majority', got {method!r}\")\n",
        "    return pred_subseq\n",
        "\n",
        "\n",
        "# Apply to current eval predictions (valid region only)\n",
        "_threshold = best_th if 'best_th' in dir() else ckpt_th\n",
        "valid_start = NRECEPT - 1\n",
        "subseq_pred_majority = subsequence_prediction_majority_vote(\n",
        "    all_preds_full,\n",
        "    threshold=_threshold,\n",
        "    valid_start=valid_start,\n",
        "    method='mean',\n",
        ")\n",
        "\n",
        "# Ground truth at subsequence level: 1 if this subsequence contains disruption, else 0\n",
        "subseq_gt = ds.seq_has_disrupt[eval_idx].astype(np.int64)\n",
        "\n",
        "# Subsequence-level metrics\n",
        "tp = ((subseq_pred_majority == 1) & (subseq_gt == 1)).sum()\n",
        "tn = ((subseq_pred_majority == 0) & (subseq_gt == 0)).sum()\n",
        "fp = ((subseq_pred_majority == 1) & (subseq_gt == 0)).sum()\n",
        "fn = ((subseq_pred_majority == 0) & (subseq_gt == 1)).sum()\n",
        "acc_sub = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "prec_sub = tp / max(tp + fp, 1)\n",
        "rec_sub = tp / max(tp + fn, 1)\n",
        "f1_sub = 2 * prec_sub * rec_sub / max(prec_sub + rec_sub, 1e-10)\n",
        "\n",
        "print('Subsequence-level (majority vote, method=mean):')\n",
        "print(f'  Threshold = {_threshold:.3f}')\n",
        "print(f'  Accuracy  = {acc_sub:.4f}')\n",
        "print(f'  Precision = {prec_sub:.4f}  Recall = {rec_sub:.4f}  F1 = {f1_sub:.4f}')\n",
        "print(f'  TP={tp}, TN={tn}, FP={fp}, FN={fn}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5b. Subsequence-level prediction (majority voting)\n",
        "\n",
        "Utility to get **one prediction per subsequence** by aggregating per-timestep outputs (majority vote or mean-threshold). Works the same on SciServer and main branches — no path or branch logic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def subsequence_prediction_majority_vote(\n",
        "    preds_full,\n",
        "    threshold=0.5,\n",
        "    valid_start=None,\n",
        "    method='mean',\n",
        "):\n",
        "    \"\"\"\n",
        "    Get one prediction per subsequence by majority voting over timesteps.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    preds_full : np.ndarray\n",
        "        Shape (N_subseqs, T_sub), model sigmoid outputs per timestep.\n",
        "    threshold : float\n",
        "        Used to binarize (method='mean': mean >= threshold -> 1) or\n",
        "        per-timestep vote (method='majority': fraction of timesteps >= threshold).\n",
        "    valid_start : int or None\n",
        "        Index where valid region starts (e.g. NRECEPT - 1). If None, use full sequence.\n",
        "    method : str\n",
        "        'mean' — subseq label = 1 if mean(preds) >= threshold else 0.\n",
        "        'majority' — subseq label = mode of (preds >= threshold) over time (strict majority).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pred_subseq : np.ndarray\n",
        "        Shape (N_subseqs,) int 0/1, one prediction per subsequence.\n",
        "    \"\"\"\n",
        "    if valid_start is not None:\n",
        "        preds = preds_full[:, valid_start:]  # (N, T_valid)\n",
        "    else:\n",
        "        preds = preds_full\n",
        "\n",
        "    if method == 'mean':\n",
        "        mean_per_sub = preds.mean(axis=-1)\n",
        "        pred_subseq = (mean_per_sub >= threshold).astype(np.int64)\n",
        "    elif method == 'majority':\n",
        "        binary = (preds >= threshold).astype(np.int64)\n",
        "        # majority = 1 if more than half of timesteps are 1\n",
        "        pred_subseq = (binary.mean(axis=-1) > 0.5).astype(np.int64)\n",
        "    else:\n",
        "        raise ValueError(f\"method must be 'mean' or 'majority', got {method!r}\")\n",
        "    return pred_subseq\n",
        "\n",
        "\n",
        "# Apply to current eval predictions (valid region only)\n",
        "# Use ckpt_th here (from section 3); after section 6 you can use best_th and re-run for optimal F1\n",
        "valid_start = NRECEPT - 1\n",
        "_threshold = best_th if 'best_th' in dir() else ckpt_th\n",
        "subseq_pred_majority = subsequence_prediction_majority_vote(\n",
        "    all_preds_full,\n",
        "    threshold=_threshold,\n",
        "    valid_start=valid_start,\n",
        "    method='mean',\n",
        ")\n",
        "\n",
        "# Ground truth at subsequence level: 1 if this subsequence contains disruption, else 0\n",
        "subseq_gt = ds.seq_has_disrupt[eval_idx].astype(np.int64)\n",
        "\n",
        "# Subsequence-level metrics\n",
        "tp = ((subseq_pred_majority == 1) & (subseq_gt == 1)).sum()\n",
        "tn = ((subseq_pred_majority == 0) & (subseq_gt == 0)).sum()\n",
        "fp = ((subseq_pred_majority == 1) & (subseq_gt == 0)).sum()\n",
        "fn = ((subseq_pred_majority == 0) & (subseq_gt == 1)).sum()\n",
        "acc_sub = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "prec_sub = tp / max(tp + fp, 1)\n",
        "rec_sub = tp / max(tp + fn, 1)\n",
        "f1_sub = 2 * prec_sub * rec_sub / max(prec_sub + rec_sub, 1e-10)\n",
        "\n",
        "print('Subsequence-level (majority vote, method=mean):')\n",
        "print(f'  Threshold = {_threshold:.3f}')\n",
        "print(f'  Accuracy  = {acc_sub:.4f}')\n",
        "print(f'  Precision = {prec_sub:.4f}  Recall = {rec_sub:.4f}  F1 = {f1_sub:.4f}')\n",
        "print(f'  TP={tp}, TN={tn}, FP={fp}, FN={fn}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Global metrics across thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "thresholds = np.linspace(0.01, 0.99, 199)\n",
        "\n",
        "precision_arr = np.zeros(len(thresholds))\n",
        "recall_arr    = np.zeros(len(thresholds))\n",
        "f1_arr        = np.zeros(len(thresholds))\n",
        "accuracy_arr  = np.zeros(len(thresholds))\n",
        "fpr_arr       = np.zeros(len(thresholds))   # for ROC\n",
        "tpr_arr       = np.zeros(len(thresholds))   # for ROC\n",
        "\n",
        "for i, th in enumerate(thresholds):\n",
        "    pred = (all_preds >= th).astype(float)\n",
        "    TP = ((pred == 1) & (all_targets == 1)).sum()\n",
        "    TN = ((pred == 0) & (all_targets == 0)).sum()\n",
        "    FP = ((pred == 1) & (all_targets == 0)).sum()\n",
        "    FN = ((pred == 0) & (all_targets == 1)).sum()\n",
        "\n",
        "    precision_arr[i] = TP / max(TP + FP, 1)\n",
        "    recall_arr[i]    = TP / max(TP + FN, 1)\n",
        "    f1_arr[i]        = 2 * precision_arr[i] * recall_arr[i] / max(precision_arr[i] + recall_arr[i], 1e-10)\n",
        "    accuracy_arr[i]  = (TP + TN) / max(TP + TN + FP + FN, 1)\n",
        "    fpr_arr[i]       = FP / max(FP + TN, 1)\n",
        "    tpr_arr[i]       = TP / max(TP + FN, 1)\n",
        "\n",
        "best_idx = np.argmax(f1_arr)\n",
        "best_th  = thresholds[best_idx]\n",
        "\n",
        "print('=' * 70)\n",
        "print('  GLOBAL EVALUATION METRICS')\n",
        "print('=' * 70)\n",
        "print(f'  Checkpoint threshold : {ckpt_th:.2f}')\n",
        "print(f'  Best threshold (F1)  : {best_th:.3f}')\n",
        "print(f'  ────────────────────────────────────────')\n",
        "print(f'  F1        = {f1_arr[best_idx]:.4f}')\n",
        "print(f'  Precision = {precision_arr[best_idx]:.4f}')\n",
        "print(f'  Recall    = {recall_arr[best_idx]:.4f}')\n",
        "print(f'  Accuracy  = {accuracy_arr[best_idx]:.4f}')\n",
        "print(f'  ────────────────────────────────────────')\n",
        "# Also show metrics at the checkpoint's saved threshold\n",
        "ckpt_idx = np.argmin(np.abs(thresholds - ckpt_th))\n",
        "print(f'  Metrics at checkpoint th={ckpt_th:.2f}:')\n",
        "print(f'    F1={f1_arr[ckpt_idx]:.4f}  P={precision_arr[ckpt_idx]:.4f}  '\n",
        "      f'R={recall_arr[ckpt_idx]:.4f}  Acc={accuracy_arr[ckpt_idx]:.4f}')\n",
        "print(f'  ────────────────────────────────────────')\n",
        "# Accuracy at th=0.5\n",
        "idx_50 = np.argmin(np.abs(thresholds - 0.5))\n",
        "print(f'  Metrics at th=0.50:')\n",
        "print(f'    F1={f1_arr[idx_50]:.4f}  P={precision_arr[idx_50]:.4f}  '\n",
        "      f'R={recall_arr[idx_50]:.4f}  Acc={accuracy_arr[idx_50]:.4f}')\n",
        "print('=' * 70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ROC & Precision-Recall curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sort for proper curve plotting\n",
        "roc_order = np.argsort(fpr_arr)\n",
        "\n",
        "# Approximate AUC (ROC) using trapezoidal rule\n",
        "auc_roc = np.abs(np.trapz(tpr_arr[roc_order], fpr_arr[roc_order]))\n",
        "# Approximate AUC (PR)\n",
        "pr_order = np.argsort(recall_arr)\n",
        "auc_pr = np.abs(np.trapz(precision_arr[pr_order], recall_arr[pr_order]))\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# ── ROC Curve ──\n",
        "ax = axes[0]\n",
        "ax.plot(fpr_arr[roc_order], tpr_arr[roc_order], color='steelblue', linewidth=2,\n",
        "        label=f'ROC (AUC={auc_roc:.4f})')\n",
        "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
        "# mark best F1 threshold\n",
        "ax.plot(fpr_arr[best_idx], tpr_arr[best_idx], 'ro', markersize=8,\n",
        "        label=f'Best F1 th={best_th:.2f}')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curve')\n",
        "ax.legend(loc='lower right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim(-0.02, 1.02)\n",
        "ax.set_ylim(-0.02, 1.02)\n",
        "\n",
        "# ── Precision-Recall Curve ──\n",
        "ax = axes[1]\n",
        "ax.plot(recall_arr[pr_order], precision_arr[pr_order], color='firebrick',\n",
        "        linewidth=2, label=f'PR (AUC={auc_pr:.4f})')\n",
        "ax.plot(recall_arr[best_idx], precision_arr[best_idx], 'bo', markersize=8,\n",
        "        label=f'Best F1 th={best_th:.2f}')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.set_title('Precision-Recall Curve')\n",
        "ax.legend(loc='lower left')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim(-0.02, 1.02)\n",
        "ax.set_ylim(-0.02, 1.02)\n",
        "\n",
        "# ── F1 / Precision / Recall vs Threshold ──\n",
        "ax = axes[2]\n",
        "ax.plot(thresholds, f1_arr, color='black', linewidth=2, label='F1')\n",
        "ax.plot(thresholds, precision_arr, color='teal', linewidth=1.5, linestyle='--', label='Precision')\n",
        "ax.plot(thresholds, recall_arr, color='darkorange', linewidth=1.5, linestyle='--', label='Recall')\n",
        "ax.axvline(best_th, color='red', linestyle=':', alpha=0.6, label=f'Best th={best_th:.2f}')\n",
        "ax.set_xlabel('Threshold')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Metrics vs Threshold')\n",
        "ax.legend(loc='best', fontsize=9)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim(0, 1)\n",
        "ax.set_ylim(0, 1.02)\n",
        "\n",
        "plt.suptitle(f'Evaluation on {EVAL_SPLIT} split  |  Best F1={f1_arr[best_idx]:.4f}  |  AUC-ROC={auc_roc:.4f}',\n",
        "             fontsize=13, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pred_best = (all_preds >= best_th).astype(int)\n",
        "target_int = all_targets.astype(int)\n",
        "\n",
        "TP = int(((pred_best == 1) & (target_int == 1)).sum())\n",
        "TN = int(((pred_best == 0) & (target_int == 0)).sum())\n",
        "FP = int(((pred_best == 1) & (target_int == 0)).sum())\n",
        "FN = int(((pred_best == 0) & (target_int == 1)).sum())\n",
        "\n",
        "cm = np.array([[TN, FP], [FN, TP]])\n",
        "cm_pct = cm / cm.sum() * 100\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "im = ax.imshow(cm_pct, cmap='Blues', vmin=0)\n",
        "\n",
        "labels = ['Clear (0)', 'Disruptive (1)']\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_yticks([0, 1])\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticklabels(labels)\n",
        "ax.set_xlabel('Predicted', fontsize=12)\n",
        "ax.set_ylabel('True', fontsize=12)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        color = 'white' if cm_pct[i, j] > 40 else 'black'\n",
        "        ax.text(j, i, f'{cm[i, j]:,}\\n({cm_pct[i, j]:.1f}%)',\n",
        "                ha='center', va='center', fontsize=13, color=color,\n",
        "                fontweight='bold')\n",
        "\n",
        "ax.set_title(f'Confusion Matrix @ threshold={best_th:.3f}\\n'\n",
        "             f'Acc={accuracy_arr[best_idx]:.4f}  F1={f1_arr[best_idx]:.4f}',\n",
        "             fontsize=12)\n",
        "fig.colorbar(im, ax=ax, label='% of total timesteps')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'TP={TP:>10,}   FP={FP:>10,}')\n",
        "print(f'FN={FN:>10,}   TN={TN:>10,}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Prediction distribution (positive vs negative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# ── Histogram ──\n",
        "ax = axes[0]\n",
        "bins = np.linspace(0, 1, 101)\n",
        "ax.hist(all_preds[all_targets == 0], bins=bins, alpha=0.6, density=True,\n",
        "        label='Clear (y=0)', color='steelblue')\n",
        "ax.hist(all_preds[all_targets == 1], bins=bins, alpha=0.6, density=True,\n",
        "        label='Disruptive (y=1)', color='firebrick')\n",
        "ax.axvline(best_th, color='black', linestyle='--', linewidth=1.5,\n",
        "           label=f'Best th={best_th:.2f}')\n",
        "ax.set_xlabel('Model output (sigmoid)', fontsize=11)\n",
        "ax.set_ylabel('Density', fontsize=11)\n",
        "ax.set_title('Prediction Distribution by True Label')\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.2)\n",
        "\n",
        "# ── Box plot of mean prediction per subsequence ──\n",
        "ax = axes[1]\n",
        "subseq_mean_pred = all_preds_full[:, NRECEPT - 1:].mean(axis=-1)\n",
        "subseq_labels    = (all_targets_full[:, NRECEPT - 1:].sum(axis=-1) > 0).astype(int)\n",
        "\n",
        "data_box = [subseq_mean_pred[subseq_labels == 0],\n",
        "            subseq_mean_pred[subseq_labels == 1]]\n",
        "bp = ax.boxplot(data_box, labels=['Clear', 'Disruptive'], widths=0.5,\n",
        "                patch_artist=True)\n",
        "bp['boxes'][0].set_facecolor('steelblue')\n",
        "bp['boxes'][0].set_alpha(0.4)\n",
        "bp['boxes'][1].set_facecolor('firebrick')\n",
        "bp['boxes'][1].set_alpha(0.4)\n",
        "ax.set_ylabel('Mean prediction (valid region)', fontsize=11)\n",
        "ax.set_title('Per-Subsequence Mean Prediction')\n",
        "ax.grid(True, alpha=0.2)\n",
        "\n",
        "plt.suptitle(f'Prediction distributions — {EVAL_SPLIT} split', fontsize=13, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Per-shot analysis\n",
        "\n",
        "For each shot in the eval split, compute:\n",
        "- Average F1 across its subsequences\n",
        "- Whether the disruption was *detected* (any positive prediction in the warning window)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "unique_shots = np.unique(subseq_shot_ids)\n",
        "\n",
        "shot_results = []\n",
        "\n",
        "for shot in unique_shots:\n",
        "    mask = subseq_shot_ids == shot\n",
        "    idx_local = np.where(mask)[0]\n",
        "\n",
        "    preds_shot  = all_preds_full[idx_local][:, NRECEPT - 1:]   # (n_sub, T_valid)\n",
        "    targets_shot = all_targets_full[idx_local][:, NRECEPT - 1:]\n",
        "\n",
        "    pred_bin = (preds_shot >= best_th).astype(float)\n",
        "\n",
        "    tp = ((pred_bin == 1) & (targets_shot == 1)).sum()\n",
        "    fp = ((pred_bin == 1) & (targets_shot == 0)).sum()\n",
        "    fn = ((pred_bin == 0) & (targets_shot == 1)).sum()\n",
        "    tn = ((pred_bin == 0) & (targets_shot == 0)).sum()\n",
        "\n",
        "    prec = tp / max(tp + fp, 1)\n",
        "    rec  = tp / max(tp + fn, 1)\n",
        "    f1   = 2 * prec * rec / max(prec + rec, 1e-10)\n",
        "    acc  = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "\n",
        "    has_disrupt = (targets_shot.sum() > 0)\n",
        "    detected    = has_disrupt and (pred_bin[targets_shot == 1].sum() > 0)\n",
        "\n",
        "    # Mean prediction in the disruption region vs clear region\n",
        "    if has_disrupt and targets_shot.sum() > 0:\n",
        "        mean_pred_pos = preds_shot[targets_shot == 1].mean()\n",
        "    else:\n",
        "        mean_pred_pos = float('nan')\n",
        "    mean_pred_neg = preds_shot[targets_shot == 0].mean() if (targets_shot == 0).sum() > 0 else float('nan')\n",
        "\n",
        "    shot_results.append({\n",
        "        'shot': shot,\n",
        "        'n_subseqs': int(mask.sum()),\n",
        "        'has_disrupt': has_disrupt,\n",
        "        'detected': detected,\n",
        "        'f1': f1,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'accuracy': acc,\n",
        "        'mean_pred_pos': mean_pred_pos,\n",
        "        'mean_pred_neg': mean_pred_neg,\n",
        "    })\n",
        "\n",
        "# ── Print table ──\n",
        "print(f\"{'Shot':>8s}  {'#Sub':>5s}  {'Disrupt':>7s}  {'Detect':>6s}  \"\n",
        "      f\"{'F1':>6s}  {'Prec':>6s}  {'Rec':>6s}  {'Acc':>6s}  \"\n",
        "      f\"{'Pred(+)':>8s}  {'Pred(-)':>8s}\")\n",
        "print('─' * 88)\n",
        "for r in shot_results:\n",
        "    det_str = '  YES' if r['detected'] else '   NO' if r['has_disrupt'] else '  n/a'\n",
        "    dis_str = '  YES' if r['has_disrupt'] else '   NO'\n",
        "    print(f\"{r['shot']:>8d}  {r['n_subseqs']:>5d}  {dis_str}  {det_str}  \"\n",
        "          f\"{r['f1']:>6.3f}  {r['precision']:>6.3f}  {r['recall']:>6.3f}  {r['accuracy']:>6.3f}  \"\n",
        "          f\"{r['mean_pred_pos']:>8.4f}  {r['mean_pred_neg']:>8.4f}\")\n",
        "\n",
        "# Overall shot-level detection rate\n",
        "n_disruptive_shots = sum(1 for r in shot_results if r['has_disrupt'])\n",
        "n_detected = sum(1 for r in shot_results if r['detected'])\n",
        "print(f'\\nDisruption detection rate: {n_detected}/{n_disruptive_shots} '\n",
        "      f'({n_detected/max(n_disruptive_shots,1)*100:.0f}%)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Bar chart of per-shot F1 ──\n",
        "shot_labels = [str(r['shot']) for r in shot_results]\n",
        "shot_f1s    = [r['f1'] for r in shot_results]\n",
        "shot_colors = ['firebrick' if r['has_disrupt'] else 'steelblue' for r in shot_results]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(max(8, len(shot_results) * 0.6), 5))\n",
        "bars = ax.bar(range(len(shot_results)), shot_f1s, color=shot_colors, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
        "ax.set_xticks(range(len(shot_results)))\n",
        "ax.set_xticklabels(shot_labels, rotation=45, ha='right', fontsize=9)\n",
        "ax.set_ylabel('F1 Score')\n",
        "ax.set_title(f'Per-Shot F1 — {EVAL_SPLIT} split  (red = disruptive, blue = clear)')\n",
        "ax.set_ylim(0, 1.05)\n",
        "ax.axhline(f1_arr[best_idx], color='black', linestyle='--', alpha=0.5, label=f'Global F1={f1_arr[best_idx]:.3f}')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.2, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Prediction time-series visualisation\n",
        "\n",
        "Plot the model's per-timestep output overlaid with the true target for several subsequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "T_sub = all_preds_full.shape[-1]\n",
        "t_ax_ms = np.arange(T_sub) / (1e6 / DATA_STEP / 1000)  # ms\n",
        "\n",
        "# Pick a mix of disruptive and clear subsequences\n",
        "dis_idxs   = np.where(subseq_labels == 1)[0]\n",
        "clear_idxs = np.where(subseq_labels == 0)[0]\n",
        "\n",
        "n_show_each = 4\n",
        "show_dis   = dis_idxs[:n_show_each]   if len(dis_idxs)   >= n_show_each else dis_idxs\n",
        "show_clear = clear_idxs[:n_show_each] if len(clear_idxs) >= n_show_each else clear_idxs\n",
        "show_all   = np.concatenate([show_dis, show_clear])\n",
        "\n",
        "n_plots = len(show_all)\n",
        "fig, axes = plt.subplots(n_plots, 1, figsize=(16, 2.8 * n_plots), sharex=True)\n",
        "if n_plots == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    idx = show_all[i]\n",
        "    pred_ts = all_preds_full[idx]\n",
        "    tgt_ts  = all_targets_full[idx]\n",
        "    shot_id = subseq_shot_ids[idx]\n",
        "    label_str = 'disruptive' if subseq_labels[idx] else 'clear'\n",
        "\n",
        "    ax.plot(t_ax_ms, pred_ts, color='steelblue', linewidth=1, label='Prediction')\n",
        "    ax.plot(t_ax_ms, tgt_ts, color='firebrick', linewidth=1, linestyle='--', label='Target')\n",
        "    ax.axhline(best_th, color='gray', linestyle=':', alpha=0.5, label=f'Threshold={best_th:.2f}')\n",
        "    ax.axvspan(0, t_ax_ms[NRECEPT - 1], alpha=0.06, color='gray')\n",
        "    ax.set_ylabel(f'Shot {shot_id}\\n({label_str})', fontsize=9)\n",
        "    ax.set_ylim(-0.05, 1.05)\n",
        "    ax.grid(True, alpha=0.2)\n",
        "    if i == 0:\n",
        "        ax.legend(loc='upper left', fontsize=9)\n",
        "        ax.set_title('Per-timestep predictions vs targets (gray = receptive field warm-up)',\n",
        "                     fontsize=12)\n",
        "\n",
        "axes[-1].set_xlabel('Time (ms) within subsequence', fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Early-warning analysis\n",
        "\n",
        "For disruptive subsequences: how early before the actual disruption does the model\n",
        "cross the threshold?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# For each disruptive subsequence, find the first timestep where\n",
        "# the prediction exceeds the threshold within the valid region\n",
        "warning_times_ms = []   # how early the alarm fires (ms before end of disruptive window)\n",
        "missed = 0\n",
        "\n",
        "for idx in dis_idxs:\n",
        "    pred_ts = all_preds_full[idx]\n",
        "    tgt_ts  = all_targets_full[idx]\n",
        "\n",
        "    # Only look at valid region\n",
        "    pred_valid = pred_ts[NRECEPT - 1:]\n",
        "    tgt_valid  = tgt_ts[NRECEPT - 1:]\n",
        "\n",
        "    # Find where disruption label starts in valid region\n",
        "    dis_start = np.where(tgt_valid == 1)[0]\n",
        "    if len(dis_start) == 0:\n",
        "        continue\n",
        "    dis_start_idx = dis_start[0]\n",
        "\n",
        "    # Find first threshold crossing\n",
        "    alarm_indices = np.where(pred_valid >= best_th)[0]\n",
        "    if len(alarm_indices) == 0:\n",
        "        missed += 1\n",
        "        continue\n",
        "\n",
        "    first_alarm = alarm_indices[0]\n",
        "    # Time advantage: how much earlier than disruption onset\n",
        "    dt_samples = dis_start_idx - first_alarm\n",
        "    dt_ms = dt_samples / (1e6 / DATA_STEP) * 1000\n",
        "    warning_times_ms.append(dt_ms)\n",
        "\n",
        "warning_times_ms = np.array(warning_times_ms)\n",
        "\n",
        "print(f'Disruptive subsequences: {len(dis_idxs)}')\n",
        "print(f'  Detected (alarm fired)  : {len(warning_times_ms)}')\n",
        "print(f'  Missed (no alarm)       : {missed}')\n",
        "\n",
        "if len(warning_times_ms) > 0:\n",
        "    early = warning_times_ms[warning_times_ms > 0]\n",
        "    late  = warning_times_ms[warning_times_ms <= 0]\n",
        "\n",
        "    print(f'\\n  Early warnings (alarm BEFORE disruption onset): {len(early)}')\n",
        "    if len(early) > 0:\n",
        "        print(f'    Mean lead time : {early.mean():.1f} ms')\n",
        "        print(f'    Median         : {np.median(early):.1f} ms')\n",
        "        print(f'    Min            : {early.min():.1f} ms')\n",
        "        print(f'    Max            : {early.max():.1f} ms')\n",
        "\n",
        "    print(f'  Late warnings (alarm AFTER disruption onset)  : {len(late)}')\n",
        "    if len(late) > 0:\n",
        "        print(f'    Mean delay     : {-late.mean():.1f} ms')\n",
        "\n",
        "    # Histogram\n",
        "    fig, ax = plt.subplots(figsize=(10, 4))\n",
        "    ax.hist(warning_times_ms, bins=30, color='teal', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
        "    ax.axvline(0, color='red', linestyle='--', linewidth=1.5, label='Disruption onset')\n",
        "    ax.set_xlabel('Warning time (ms, positive = early)', fontsize=11)\n",
        "    ax.set_ylabel('Count', fontsize=11)\n",
        "    ax.set_title('Distribution of early-warning lead times')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.2)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('  No detections — skipping warning-time plot.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('\\n' + '=' * 70)\n",
        "print('  EVALUATION SUMMARY')\n",
        "print('=' * 70)\n",
        "print(f'  Checkpoint     : {CHECKPOINT_PATH}')\n",
        "print(f'  Epoch          : {ckpt_epoch}')\n",
        "print(f'  Eval split     : {EVAL_SPLIT}')\n",
        "print(f'  Subsequences   : {len(eval_idx)}')\n",
        "print(f'  Timesteps      : {len(all_targets):,} (valid region)')\n",
        "print(f'  ─────────────────────────────────────')\n",
        "print(f'  Best threshold : {best_th:.3f}')\n",
        "print(f'  F1             : {f1_arr[best_idx]:.4f}')\n",
        "print(f'  Precision      : {precision_arr[best_idx]:.4f}')\n",
        "print(f'  Recall         : {recall_arr[best_idx]:.4f}')\n",
        "print(f'  Accuracy       : {accuracy_arr[best_idx]:.4f}')\n",
        "print(f'  AUC-ROC        : {auc_roc:.4f}')\n",
        "print(f'  AUC-PR         : {auc_pr:.4f}')\n",
        "print(f'  ─────────────────────────────────────')\n",
        "if len(warning_times_ms) > 0:\n",
        "    print(f'  Disruption detection rate : {n_detected}/{n_disruptive_shots}')\n",
        "    if len(early) > 0:\n",
        "        print(f'  Mean early-warning lead  : {early.mean():.1f} ms')\n",
        "print('=' * 70)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}