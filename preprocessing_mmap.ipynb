{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocess subsequences to mmap_ninja (original DisruptCNN setting)\n",
        "\n",
        "Pre-save **normalized** subsequences from decimated H5 using the same segment/tiling/label logic as `EceiDatasetOriginal` (shot lists, Twarn=300 ms). All normalization and preprocessing is done at save time so training/validation can load directly from memory-mapped files.\n",
        "\n",
        "**Two variants (set `FLATTOP_ONLY` in config):**\n",
        "- **`FLATTOP_ONLY = True`** (default): segment from t_flat_start to tend (flattop only). Output: `subseqs_original_mmap/`\n",
        "- **`FLATTOP_ONLY = False`**: full segment from 0 to tend. Output: `subseqs_original_mmap_full/`\n",
        "\n",
        "**Output dir contents:**\n",
        "- `X/`, `target/`, `weight/` — RaggedMmap (mmap_ninja)\n",
        "- `labels.npy` — seq_has_disrupt per index\n",
        "- `train_inds.npy`, `test_inds.npy`, `val_inds.npy` — split indices\n",
        "- `meta.json` — nsub, nrecept, data_step, pos_weight, neg_weight, flattop_only\n",
        "\n",
        "**Requires:** `pip install mmap_ninja`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Project root (soen_fusion_zero)\n",
        "ROOT = Path.cwd()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from disruptcnn.dataset_original import EceiDatasetOriginal\n",
        "\n",
        "try:\n",
        "    from mmap_ninja import RaggedMmap\n",
        "    HAS_MMAP_NINJA = True\n",
        "except ImportError:\n",
        "    HAS_MMAP_NINJA = False\n",
        "    print(\"Install mmap_ninja: pip install mmap_ninja\")\n",
        "\n",
        "# ── Config (edit for your environment) ─────────────────────────────\n",
        "ROOT_DATA = Path(\"/home/idies/workspace/Storage/yhuang2/persistent/ecei\")\n",
        "DECIMATED_ROOT = ROOT_DATA / \"dsrpt_decimated\"\n",
        "DISRUPT_FILE = \"disruptcnn/shots/d3d_disrupt_ecei.final.txt\"\n",
        "CLEAR_FILE = \"disruptcnn/shots/d3d_clear_ecei.final.txt\"  # or None for disrupt-only\n",
        "NORM_STATS = ROOT / \"norm_stats.npz\"\n",
        "\n",
        "# flattop_only=True  → segment from t_flat_start to tend (flattop only); saves to subseqs_original_mmap\n",
        "# flattop_only=False → full segment from 0 to tend; saves to subseqs_original_mmap_full\n",
        "FLATTOP_ONLY = True  # set False for full-segment version\n",
        "OUTPUT_DIR = ROOT / (\"subseqs_original_mmap\" if FLATTOP_ONLY else \"subseqs_original_mmap_full\")\n",
        "\n",
        "NSUB_RAW = 781_250\n",
        "NRECEPT_RAW = 30_000\n",
        "DATA_STEP = 10\n",
        "RANDOM_SEED = 42\n",
        "MMAP_BATCH_SIZE = 512\n",
        "\n",
        "print(f\"Decimated root: {DECIMATED_ROOT}\")\n",
        "print(f\"Flattop only: {FLATTOP_ONLY}  →  output: {OUTPUT_DIR.name}\")\n",
        "print(f\"Output dir: {OUTPUT_DIR}\")\n",
        "print(f\"mmap_ninja: {HAS_MMAP_NINJA}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build dataset and split indices\n",
        "\n",
        "Use `EceiDatasetOriginal` to get the exact same subsequence indices (shot_idxi, start_idxi, stop_idxi, disrupt_idxi) and train/test split. We only need the indices and normalization stats; we will read H5 and write mmap ourselves so all preprocessing is baked in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inner = EceiDatasetOriginal(\n",
        "    root=str(ROOT_DATA),\n",
        "    clear_file=CLEAR_FILE if Path(ROOT / CLEAR_FILE).exists() else None,\n",
        "    disrupt_file=DISRUPT_FILE,\n",
        "    train=True,\n",
        "    flattop_only=FLATTOP_ONLY,\n",
        "    Twarn=300,\n",
        "    test=0,\n",
        "    normalize=True,\n",
        "    data_step=DATA_STEP,\n",
        "    nsub=NSUB_RAW,\n",
        "    nrecept=NRECEPT_RAW,\n",
        "    decimated_root=str(DECIMATED_ROOT),\n",
        "    norm_stats_path=str(NORM_STATS),\n",
        ")\n",
        "inner.train_val_test_split(sizes=(0.8, 0.1, 0.1), random_seed=RANDOM_SEED)\n",
        "\n",
        "n_seq = len(inner.shot_idxi)\n",
        "train_inds = inner.train_inds\n",
        "test_inds = inner.test_inds\n",
        "val_inds = inner.val_inds\n",
        "print(f\"Total subsequences: {n_seq}\")\n",
        "print(f\"Train: {len(train_inds)}, val: {len(val_inds)}, test: {len(test_inds)}\")\n",
        "print(f\"nsub (decimated): {inner.nsub}, step in getitem: {inner._step_in_getitem}\")\n",
        "print(f\"pos_weight: {inner.pos_weight:.4f}, neg_weight: {inner.neg_weight:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save normalized subsequences to mmap_ninja\n",
        "\n",
        "For each sequence index we: read the slice from decimated H5, apply offset (if any) and normalization, compute target and weight as in `EceiDatasetOriginal.__getitem__`, then append to RaggedMmap. All preprocessing is done here so training loads pre-normalized data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if not HAS_MMAP_NINJA:\n",
        "    raise RuntimeError(\"mmap_ninja required; pip install mmap_ninja\")\n",
        "\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "X_batch, target_batch, weight_batch = [], [], []\n",
        "mmap_initialized = False\n",
        "x_mmap = t_mmap = w_mmap = None\n",
        "\n",
        "def flush_mmap():\n",
        "    global mmap_initialized, x_mmap, t_mmap, w_mmap\n",
        "    if not X_batch:\n",
        "        return\n",
        "    if not mmap_initialized:\n",
        "        RaggedMmap.from_lists(str(OUTPUT_DIR / \"X\"), X_batch)\n",
        "        RaggedMmap.from_lists(str(OUTPUT_DIR / \"target\"), target_batch)\n",
        "        RaggedMmap.from_lists(str(OUTPUT_DIR / \"weight\"), weight_batch)\n",
        "        mmap_initialized = True\n",
        "    else:\n",
        "        x_mmap = x_mmap or RaggedMmap(str(OUTPUT_DIR / \"X\"))\n",
        "        t_mmap = t_mmap or RaggedMmap(str(OUTPUT_DIR / \"target\"))\n",
        "        w_mmap = w_mmap or RaggedMmap(str(OUTPUT_DIR / \"weight\"))\n",
        "        x_mmap.extend(X_batch)\n",
        "        t_mmap.extend(target_batch)\n",
        "        w_mmap.extend(weight_batch)\n",
        "    X_batch.clear()\n",
        "    target_batch.clear()\n",
        "    weight_batch.clear()\n",
        "\n",
        "labels_all = []\n",
        "\n",
        "for idx in tqdm(range(n_seq), desc=\"Writing subsequences\"):\n",
        "    # Same logic as EceiDatasetOriginal._read_data and __getitem__\n",
        "    shot_index = inner.shot_idxi[idx]\n",
        "    filename = inner._filename(shot_index)\n",
        "    start_i = inner.start_idxi[idx]\n",
        "    stop_i = inner.stop_idxi[idx]\n",
        "    with h5py.File(filename, \"r\") as f:\n",
        "        if np.all(inner.offsets[..., shot_index] == 0) and \"offsets\" in f:\n",
        "            inner.offsets[..., shot_index] = f[\"offsets\"][...]\n",
        "        X = (\n",
        "            f[\"LFS\"][..., start_i:stop_i][..., :: inner._step_in_getitem]\n",
        "            - inner.offsets[..., shot_index][..., np.newaxis]\n",
        "        ).astype(np.float32)\n",
        "    if inner.normalize:\n",
        "        X = (X - inner.normalize_mean[..., np.newaxis]) / inner.normalize_std[..., np.newaxis]\n",
        "    T = X.shape[-1]\n",
        "    target = np.zeros((T,), dtype=np.float32)\n",
        "    weight = np.full((T,), inner.neg_weight, dtype=np.float32)\n",
        "    if inner.disruptedi[idx]:\n",
        "        first_disrupt = int(\n",
        "            (inner.disrupt_idxi[idx] - start_i + 1) / inner._step_in_getitem\n",
        "        )\n",
        "        target[first_disrupt:] = 1.0\n",
        "        weight[first_disrupt:] = inner.pos_weight\n",
        "    labels_all.append(1 if inner.disruptedi[idx] else 0)\n",
        "    X_batch.append(np.ascontiguousarray(X))\n",
        "    target_batch.append(target)\n",
        "    weight_batch.append(weight.astype(np.float32))\n",
        "    if len(X_batch) >= MMAP_BATCH_SIZE:\n",
        "        flush_mmap()\n",
        "\n",
        "flush_mmap()\n",
        "np.save(OUTPUT_DIR / \"labels.npy\", np.array(labels_all, dtype=np.int64))\n",
        "np.save(OUTPUT_DIR / \"train_inds.npy\", train_inds)\n",
        "np.save(OUTPUT_DIR / \"test_inds.npy\", test_inds)\n",
        "np.save(OUTPUT_DIR / \"val_inds.npy\", val_inds)\n",
        "\n",
        "meta = {\n",
        "    \"nsub\": int(inner.nsub),\n",
        "    \"nrecept\": int(inner.nrecept),\n",
        "    \"data_step\": int(DATA_STEP),\n",
        "    \"pos_weight\": float(inner.pos_weight),\n",
        "    \"neg_weight\": float(inner.neg_weight),\n",
        "    \"flattop_only\": FLATTOP_ONLY,\n",
        "    \"n_sequences\": n_seq,\n",
        "    \"n_train\": len(train_inds),\n",
        "    \"n_val\": len(val_inds),\n",
        "    \"n_test\": len(test_inds),\n",
        "}\n",
        "with open(OUTPUT_DIR / \"meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(f\"Saved to {OUTPUT_DIR}\")\n",
        "print(json.dumps(meta, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify: load back and compare one sample\n",
        "\n",
        "Load the mmap and compare one subsequence with the same index from `EceiDatasetOriginal` to ensure preprocessing matches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from mmap_ninja import RaggedMmap\n",
        "import torch\n",
        "\n",
        "x_m = RaggedMmap(str(OUTPUT_DIR / \"X\"))\n",
        "t_m = RaggedMmap(str(OUTPUT_DIR / \"target\"))\n",
        "w_m = RaggedMmap(str(OUTPUT_DIR / \"weight\"))\n",
        "labels = np.load(OUTPUT_DIR / \"labels.npy\")\n",
        "\n",
        "assert len(x_m) == n_seq\n",
        "idx = 0\n",
        "X_saved = np.ascontiguousarray(x_m[idx])\n",
        "target_saved = t_m[idx]\n",
        "weight_saved = w_m[idx]\n",
        "X_live, target_live, _, weight_live = inner[idx]\n",
        "X_live = X_live.numpy()\n",
        "target_live = target_live.numpy()\n",
        "weight_live = weight_live.numpy()\n",
        "\n",
        "print(f\"Shape saved: {X_saved.shape}, live: {X_live.shape}\")\n",
        "print(f\"X match: {np.allclose(X_saved, X_live)}\")\n",
        "print(f\"target match: {np.allclose(target_saved, target_live)}\")\n",
        "print(f\"weight match: {np.allclose(weight_saved, weight_live)}\")\n",
        "print(\"Verification OK.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train using prebuilt mmap\n",
        "\n",
        "Run training without loading decimated H5 on the fly; use the pre-saved subsequences instead.\n",
        "\n",
        "**Flattop-only** (default output):\n",
        "```bash\n",
        "torchrun --nproc_per_node=4 train_tcn_ddp_original.py --prebuilt-mmap-dir subseqs_original_mmap --flattop-only ...\n",
        "# or\n",
        "bash run_tcn_baseline_160_original_prenorm.sh --prebuilt-mmap-dir subseqs_original_mmap\n",
        "```\n",
        "\n",
        "**Full segment** (when you ran with `FLATTOP_ONLY = False`):\n",
        "```bash\n",
        "torchrun --nproc_per_node=4 train_tcn_ddp_original.py --prebuilt-mmap-dir subseqs_original_mmap_full ...\n",
        "# or\n",
        "bash run_tcn_baseline_160_original_prenorm.sh --prebuilt-mmap-dir subseqs_original_mmap_full\n",
        "```\n",
        "(Do **not** pass `--flattop-only` when using the full-segment mmap.)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}