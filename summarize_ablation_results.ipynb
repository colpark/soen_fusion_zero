{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarize ablation results (small models)\n",
        "\n",
        "Loads `history.json` from each run of `run_ablation_small_models.sh` (dirs `checkpoints_tcn_ddp_original/ablation_L*_H*/`) and builds a summary table and plots.\n",
        "\n",
        "**Requires:** Ablation runs completed; checkpoint dirs named `ablation_L{levels}_H{nhid}`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Project root and checkpoint base\n",
        "ROOT = Path.cwd()\n",
        "CKPT_BASE = ROOT / \"checkpoints_tcn_ddp_original\"\n",
        "\n",
        "# Pattern for ablation dirs: ablation_L4_H80, ablation_L3_H40, etc.\n",
        "ABLATION_PATTERN = re.compile(r\"^ablation_L(\\d+)_H(\\d+)$\")\n",
        "\n",
        "def find_ablation_dirs():\n",
        "    \"\"\"Return list of (dir_path, levels, nhid) for each ablation run.\"\"\"\n",
        "    if not CKPT_BASE.exists():\n",
        "        return []\n",
        "    out = []\n",
        "    for d in CKPT_BASE.iterdir():\n",
        "        if not d.is_dir():\n",
        "            continue\n",
        "        m = ABLATION_PATTERN.match(d.name)\n",
        "        if m and (d / \"history.json\").exists():\n",
        "            out.append((d, int(m.group(1)), int(m.group(2))))\n",
        "    return sorted(out, key=lambda x: (x[1], x[2]))\n",
        "\n",
        "dirs = find_ablation_dirs()\n",
        "print(f\"Found {len(dirs)} ablation run(s) under {CKPT_BASE}\")\n",
        "for d, L, H in dirs:\n",
        "    print(f\"  {d.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Param count (same formula as ablation_model_sizes.py)\n",
        "def count_params(levels: int, nhid: int, input_channels: int = 160, kernel_size: int = 15) -> int:\n",
        "    k, in_ch = kernel_size, input_channels\n",
        "    n0 = 2 * in_ch + (in_ch * nhid * k + nhid) + 2 * nhid + (nhid * nhid * k + nhid)\n",
        "    if in_ch != nhid:\n",
        "        n0 += in_ch * nhid * 1 + nhid\n",
        "    n_block = 2 * nhid + (nhid * nhid * k + nhid) + 2 * nhid + (nhid * nhid * k + nhid)\n",
        "    n_lin = nhid * 1 + 1\n",
        "    return n0 + (levels - 1) * n_block + n_lin\n",
        "\n",
        "def load_summary(ckpt_dir: Path, levels: int, nhid: int) -> dict:\n",
        "    with open(ckpt_dir / \"history.json\") as f:\n",
        "        hist = json.load(f)\n",
        "    n_epochs = len(hist.get(\"val_f1\", []))\n",
        "    if n_epochs == 0:\n",
        "        return None\n",
        "    val_f1 = hist[\"val_f1\"]\n",
        "    best_idx = int(np.argmax(val_f1))\n",
        "    return {\n",
        "        \"levels\": levels,\n",
        "        \"nhid\": nhid,\n",
        "        \"n_params\": count_params(levels, nhid),\n",
        "        \"best_val_f1\": float(val_f1[best_idx]),\n",
        "        \"best_epoch\": best_idx + 1,\n",
        "        \"n_epochs\": n_epochs,\n",
        "        \"final_train_loss\": float(hist[\"train_loss\"][-1]),\n",
        "        \"final_val_loss\": float(hist[\"val_loss\"][-1]),\n",
        "        \"final_val_f1\": float(val_f1[-1]),\n",
        "        \"final_val_acc\": float(hist[\"val_acc\"][-1]),\n",
        "        \"dir\": str(ckpt_dir.name),\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "for ckpt_dir, L, H in dirs:\n",
        "    row = load_summary(ckpt_dir, L, H)\n",
        "    if row:\n",
        "        rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "if df.empty:\n",
        "    print(\"No history found. Run run_ablation_small_models.sh first.\")\n",
        "else:\n",
        "    df = df.sort_values(\"n_params\", ascending=False).reset_index(drop=True)\n",
        "    display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary table (by param count)\n",
        "\n",
        "Key columns: `n_params`, `best_val_f1`, `best_epoch`, `final_*`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not df.empty:\n",
        "    print(\"Best val F1 per config:\")\n",
        "    print(df[[\"levels\", \"nhid\", \"n_params\", \"best_val_f1\", \"best_epoch\"]].to_string(index=False))\n",
        "    print()\n",
        "    best_overall = df.loc[df[\"best_val_f1\"].idxmax()]\n",
        "    print(f\"Best overall val F1: {best_overall['best_val_f1']:.4f} (L={best_overall['levels']}, H={best_overall['nhid']}, {best_overall['n_params']:,} params)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df.empty:\n",
        "    pass\n",
        "else:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Val F1 vs n_params (log scale)\n",
        "    ax = axes[0]\n",
        "    ax.scatter(df[\"n_params\"], df[\"best_val_f1\"], s=80, alpha=0.8)\n",
        "    for _, r in df.iterrows():\n",
        "        ax.annotate(f\"L{r['levels']}H{r['nhid']}\", (r[\"n_params\"], r[\"best_val_f1\"]),\n",
        "                    textcoords=\"offset points\", xytext=(0, 6), ha=\"center\", fontsize=8)\n",
        "    ax.set_xscale(\"log\")\n",
        "    ax.set_xlabel(\"Number of parameters\")\n",
        "    ax.set_ylabel(\"Best val F1\")\n",
        "    ax.set_title(\"Best validation F1 vs model size\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Bar: best_val_f1 per config\n",
        "    ax = axes[1]\n",
        "    x_labels = [f\"L{int(r['levels'])}H{int(r['nhid'])}\" for _, r in df.iterrows()]\n",
        "    ax.bar(range(len(df)), df[\"best_val_f1\"], color=\"steelblue\", alpha=0.8)\n",
        "    ax.set_xticks(range(len(df)))\n",
        "    ax.set_xticklabels(x_labels, rotation=45, ha=\"right\")\n",
        "    ax.set_ylabel(\"Best val F1\")\n",
        "    ax.set_title(\"Best validation F1 by config\")\n",
        "    ax.grid(True, axis=\"y\", alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning curves: val_f1 vs epoch for each config (optional)\n",
        "if not df.empty and len(dirs) <= 12:\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    for ckpt_dir, L, H in dirs:\n",
        "        with open(ckpt_dir / \"history.json\") as f:\n",
        "            hist = json.load(f)\n",
        "        epochs = range(1, len(hist[\"val_f1\"]) + 1)\n",
        "        ax.plot(epochs, hist[\"val_f1\"], label=f\"L{L} H{H}\", alpha=0.8)\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Val F1\")\n",
        "    ax.set_title(\"Validation F1 over training\")\n",
        "    ax.legend(loc=\"lower right\", fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
