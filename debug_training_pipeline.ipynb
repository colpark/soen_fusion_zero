{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretable Debug: TCN Training Pipeline\n",
        "\n",
        "This notebook walks through the **rolled-back** training pipeline with rich visualizations:\n",
        "\n",
        "1. **Input** — Data layout, how subsequences are formed, time parameters  \n",
        "2. **Normalization & labels** — Preprocessing, label definition, **label segments** for disruptive data  \n",
        "3. **Model** — TCN structure, **per-layer receptive field**  \n",
        "4. **Prediction** — How output is produced and cropped  \n",
        "5. **Weighting** — How loss weights are applied (and why we use only `batch_weights`)\n",
        "\n",
        "Set `USE_REAL_DATA = True` and the data paths in the next cell to use real dataset; otherwise synthetic data is used."
      ],
      "id": "17a4f5d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: paths and constants (match train_tcn_ddp.py)\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "\n",
        "USE_REAL_DATA = False  # Set True and set paths below to use real dataset\n",
        "ROOT = \"/path/to/dsrpt\"\n",
        "DECIMATED_ROOT = \"/path/to/dsrpt_decimated\"\n",
        "CLEAR_ROOT = \"/path/to/clear_decimated\"\n",
        "CLEAR_DECIMATED_ROOT = \"/path/to/clear_decimated\"\n",
        "NORM_STATS = None  # e.g. \"norm_stats_pca1.npz\"\n",
        "PCA_COMPONENTS = 0  # 0, 1, 4, 8, 16\n",
        "\n",
        "# Training params\n",
        "DATA_STEP = 10\n",
        "NSUB_RAW = 781_250\n",
        "TWARN = 300_000\n",
        "BASELINE_LEN = 40_000\n",
        "EXCLUDE_LAST_MS = 0.0\n",
        "INPUT_CHANNELS = 160\n",
        "LEVELS = 4\n",
        "NHID = 80\n",
        "KERNEL_SIZE = 15\n",
        "DILATION_BASE = 10\n",
        "DROPOUT = 0.2\n",
        "NRECEPT_TARGET = 30_000\n",
        "T_sub = NSUB_RAW // DATA_STEP\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10, 4)\n",
        "plt.rcParams['font.size'] = 11"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2bc9e507"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Input — Data layout and how subsequences are formed\n",
        "\n",
        "- **Raw data:** `root/` has `meta.csv` (shot, split, t_disruption) and `{shot}.h5` with key `LFS` → shape `(20, 8, T)` at 1 MHz (or `(C, T)` for PCA).\n",
        "- **Clear shots:** optional `clear_root/`; whole shot = label 0.\n",
        "- **Decimated:** when `decimated_root` is used, LFS is already offset-removed and decimated (100 kHz); no decimation in `__getitem__`.\n",
        "- **Tiling:** each shot is split into windows of length `nsub`; windows advance by `stride`. For each window we store `disrupt_local` (start of Twarn in window, or -1 if clear) and `positive_end_local` (end of label-1 region)."
      ],
      "id": "0315a58d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Time parameters (all in raw 1 MHz samples unless noted)\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 2.5))\n",
        "ax.set_xlim(0, 10)\n",
        "ax.set_ylim(0, 4)\n",
        "ax.axis('off')\n",
        "\n",
        "params = [\n",
        "    ('Twarn', TWARN, f'{TWARN/1e6*1000:.1f} ms before disruption'),\n",
        "    ('baseline_length', BASELINE_LEN, 'DC offset window'),\n",
        "    ('data_step', DATA_STEP, 'decimation → 100 kHz'),\n",
        "    ('nsub', NSUB_RAW, f'~{NSUB_RAW/1e6*1000:.1f} ms window'),\n",
        "    ('T_sub', T_sub, 'nsub // data_step (output length)'),\n",
        "]\n",
        "y = 3.5\n",
        "for name, val, desc in params:\n",
        "    ax.text(0.2, y, f'{name}', fontfamily='monospace', fontsize=12, fontweight='bold')\n",
        "    ax.text(2.2, y, f'= {val:,}', fontfamily='monospace')\n",
        "    ax.text(5, y, desc, color='gray')\n",
        "    y -= 0.65\n",
        "ax.set_title('Time parameters', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"T_sub = {T_sub:,}  (samples per subsequence)\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "fcdf20d6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Schematic: one shot tiled into overlapping windows (conceptual)\n",
        "from train_tcn_ddp import build_model\n",
        "_, nrecept, _ = build_model(INPUT_CHANNELS, 1, LEVELS, NHID, KERNEL_SIZE, DILATION_BASE, DROPOUT, nrecept_target=NRECEPT_TARGET)\n",
        "stride_raw = (NSUB_RAW // DATA_STEP - nrecept + 1) * DATA_STEP\n",
        "stride_data = stride_raw // DATA_STEP  # in decimated space\n",
        "nsub_data = NSUB_RAW // DATA_STEP\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 2))\n",
        "L = 5 * nsub_data  # show 5 windows\n",
        "ax.set_xlim(0, L)\n",
        "ax.set_ylim(-0.3, 1.5)\n",
        "ax.set_xlabel('Time (decimated samples)')\n",
        "ax.set_yticks([])\n",
        "for i in range(5):\n",
        "    start = i * stride_data\n",
        "    end = start + nsub_data\n",
        "    ax.add_patch(Rectangle((start, 0.2), nsub_data, 0.6, facecolor='steelblue', alpha=0.7, edgecolor='navy', linewidth=1.5))\n",
        "    ax.text(start + nsub_data/2, 0.5, f'win {i}', ha='center', va='center', color='white', fontweight='bold')\n",
        "ax.axhline(0.5, color='k', linewidth=0.5, linestyle='--')\n",
        "ax.set_title(f'Subsequence tiling: window length = {nsub_data:,}, stride = {stride_data:,} (raw stride {stride_raw:,})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6e72744e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Normalization and label definition\n",
        "\n",
        "**Preprocessing in `__getitem__`:**\n",
        "1. **DC offset:** `baseline = mean(X[..., :baseline_length])`; `X = X - baseline`\n",
        "2. **Decimation:** `X = X[..., ::data_step]` (1 MHz → 100 kHz)\n",
        "3. **Z-score:** `X = (X - norm_mean) / norm_std` (per-channel, from training split)\n",
        "\n",
        "**Labels (output space):**  \n",
        "- `d = (disrupt_local + 1) // step`, `e = (positive_end_local + step - 1) // step`  \n",
        "- `target[d:e] = 1` (Twarn window), elsewhere 0  \n",
        "- `weight[0:d] = neg_weight`, `weight[d:e] = pos_weight`, `weight[e:T] = 0` (excluded)"
      ],
      "id": "1e795773"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Normalization: synthetic signal before and after z-score (one channel)\n",
        "np.random.seed(42)\n",
        "t = np.linspace(0, 1, 500)\n",
        "sig = 0.5 * np.sin(2 * np.pi * 5 * t) + 0.3 * np.random.randn(500) + 2.0  # offset ~2\n",
        "sig_z = (sig - sig.mean()) / (sig.std() + 1e-8)\n",
        "fig, axes = plt.subplots(2, 1, figsize=(10, 4), sharex=True)\n",
        "axes[0].plot(sig, color='steelblue')\n",
        "axes[0].set_ylabel('Raw (with offset)')\n",
        "axes[0].set_title('Before: DC offset + z-score')\n",
        "axes[1].plot(sig_z, color='green')\n",
        "axes[1].set_ylabel('Normalized')\n",
        "axes[1].set_xlabel('Sample')\n",
        "axes[1].set_title('After: (x - mean) / std')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "3f11303a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Label segments for a disruptive subsequence (rich visualization)\n",
        "T_ex = 78_125\n",
        "d_ex, e_ex = 35_000, 38_000  # example: clear [0, d), Twarn [d, e), excluded [e, T]\n",
        "t_target = np.zeros(T_ex)\n",
        "t_target[d_ex:e_ex] = 1.0\n",
        "t_weight = np.zeros(T_ex)\n",
        "t_weight[:d_ex] = 0.56\n",
        "t_weight[d_ex:e_ex] = 4.5\n",
        "# Plot a window around the transition for clarity\n",
        "win = slice(33_000, 42_000)\n",
        "r = np.arange(T_ex)[win]\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 5), sharex=True)\n",
        "ax0, ax1 = axes\n",
        "ax0.fill_between(r, 0, t_target[win], color='green', alpha=0.3, label='label 0 (clear)')\n",
        "ax0.fill_between(r, 0, t_target[win], where=(t_target[win] > 0.5), color='red', alpha=0.5, label='label 1 (Twarn)')\n",
        "ax0.axvspan(d_ex, e_ex, alpha=0.25, color='red')\n",
        "ax0.set_ylabel('Target')\n",
        "ax0.set_ylim(-0.05, 1.2)\n",
        "ax0.legend(loc='upper right')\n",
        "ax0.set_title('Label segments (zoom around transition)')\n",
        "ax0.axvline(d_ex, color='red', linestyle='--', linewidth=1.5, alpha=0.9)\n",
        "ax0.axvline(e_ex, color='red', linestyle='--', linewidth=1.5, alpha=0.9)\n",
        "ax1.fill_between(r, 0, t_weight[win], color='steelblue', alpha=0.5)\n",
        "ax1.axvspan(d_ex, e_ex, alpha=0.2, color='red')\n",
        "ax1.set_xlabel('Output step index')\n",
        "ax1.set_ylabel('Weight')\n",
        "ax1.set_title('Per-timestep BCE weight')\n",
        "ax1.axvline(d_ex, color='red', linestyle='--', linewidth=1.5, alpha=0.9)\n",
        "ax1.axvline(e_ex, color='red', linestyle='--', linewidth=1.5, alpha=0.9)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"  [0, {d_ex})   → label 0 (clear),  count = {d_ex}\")\n",
        "print(f\"  [{d_ex}, {e_ex}) → label 1 (Twarn), count = {e_ex - d_ex}\")\n",
        "print(f\"  [{e_ex}, {T_ex}) → excluded,       count = {T_ex - e_ex}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "962825b5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: load real dataset and show one disruptive sample's target & weight\n",
        "if USE_REAL_DATA and Path(ROOT).exists():\n",
        "    from dataset_ecei_tcn import ECEiTCNDataset\n",
        "    from train_tcn_ddp import build_model\n",
        "    _, nrecept_ds, _ = build_model(INPUT_CHANNELS if PCA_COMPONENTS == 0 else PCA_COMPONENTS, 1, LEVELS, NHID,\n",
        "                                  KERNEL_SIZE, DILATION_BASE, DROPOUT, nrecept_target=NRECEPT_TARGET)\n",
        "    _stride_raw = (NSUB_RAW // DATA_STEP - nrecept_ds + 1) * DATA_STEP\n",
        "    ds = ECEiTCNDataset(root=ROOT, decimated_root=DECIMATED_ROOT or None, clear_root=CLEAR_ROOT or None,\n",
        "                        clear_decimated_root=CLEAR_DECIMATED_ROOT or None, Twarn=TWARN, baseline_length=BASELINE_LEN,\n",
        "                        data_step=DATA_STEP, nsub=NSUB_RAW, stride=_stride_raw, normalize=True,\n",
        "                        norm_stats_path=NORM_STATS, exclude_last_ms=EXCLUDE_LAST_MS, ignore_twarn=False,\n",
        "                        n_input_channels=PCA_COMPONENTS if PCA_COMPONENTS > 0 else None)\n",
        "    idx = np.where(ds.seq_has_disrupt)[0][0]\n",
        "    X, target, weight = ds[idx]\n",
        "    target = target.numpy()\n",
        "    weight = weight.numpy()\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(14, 3))\n",
        "    ax.plot(target, label='target', color='green', alpha=0.8)\n",
        "    ax.plot(weight, label='weight', color='steelblue', alpha=0.7)\n",
        "    ax.set_xlabel('Output step')\n",
        "    ax.legend()\n",
        "    ax.set_title(f'Real sample index {idx} (disruptive): target and weight')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Using synthetic example above. Set USE_REAL_DATA=True and paths to plot a real sample.')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "389b5124"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Model and per-layer receptive field\n",
        "\n",
        "- **TCN:** stack of `TemporalBlock`s (dilated causal convs) → linear → sigmoid → `(B, T_sub)`.\n",
        "- **Causal:** output at time `t` only sees input `[0..t]`. The first `(nrecept - 1)` outputs do not have full context, so training uses only `output[nrecept-1:]` (and target/weight cropped the same way).\n",
        "- **Receptive field:** `RF = 1 + 2 * (kernel_size - 1) * sum(dilations)`. Each block adds `2*(k-1)*dilation_i`."
      ],
      "id": "95190c66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from train_tcn_ddp import build_model, calc_receptive_field\n",
        "\n",
        "model, nrecept, dilation_sizes = build_model(\n",
        "    INPUT_CHANNELS, 1, LEVELS, NHID, KERNEL_SIZE, DILATION_BASE, DROPOUT, nrecept_target=NRECEPT_TARGET,\n",
        ")\n",
        "cum_rf = []\n",
        "cum = 0\n",
        "for i, d in enumerate(dilation_sizes):\n",
        "    add = 2 * (KERNEL_SIZE - 1) * d\n",
        "    cum += add\n",
        "    cum_rf.append(1 + cum)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
        "x = np.arange(len(dilation_sizes))\n",
        "bars = ax.bar(x, cum_rf, color='steelblue', edgecolor='navy', linewidth=1.2)\n",
        "ax.axhline(nrecept, color='red', linestyle='--', label=f'Total RF = {nrecept:,}')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([f'Level {i}\\ndilation={d}' for i, d in enumerate(dilation_sizes)])\n",
        "ax.set_ylabel('Cumulative receptive field (samples)')\n",
        "ax.set_title('Per-level receptive field (causal)')\n",
        "ax.legend()\n",
        "for i, (v, d) in enumerate(zip(cum_rf, dilation_sizes)):\n",
        "    ax.text(i, v + 500, f'{v:,}', ha='center', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f'Target RF: {NRECEPT_TARGET:,}  →  Achieved: {nrecept:,}')\n",
        "print(f'Usable length for loss: T_sub - (nrecept - 1) = {T_sub - (nrecept - 1):,}')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "834b1205"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. How the prediction is made\n",
        "\n",
        "- Forward: `(B, C, T_sub)` → TCN → linear → sigmoid → `(B, T_sub)`.\n",
        "- Crop: `out_v = output[:, nrecept-1:]`, `tgt_v = target[:, nrecept-1:]`.\n",
        "- Prediction: `pred = (out_v >= 0.5).float()`."
      ],
      "id": "6331eb09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dummy forward (small T to avoid OOM)\n",
        "T_forward = min(T_sub, 4000)\n",
        "X_dummy = torch.randn(2, INPUT_CHANNELS, T_forward) * 0.1\n",
        "with torch.no_grad():\n",
        "    out = model(X_dummy)\n",
        "out_crop = out[:, nrecept - 1:]\n",
        "print(f'Input: {X_dummy.shape}  →  Output: {out.shape}  →  Crop: {out_crop.shape}')\n",
        "print('Prediction: pred = (out_crop >= 0.5).float()')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "facb2668"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Loss weighting (current rolled-back version)\n",
        "\n",
        "- The dataset returns `(X, target, weight)`; the third tensor has per-timestep pos/neg weights. **In the current code this is not used in the loss** (loader yields `_weight`, ignored).\n",
        "- Training uses **only** `batch_weights(tgt_v)` for BCE weights:\n",
        "  - `n_pos = tgt_v.sum()`, `n_neg = n_total - n_pos`\n",
        "  - Positive steps: weight = `0.5 * n_total / n_pos`\n",
        "  - Negative steps: weight = `0.5 * n_total / n_neg`  \n",
        "  So total weight on positives = total on negatives = 0.5×n_total (50/50 balance per batch).\n",
        "- **Do not** multiply dataset weight by `batch_weights` — double weighting causes collapse to predicting 1 everywhere."
      ],
      "id": "0aa1a263"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from train_tcn_ddp import batch_weights\n",
        "\n",
        "# Example: 10 timesteps, 2 positive\n",
        "tgt = torch.tensor([0., 0, 0, 0, 0, 1., 1, 0, 0, 0.], dtype=torch.float32)\n",
        "w = batch_weights(tgt)\n",
        "n_total, n_pos = tgt.numel(), int(tgt.sum().item())\n",
        "n_neg = n_total - n_pos\n",
        "pw = 0.5 * n_total / max(n_pos, 1)\n",
        "nw = 0.5 * n_total / max(n_neg, 1)\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 5), sharex=True)\n",
        "ax0, ax1 = axes\n",
        "x = np.arange(len(tgt))\n",
        "colors = ['green' if t == 0 else 'red' for t in tgt]\n",
        "ax0.bar(x, tgt.numpy(), color=colors, edgecolor='black')\n",
        "ax0.set_ylabel('Target')\n",
        "ax0.set_title('Target (0 = clear, 1 = disruptive)')\n",
        "ax0.set_ylim(-0.05, 1.2)\n",
        "\n",
        "ax1.bar(x, w.numpy(), color=colors, edgecolor='black')\n",
        "ax1.axhline(pw, color='red', linestyle='--', alpha=0.8, label=f'pos weight = {pw:.3f}')\n",
        "ax1.axhline(nw, color='green', linestyle='--', alpha=0.8, label=f'neg weight = {nw:.3f}')\n",
        "ax1.set_xlabel('Timestep')\n",
        "ax1.set_ylabel('BCE weight')\n",
        "ax1.set_title('batch_weights(tgt): 50/50 total weight on pos vs neg')\n",
        "ax1.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f'n_pos={n_pos}, n_neg={n_neg}  →  pos weight={pw:.3f}, neg weight={nw:.3f}')\n",
        "print(f'Sum on pos: {w[tgt==1].sum().item():.3f},  Sum on neg: {w[tgt==0].sum().item():.3f}')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ecf3dbdb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Training step (conceptual)\n",
        "\n",
        "1. Get batch `(X, target, _weight)`; **\\_weight is ignored**.\n",
        "2. `out = model(X)` → `(B, T_sub)`.\n",
        "3. `out_v = out[:, nrecept-1:]`, `tgt_v = target[:, nrecept-1:]`.\n",
        "4. `wgt_v = batch_weights(tgt_v)`.\n",
        "5. `loss = BCE(out_v, tgt_v, weight=wgt_v)`.\n",
        "6. `loss.backward()`, `clip_grad_norm_`, `optimizer.step()`."
      ],
      "id": "4751875b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}