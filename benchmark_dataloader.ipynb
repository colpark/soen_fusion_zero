{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DataLoader Benchmark\n",
        "\n",
        "Measure wall-clock time for one full epoch of data loading (no model forward pass).\n",
        "Uses the pre-decimated h5 files for fast I/O."
      ],
      "id": "title"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from dataset_ecei_tcn import ECEiTCNDataset, create_loaders\n",
        "\n",
        "ROOT           = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/dsrpt'\n",
        "DECIMATED_ROOT = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/dsrpt_decimated'\n",
        "CLEAR_ROOT     = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/clear'\n",
        "CLEAR_DECIMATED_ROOT = '/home/idies/workspace/Storage/yhuang2/persistent/ecei/clear_decimated'"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "setup"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ds = ECEiTCNDataset(\n",
        "    root                 = ROOT,\n",
        "    decimated_root       = DECIMATED_ROOT,\n",
        "    clear_root           = CLEAR_ROOT,\n",
        "    clear_decimated_root = CLEAR_DECIMATED_ROOT,\n",
        "    Twarn                = 300_000,\n",
        "    baseline_length      = 40_000,\n",
        "    data_step            = 10,\n",
        "    nsub                 = 781_250,    # ~781 ms (matches disruptcnn)\n",
        "    stride               = 481_090,    # (nsub/step - nrecept + 1) * step\n",
        "    normalize            = True,\n",
        ")\n",
        "ds.summary()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "build-dataset"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "BATCH_SIZE  = 8\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "loaders = create_loaders(ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "\n",
        "for name, loader in loaders.items():\n",
        "    print(f'{name:>5s}: {len(loader.dataset):5d} subseqs, '\n",
        "          f'{len(loader):4d} batches (bs={BATCH_SIZE})')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "create-loaders"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def benchmark_epoch(loader, name=''):\n",
        "    \"\"\"Iterate one full epoch, return timing stats.\"\"\"\n",
        "    n_batches = 0\n",
        "    n_samples = 0\n",
        "    total_pos = 0\n",
        "    total_neg = 0\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    for X, target, weight in loader:\n",
        "        n_batches += 1\n",
        "        n_samples += X.shape[0]\n",
        "        total_pos += (target == 1).sum().item()\n",
        "        total_neg += (target == 0).sum().item()\n",
        "    elapsed = time.perf_counter() - t0\n",
        "\n",
        "    print(f'[{name}]  {n_batches} batches, {n_samples} samples')\n",
        "    print(f'  Elapsed : {elapsed:.2f} s')\n",
        "    print(f'  Per batch : {elapsed/n_batches*1e3:.1f} ms')\n",
        "    print(f'  Per sample: {elapsed/n_samples*1e3:.1f} ms')\n",
        "    print(f'  Throughput: {n_samples/elapsed:.1f} samples/s')\n",
        "    frac = total_pos / (total_pos + total_neg) if (total_pos + total_neg) > 0 else 0\n",
        "    print(f'  Label 1 fraction: {frac:.3f}')\n",
        "    return elapsed"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "benchmark"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = {}\n",
        "for name, loader in loaders.items():\n",
        "    results[name] = benchmark_epoch(loader, name=name)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "run-benchmark"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "names = list(results.keys())\n",
        "times = [results[n] for n in names]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 3))\n",
        "bars = ax.barh(names, times, color='steelblue')\n",
        "for bar, t in zip(bars, times):\n",
        "    ax.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height() / 2,\n",
        "            f'{t:.2f} s', va='center', fontweight='bold')\n",
        "ax.set_xlabel('Epoch time (seconds)')\n",
        "ax.set_title(f'Data-loading epoch time (bs={BATCH_SIZE}, workers={NUM_WORKERS})')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "summary-bar"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity: print one batch's shapes and dtypes\n",
        "split_name = 'train' if 'train' in loaders else list(loaders.keys())[0]\n",
        "X, target, weight = next(iter(loaders[split_name]))\n",
        "print(f'X      : {X.shape}  {X.dtype}')\n",
        "print(f'target : {target.shape}  {target.dtype}  unique={target.unique().tolist()}')\n",
        "print(f'weight : {weight.shape}  {weight.dtype}  unique={weight.unique().tolist()}')"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "shape-check"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}