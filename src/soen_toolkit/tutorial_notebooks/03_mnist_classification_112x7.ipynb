{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST Classification (112 timesteps × 7 features)\n",
    "\n",
    "**Hardware-compatible SOEN model** for MNIST digit classification.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "| Layer | Dimension | Inputs per Neuron |\n",
    "|-------|-----------|-------------------|\n",
    "| Input | 7 | - |\n",
    "| Hidden | 28 | **7** (< 8 max) |\n",
    "| Output | 10 | 28 |\n",
    "\n",
    "## Data Format\n",
    "\n",
    "```\n",
    "Original: 28 × 28 = 784 pixels\n",
    "Reshaped: 112 timesteps × 7 features = 784 pixels\n",
    "\n",
    "Each timestep: 7 pixels scanned sequentially through the image\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TQDM_DISABLE\"] = \"0\"\n",
    "os.environ[\"TQDM_MININTERVAL\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import glob\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare MNIST Dataset (112 × 7 Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        url = base_url + filename\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num_images, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def reshape_to_112x7(images):\n",
    "    \"\"\"\n",
    "    Reshape MNIST from (N, 28, 28) to (N, 112, 7).\n",
    "    \n",
    "    - 112 timesteps\n",
    "    - 7 features per timestep\n",
    "    - Scans image row by row, 7 pixels at a time\n",
    "    \n",
    "    28 × 28 = 784 pixels\n",
    "    112 × 7 = 784 pixels\n",
    "    \"\"\"\n",
    "    n_samples = images.shape[0]\n",
    "    # Flatten to 784, then reshape to (112, 7)\n",
    "    flat = images.reshape(n_samples, -1)  # (N, 784)\n",
    "    reshaped = flat.reshape(n_samples, 112, 7)  # (N, 112, 7)\n",
    "    return reshaped\n",
    "\n",
    "def prepare_mnist_hdf5_112x7(output_path=\"training/datasets/mnist_seq112x7.hdf5\", \n",
    "                              normalize=True, val_split=0.1):\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if output_path.exists():\n",
    "        print(f\"Dataset already exists at {output_path}\")\n",
    "        with h5py.File(output_path, 'r') as f:\n",
    "            print(f\"  Train: {f['train']['data'].shape}\")\n",
    "            print(f\"  Val: {f['val']['data'].shape}\")\n",
    "            print(f\"  Test: {f['test']['data'].shape}\")\n",
    "        return output_path\n",
    "    \n",
    "    print(\"Downloading MNIST...\")\n",
    "    train_images = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32)\n",
    "    train_labels = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_images = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32)\n",
    "    test_labels = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    if normalize:\n",
    "        train_images = train_images / 255.0\n",
    "        test_images = test_images / 255.0\n",
    "    \n",
    "    print(\"\\nReshaping to 112 timesteps × 7 features...\")\n",
    "    print(\"  Hardware compatible: each neuron receives 7 inputs (< 8 max)\")\n",
    "    train_images = reshape_to_112x7(train_images)\n",
    "    test_images = reshape_to_112x7(test_images)\n",
    "    \n",
    "    # Split train/val\n",
    "    n_train = len(train_images)\n",
    "    n_val = int(n_train * val_split)\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(n_train)\n",
    "    \n",
    "    val_images = train_images[indices[:n_val]]\n",
    "    val_labels = train_labels[indices[:n_val]]\n",
    "    train_images = train_images[indices[n_val:]]\n",
    "    train_labels = train_labels[indices[n_val:]]\n",
    "    \n",
    "    print(f\"\\nFinal shapes:\")\n",
    "    print(f\"  Train: {train_images.shape} (N, T=112, D=7)\")\n",
    "    print(f\"  Val: {val_images.shape}\")\n",
    "    print(f\"  Test: {test_images.shape}\")\n",
    "    \n",
    "    print(f\"\\nSaving to {output_path}...\")\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        f.create_group('train')\n",
    "        f['train'].create_dataset('data', data=train_images)\n",
    "        f['train'].create_dataset('labels', data=train_labels)\n",
    "        \n",
    "        f.create_group('val')\n",
    "        f['val'].create_dataset('data', data=val_images)\n",
    "        f['val'].create_dataset('labels', data=val_labels)\n",
    "        \n",
    "        f.create_group('test')\n",
    "        f['test'].create_dataset('data', data=test_images)\n",
    "        f['test'].create_dataset('labels', data=test_labels)\n",
    "        \n",
    "        f.attrs['seq_len'] = 112\n",
    "        f.attrs['feature_dim'] = 7\n",
    "        f.attrs['num_classes'] = 10\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return output_path\n",
    "\n",
    "data_path = prepare_mnist_hdf5_112x7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the 112×7 Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_112x7_format(data_path, n_samples=5):\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        images_112x7 = np.array(f['train']['data'][:n_samples])\n",
    "        labels = np.array(f['train']['labels'][:n_samples])\n",
    "    \n",
    "    # Reconstruct 28×28\n",
    "    images_28x28 = images_112x7.reshape(n_samples, 784).reshape(n_samples, 28, 28)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_samples, figsize=(3*n_samples, 8))\n",
    "    fig.suptitle('MNIST: 112 timesteps × 7 features', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Row 1: Original 28×28\n",
    "        axes[0, i].imshow(images_28x28[i], cmap='gray')\n",
    "        axes[0, i].set_title(f'Label: {labels[i]}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Row 2: 112×7 as heatmap\n",
    "        axes[1, i].imshow(images_112x7[i], cmap='viridis', aspect='auto')\n",
    "        axes[1, i].set_xlabel('Feature (0-6)')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('Timestep (0-111)')\n",
    "        \n",
    "        # Row 3: Show scanning pattern\n",
    "        scan_vis = np.zeros((28, 28))\n",
    "        for t in range(0, 112, 16):  # Show every 16th timestep\n",
    "            start_pixel = t * 7\n",
    "            for p in range(7):\n",
    "                pixel_idx = start_pixel + p\n",
    "                if pixel_idx < 784:\n",
    "                    row, col = pixel_idx // 28, pixel_idx % 28\n",
    "                    scan_vis[row, col] = t / 112\n",
    "        axes[2, i].imshow(scan_vis, cmap='plasma', aspect='equal')\n",
    "        axes[2, i].set_title('Scan order')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    axes[0, 0].set_ylabel('Original\\n28×28', fontsize=10)\n",
    "    axes[1, 0].set_ylabel('Sequence\\n112×7', fontsize=10)\n",
    "    axes[2, 0].set_ylabel('Scan\\nPattern', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"112×7 Format Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"• 112 timesteps, 7 features each\")\n",
    "    print(f\"• Total: 112 × 7 = 784 pixels (matches 28×28)\")\n",
    "    print(f\"• Each hidden neuron receives 7 inputs (< 8 max)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "visualize_112x7_format(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Inspect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soen_toolkit.core.model_yaml import build_model_from_yaml\n",
    "\n",
    "model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec_112x7.yaml\")\n",
    "model = build_model_from_yaml(model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MNIST SOEN MODEL (112×7 Format)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nArchitecture:\")\n",
    "for layer_id, dim in model.layer_nodes.items():\n",
    "    print(f\"  Layer {layer_id}: {dim} neurons\")\n",
    "\n",
    "print(\"\\nConnections:\")\n",
    "for name, param in model.connections.items():\n",
    "    print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "print(\"\\nHardware compatibility:\")\n",
    "print(f\"  Input → Hidden: 7 inputs per neuron ✓ (< 8)\")\n",
    "print(f\"  Hidden → Hidden: 28 inputs per neuron (recurrent)\")\n",
    "print(f\"  Hidden → Output: 28 inputs per neuron\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "x_test = torch.randn(2, 112, 7)  # batch=2, 112 timesteps, 7 features\n",
    "with torch.no_grad():\n",
    "    output, states = model(x_test)\n",
    "print(f\"  Input: {x_test.shape}\")\n",
    "print(f\"  Output: {output.shape}\")\n",
    "print(\"  Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SOEN_NO_PROGRESS_BAR\"] = \"1\"\n",
    "\n",
    "from soen_toolkit.training.trainers.experiment import run_from_config\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING: 112 timesteps × 7 features\")\n",
    "print(\"=\"*60)\n",
    "print(\"Each hidden neuron receives 7 inputs (hardware compatible)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "run_from_config(\"training/training_configs/mnist_soen_112x7.yaml\", script_dir=Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint():\n",
    "    patterns = [\"training/temp/**/checkpoints/**/*.ckpt\", \"training/temp/**/*.ckpt\"]\n",
    "    all_ckpts = []\n",
    "    for p in patterns:\n",
    "        all_ckpts.extend(glob.glob(p, recursive=True))\n",
    "    \n",
    "    ckpts_112x7 = [c for c in all_ckpts if '112x7' in c]\n",
    "    if not ckpts_112x7:\n",
    "        ckpts_112x7 = all_ckpts\n",
    "    \n",
    "    if not ckpts_112x7:\n",
    "        print(\"No checkpoint found.\")\n",
    "        return None\n",
    "    \n",
    "    latest = max(ckpts_112x7, key=lambda x: Path(x).stat().st_mtime)\n",
    "    print(f\"Loading: {latest}\")\n",
    "    \n",
    "    model = build_model_from_yaml(model_path)\n",
    "    ckpt = torch.load(latest, map_location='cpu')\n",
    "    state_dict = ckpt.get('state_dict', ckpt)\n",
    "    clean = {k[6:] if k.startswith('model.') else k: v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(clean, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "trained_model = load_best_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_path):\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(test_data), 128)):\n",
    "            x = torch.tensor(test_data[i:i+128], dtype=torch.float32)\n",
    "            output, _ = model(x)\n",
    "            if output.dim() == 3:\n",
    "                output = output.mean(dim=1)  # Mean pooling\n",
    "            preds = output.argmax(dim=1).numpy()\n",
    "            all_preds.append(preds)\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    accuracy = (all_preds == test_labels).mean()\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    return accuracy\n",
    "\n",
    "if trained_model:\n",
    "    evaluate(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_path, n_samples=20):\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(len(test_data), n_samples, replace=False)\n",
    "    samples = test_data[idx]\n",
    "    labels = test_labels[idx]\n",
    "    \n",
    "    # Reconstruct 28×28\n",
    "    images = samples.reshape(n_samples, 784).reshape(n_samples, 28, 28)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(samples, dtype=torch.float32)\n",
    "        output, _ = model(x)\n",
    "        if output.dim() == 3:\n",
    "            output = output.mean(dim=1)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        preds = probs.argmax(dim=1).numpy()\n",
    "        conf = probs.max(dim=1)[0].numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle('Predictions (112×7 SOEN)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        correct = preds[i] == labels[i]\n",
    "        color = 'green' if correct else 'red'\n",
    "        axes[i].set_title(f\"{'✓' if correct else '✗'} {preds[i]} ({conf[i]:.0%})\\nTrue: {labels[i]}\",\n",
    "                          color=color, fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if trained_model:\n",
    "    visualize_predictions(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | Value |\n",
    "|--------|-------|\n",
    "| Input shape | (112, 7) |\n",
    "| Timesteps | 112 |\n",
    "| Features/timestep | 7 |\n",
    "| Hidden neurons | 28 |\n",
    "| Inputs per hidden neuron | **7** (< 8 max) |\n",
    "\n",
    "This format is **hardware compatible** because each hidden neuron receives only 7 inputs from the input layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
