# ==============================================================================
# MNIST SOEN Model Specification (7x112 Input, 8 Inputs Per Neuron)
# ==============================================================================
# Architecture: 112D → 128D (SingleDendrite) → 10D (Output)
#
# MNIST is reshaped from 28×28 to 7×112:
#   - 7 timesteps (groups of 4 rows)
#   - 112 features per timestep (4 rows × 28 pixels = 112)
#
# HARDWARE CONSTRAINT: Each neuron can receive at most 8 inputs
#   - Input → Hidden: SPARSE, each hidden neuron receives exactly 8 inputs
#   - Hidden → Hidden: SPARSE, each hidden neuron receives exactly 8 recurrent inputs
#   - Hidden → Output: SPARSE, each output neuron receives exactly 8 inputs
#
# This notebook uses custom mask files generated at runtime.
# ==============================================================================

simulation:
  dt: 100.0
  dt_learnable: false
  input_type: state
  track_power: false
  track_phi: true
  track_g: false
  track_s: false

layers:
  # Layer 0: Input Layer (112 features per timestep)
  - layer_id: 0
    layer_type: Input
    params:
      dim: 112
    description: "MNIST input (4 rows × 28 pixels = 112 features per timestep)"
    noise:
      phi: 0.0
      g: 0.0
      s: 0.0
      bias_current: 0.0
      j: 0.0
      relative: false
      extras: {}
    perturb:
      phi_mean: 0.0
      phi_std: 0.0
      g_mean: 0.0
      g_std: 0.0
      s_mean: 0.0
      s_std: 0.0
      bias_current_mean: 0.0
      bias_current_std: 0.0
      j_mean: 0.0
      j_std: 0.0
      extras_mean: {}
      extras_std: {}

  # Layer 1: Hidden SOEN Layer (128 neurons, each receives 8 inputs)
  - layer_id: 1
    layer_type: SingleDendrite
    params:
      dim: 128
      solver: FE
      source_func: Heaviside_fit_state_dep
      phi_offset:
        distribution: constant
        params:
          value: 0.02
      bias_current:
        distribution: uniform
        params:
          min: 1.8
          max: 2.1
      gamma_plus:
        distribution: constant
        params:
          value: 0.001
      gamma_minus:
        distribution: constant
        params:
          value: 0.0001
      learnable_params:
        phi_offset: false
        bias_current: false
        gamma_plus: false
        gamma_minus: false
    description: "Hidden SOEN layer (8 inputs per neuron - hardware compatible)"
    noise:
      phi: 0.01
      g: 0.0
      s: 0.005
      bias_current: 0.0
      j: 0.0
      relative: false
      extras:
        phi_offset: 0.0
        gamma_plus: 0.0
        gamma_minus: 0.0
    perturb:
      phi_mean: 0.0
      phi_std: 0.0
      g_mean: 0.0
      g_std: 0.0
      s_mean: 0.0
      s_std: 0.0
      bias_current_mean: 0.0
      bias_current_std: 0.0
      j_mean: 0.0
      j_std: 0.0
      extras_mean:
        phi_offset: 0.0
        gamma_plus: 0.0
        gamma_minus: 0.0
      extras_std:
        phi_offset: 0.0
        gamma_plus: 0.0
        gamma_minus: 0.0

  # Layer 2: Output Layer (10 classes)
  - layer_id: 2
    layer_type: Input
    params:
      dim: 10
    description: "Classification output (10 classes)"
    noise:
      phi: 0.0
      g: 0.0
      s: 0.0
      bias_current: 0.0
      j: 0.0
      relative: false
      extras: {}
    perturb:
      phi_mean: 0.0
      phi_std: 0.0
      g_mean: 0.0
      g_std: 0.0
      s_mean: 0.0
      s_std: 0.0
      bias_current_mean: 0.0
      bias_current_std: 0.0
      j_mean: 0.0
      j_std: 0.0
      extras_mean: {}
      extras_std: {}

connections:
  # J_0_to_1: Input → Hidden (112 → 128, SPARSE: 8 inputs per hidden neuron)
  # Uses custom mask file generated by notebook
  - from_layer: 0
    to_layer: 1
    connection_type: custom
    params:
      mask_file: "training/test_models/masks/J_0_to_1_fanin8.npz"
      min: -0.3
      max: 0.3
      init: uniform
      constraints:
        min: -1.0
        max: 1.0
    learnable: true
    noise:
      phi: 0.0
      g: 0.0
      s: 0.0
      bias_current: 0.0
      j: 0.0
      relative: false
      extras: {}
    perturb:
      phi_mean: 0.0
      phi_std: 0.0
      g_mean: 0.0
      g_std: 0.0
      s_mean: 0.0
      s_std: 0.0
      bias_current_mean: 0.0
      bias_current_std: 0.0
      j_mean: 0.0
      j_std: 0.0
      extras_mean: {}
      extras_std: {}

  # J_1_to_1: Hidden → Hidden (128 → 128, SPARSE: 8 inputs per hidden neuron)
  - from_layer: 1
    to_layer: 1
    connection_type: custom
    params:
      mask_file: "training/test_models/masks/J_1_to_1_fanin8.npz"
      mean: 0.0
      std: 0.1
      init: normal
      allow_self_connections: false
      constraints:
        min: -0.5
        max: 0.5
    learnable: true
    noise:
      phi: 0.0
      g: 0.0
      s: 0.0
      bias_current: 0.0
      j: 0.0
      relative: false
      extras: {}
    perturb:
      phi_mean: 0.0
      phi_std: 0.0
      g_mean: 0.0
      g_std: 0.0
      s_mean: 0.0
      s_std: 0.0
      bias_current_mean: 0.0
      bias_current_std: 0.0
      j_mean: 0.0
      j_std: 0.0
      extras_mean: {}
      extras_std: {}

  # J_1_to_2: Hidden → Output (128 → 10, SPARSE: 8 inputs per output neuron)
  - from_layer: 1
    to_layer: 2
    connection_type: custom
    params:
      mask_file: "training/test_models/masks/J_1_to_2_fanin8.npz"
      mean: 0.0
      std: 0.2
      init: normal
      constraints:
        min: -1.0
        max: 1.0
    learnable: true
    noise:
      phi: 0.0
      g: 0.0
      s: 0.0
      bias_current: 0.0
      j: 0.0
      relative: false
      extras: {}
    perturb:
      phi_mean: 0.0
      phi_std: 0.0
      g_mean: 0.0
      g_std: 0.0
      s_mean: 0.0
      s_std: 0.0
      bias_current_mean: 0.0
      bias_current_std: 0.0
      j_mean: 0.0
      j_std: 0.0
      extras_mean: {}
      extras_std: {}

seed: 42
