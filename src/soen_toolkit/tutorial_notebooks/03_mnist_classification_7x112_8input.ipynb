{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03c — MNIST Classification with SOEN (8 Inputs Per Neuron)\n",
    "\n",
    "This notebook demonstrates training a **hardware-compatible** SOEN model on MNIST where **each neuron receives at most 8 inputs**.\n",
    "\n",
    "---\n",
    "\n",
    "## Hardware Constraint\n",
    "\n",
    "| Connection | From → To | Fan-in per Neuron |\n",
    "|------------|-----------|-------------------|\n",
    "| J_0_to_1 | Input (112) → Hidden (128) | **8 inputs** per hidden neuron |\n",
    "| J_1_to_1 | Hidden (128) → Hidden (128) | **8 inputs** per hidden neuron |\n",
    "| J_1_to_2 | Hidden (128) → Output (10) | **8 inputs** per output neuron |\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Input (112D)  →  Hidden (128D)  →  Output (10D)\n",
    "              \\      ↺          /\n",
    "            8 inputs  8 recurrent  8 inputs\n",
    "            per neuron  per neuron  per neuron\n",
    "```\n",
    "\n",
    "## Data Format\n",
    "\n",
    "- **7 timesteps** × **112 features** per timestep\n",
    "- Each timestep = 4 rows × 28 pixels = 112 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TQDM_DISABLE\"] = \"0\"\n",
    "os.environ[\"TQDM_MININTERVAL\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Fixed Fan-In Masks (8 Inputs Per Neuron)\n",
    "\n",
    "Each neuron receives **exactly 8 inputs**. We create sparse connectivity masks that enforce this constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_fanin_mask(from_nodes: int, to_nodes: int, fan_in: int = 8, \n",
    "                            allow_self_connections: bool = True, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a connectivity mask where each destination neuron receives exactly `fan_in` inputs.\n",
    "    \n",
    "    Args:\n",
    "        from_nodes: Number of source neurons\n",
    "        to_nodes: Number of destination neurons  \n",
    "        fan_in: Number of inputs per destination neuron (default: 8)\n",
    "        allow_self_connections: Whether to allow neuron i to connect to itself\n",
    "        seed: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        mask: Binary mask [to_nodes, from_nodes] where 1 indicates a connection\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    mask = np.zeros((to_nodes, from_nodes), dtype=np.float32)\n",
    "    \n",
    "    for i in range(to_nodes):\n",
    "        # Get available source neurons\n",
    "        if allow_self_connections or from_nodes != to_nodes:\n",
    "            available = list(range(from_nodes))\n",
    "        else:\n",
    "            available = [j for j in range(from_nodes) if j != i]\n",
    "        \n",
    "        # Randomly select fan_in sources\n",
    "        k = min(fan_in, len(available))\n",
    "        selected = np.random.choice(available, size=k, replace=False)\n",
    "        mask[i, selected] = 1.0\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def save_mask(mask: np.ndarray, filepath: str):\n",
    "    \"\"\"Save mask to .npz file.\"\"\"\n",
    "    path = Path(filepath)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(filepath, mask=mask)\n",
    "    print(f\"Saved mask to {filepath}\")\n",
    "    print(f\"  Shape: {mask.shape}\")\n",
    "    print(f\"  Fan-in per neuron: {mask.sum(axis=1).astype(int)}\")\n",
    "    print(f\"  Total connections: {int(mask.sum())}\")\n",
    "\n",
    "\n",
    "# Create the masks directory\n",
    "masks_dir = Path(\"training/test_models/masks\")\n",
    "masks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define network dimensions\n",
    "INPUT_DIM = 112   # 4 rows × 28 pixels\n",
    "HIDDEN_DIM = 128  # Hidden layer size\n",
    "OUTPUT_DIM = 10   # 10 digit classes\n",
    "FAN_IN = 8        # Maximum inputs per neuron\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING FIXED FAN-IN MASKS (8 inputs per neuron)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# J_0_to_1: Input → Hidden (112 → 128)\n",
    "print(\"\\n[J_0_to_1] Input → Hidden\")\n",
    "mask_0_to_1 = create_fixed_fanin_mask(INPUT_DIM, HIDDEN_DIM, fan_in=FAN_IN, seed=42)\n",
    "save_mask(mask_0_to_1, str(masks_dir / \"J_0_to_1_fanin8.npz\"))\n",
    "\n",
    "# J_1_to_1: Hidden → Hidden (128 → 128, no self-connections)\n",
    "print(\"\\n[J_1_to_1] Hidden → Hidden (recurrent)\")\n",
    "mask_1_to_1 = create_fixed_fanin_mask(HIDDEN_DIM, HIDDEN_DIM, fan_in=FAN_IN, \n",
    "                                       allow_self_connections=False, seed=43)\n",
    "save_mask(mask_1_to_1, str(masks_dir / \"J_1_to_1_fanin8.npz\"))\n",
    "\n",
    "# J_1_to_2: Hidden → Output (128 → 10)\n",
    "print(\"\\n[J_1_to_2] Hidden → Output\")\n",
    "mask_1_to_2 = create_fixed_fanin_mask(HIDDEN_DIM, OUTPUT_DIM, fan_in=FAN_IN, seed=44)\n",
    "save_mask(mask_1_to_2, str(masks_dir / \"J_1_to_2_fanin8.npz\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MASK SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"J_0_to_1: {INPUT_DIM} → {HIDDEN_DIM}, {FAN_IN} inputs/neuron, {int(mask_0_to_1.sum())} connections\")\n",
    "print(f\"J_1_to_1: {HIDDEN_DIM} → {HIDDEN_DIM}, {FAN_IN} inputs/neuron, {int(mask_1_to_1.sum())} connections\")\n",
    "print(f\"J_1_to_2: {HIDDEN_DIM} → {OUTPUT_DIM}, {FAN_IN} inputs/neuron, {int(mask_1_to_2.sum())} connections\")\n",
    "print(f\"\\nTotal connections: {int(mask_0_to_1.sum() + mask_1_to_1.sum() + mask_1_to_2.sum())}\")\n",
    "print(f\"Dense equivalent: {INPUT_DIM*HIDDEN_DIM + HIDDEN_DIM*HIDDEN_DIM + HIDDEN_DIM*OUTPUT_DIM}\")\n",
    "sparsity = 1 - (mask_0_to_1.sum() + mask_1_to_1.sum() + mask_1_to_2.sum()) / \\\n",
    "           (INPUT_DIM*HIDDEN_DIM + HIDDEN_DIM*HIDDEN_DIM + HIDDEN_DIM*OUTPUT_DIM)\n",
    "print(f\"Sparsity: {sparsity:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Connectivity Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_masks():\n",
    "    \"\"\"Visualize the sparse connectivity masks.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    fig.suptitle('Sparse Connectivity Masks (8 inputs per neuron)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    masks = [\n",
    "        (mask_0_to_1, \"J_0_to_1: Input→Hidden\\n(112→128)\"),\n",
    "        (mask_1_to_1, \"J_1_to_1: Hidden→Hidden\\n(128→128, recurrent)\"),\n",
    "        (mask_1_to_2, \"J_1_to_2: Hidden→Output\\n(128→10)\"),\n",
    "    ]\n",
    "    \n",
    "    for ax, (mask, title) in zip(axes, masks):\n",
    "        im = ax.imshow(mask, aspect='auto', cmap='binary')\n",
    "        ax.set_title(title, fontsize=11)\n",
    "        ax.set_xlabel('Source Neurons')\n",
    "        ax.set_ylabel('Destination Neurons')\n",
    "        \n",
    "        # Add statistics\n",
    "        fan_ins = mask.sum(axis=1)\n",
    "        ax.text(0.02, 0.98, f\"Fan-in: {int(fan_ins.min())}-{int(fan_ins.max())}\\nConns: {int(mask.sum())}\",\n",
    "                transform=ax.transAxes, va='top', fontsize=9,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show fan-in distribution\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 3))\n",
    "    fig.suptitle('Fan-in Distribution (should be exactly 8 for each neuron)', fontsize=12)\n",
    "    \n",
    "    for ax, (mask, title) in zip(axes, masks):\n",
    "        fan_ins = mask.sum(axis=1)\n",
    "        ax.bar(range(len(fan_ins)), fan_ins, color='steelblue', edgecolor='none', alpha=0.7)\n",
    "        ax.axhline(y=8, color='red', linestyle='--', linewidth=2, label='Target (8)')\n",
    "        ax.set_xlabel('Neuron Index')\n",
    "        ax.set_ylabel('Number of Inputs')\n",
    "        ax.set_title(title.split('\\n')[0])\n",
    "        ax.set_ylim(0, 10)\n",
    "        ax.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_masks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare MNIST Dataset (7×112 Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        url = base_url + filename\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num_images, rows, cols)\n",
    "    return images\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def reshape_to_7x112(images):\n",
    "    n_samples = images.shape[0]\n",
    "    reshaped = images.reshape(n_samples, 7, 4, 28)\n",
    "    reshaped = reshaped.reshape(n_samples, 7, 112)\n",
    "    return reshaped\n",
    "\n",
    "def prepare_mnist_hdf5_7x112(output_path=\"training/datasets/mnist_seq7x112.hdf5\", \n",
    "                             normalize=True, val_split=0.1):\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if output_path.exists():\n",
    "        print(f\"Dataset already exists at {output_path}\")\n",
    "        with h5py.File(output_path, 'r') as f:\n",
    "            print(f\"  Train samples: {len(f['train']['labels'])}\")\n",
    "            print(f\"  Val samples: {len(f['val']['labels'])}\")\n",
    "            print(f\"  Test samples: {len(f['test']['labels'])}\")\n",
    "            print(f\"  Data shape: {f['train']['data'].shape}\")\n",
    "        return output_path\n",
    "    \n",
    "    print(\"Downloading MNIST...\")\n",
    "    train_images_file = download_mnist_file(\"train-images-idx3-ubyte.gz\")\n",
    "    train_labels_file = download_mnist_file(\"train-labels-idx1-ubyte.gz\")\n",
    "    test_images_file = download_mnist_file(\"t10k-images-idx3-ubyte.gz\")\n",
    "    test_labels_file = download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")\n",
    "    \n",
    "    train_images = read_mnist_images(train_images_file).astype(np.float32)\n",
    "    train_labels = read_mnist_labels(train_labels_file).astype(np.int64)\n",
    "    test_images = read_mnist_images(test_images_file).astype(np.float32)\n",
    "    test_labels = read_mnist_labels(test_labels_file).astype(np.int64)\n",
    "    \n",
    "    if normalize:\n",
    "        train_images = train_images / 255.0\n",
    "        test_images = test_images / 255.0\n",
    "    \n",
    "    print(\"\\nReshaping to 7×112 format...\")\n",
    "    train_images = reshape_to_7x112(train_images)\n",
    "    test_images = reshape_to_7x112(test_images)\n",
    "    \n",
    "    n_train = len(train_images)\n",
    "    n_val = int(n_train * val_split)\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(n_train)\n",
    "    val_indices = indices[:n_val]\n",
    "    train_indices = indices[n_val:]\n",
    "    \n",
    "    val_images = train_images[val_indices]\n",
    "    val_labels = train_labels[val_indices]\n",
    "    train_images = train_images[train_indices]\n",
    "    train_labels = train_labels[train_indices]\n",
    "    \n",
    "    print(f\"\\nSaving to {output_path}...\")\n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        train_grp = f.create_group('train')\n",
    "        train_grp.create_dataset('data', data=train_images)\n",
    "        train_grp.create_dataset('labels', data=train_labels)\n",
    "        \n",
    "        val_grp = f.create_group('val')\n",
    "        val_grp.create_dataset('data', data=val_images)\n",
    "        val_grp.create_dataset('labels', data=val_labels)\n",
    "        \n",
    "        test_grp = f.create_group('test')\n",
    "        test_grp.create_dataset('data', data=test_images)\n",
    "        test_grp.create_dataset('labels', data=test_labels)\n",
    "        \n",
    "        f.attrs['description'] = 'MNIST 7x112 format for 8-input neurons'\n",
    "        f.attrs['num_classes'] = 10\n",
    "        f.attrs['seq_len'] = 7\n",
    "        f.attrs['feature_dim'] = 112\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return output_path\n",
    "\n",
    "data_path = prepare_mnist_hdf5_7x112()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Illustrate the 8-Input Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_8input_constraint():\n",
    "    \"\"\"Visualize how each neuron receives exactly 8 inputs.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: Show which input features connect to a few example hidden neurons\n",
    "    ax = axes[0]\n",
    "    example_neurons = [0, 10, 50, 100, 127]  # Sample hidden neurons\n",
    "    \n",
    "    for i, neuron_idx in enumerate(example_neurons):\n",
    "        connected_inputs = np.where(mask_0_to_1[neuron_idx] == 1)[0]\n",
    "        y_pos = len(example_neurons) - i - 1\n",
    "        ax.scatter(connected_inputs, [y_pos] * len(connected_inputs), \n",
    "                   s=50, alpha=0.7, label=f'Hidden neuron {neuron_idx}')\n",
    "    \n",
    "    ax.set_xlabel('Input Feature Index (0-111)', fontsize=11)\n",
    "    ax.set_ylabel('Hidden Neuron')\n",
    "    ax.set_yticks(range(len(example_neurons)))\n",
    "    ax.set_yticklabels([f'H{n}' for n in reversed(example_neurons)])\n",
    "    ax.set_xlim(-2, 114)\n",
    "    ax.set_title('Input Connections to Example Hidden Neurons\\n(Each receives exactly 8 inputs)', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right: Show the sparse pattern as a circuit diagram\n",
    "    ax = axes[1]\n",
    "    \n",
    "    # Draw simplified network diagram\n",
    "    input_y = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]  # 8 sample inputs\n",
    "    hidden_y = 0.5  # Single hidden neuron\n",
    "    output_y = 0.5\n",
    "    \n",
    "    # Input neurons\n",
    "    for y in input_y:\n",
    "        ax.scatter([0.1], [y], s=200, c='lightblue', edgecolors='black', zorder=3)\n",
    "    ax.text(0.1, 1.0, 'Input\\n(8 of 112)', ha='center', fontsize=10)\n",
    "    \n",
    "    # Hidden neuron\n",
    "    ax.scatter([0.5], [hidden_y], s=400, c='lightgreen', edgecolors='black', zorder=3)\n",
    "    ax.text(0.5, 0.2, 'Hidden\\nNeuron\\n(1 of 128)', ha='center', fontsize=10)\n",
    "    \n",
    "    # Output neuron\n",
    "    ax.scatter([0.9], [output_y], s=300, c='lightyellow', edgecolors='black', zorder=3)\n",
    "    ax.text(0.9, 0.2, 'Output\\n(1 of 10)', ha='center', fontsize=10)\n",
    "    \n",
    "    # Draw connections from 8 inputs to hidden\n",
    "    for y in input_y:\n",
    "        ax.plot([0.1, 0.5], [y, hidden_y], 'b-', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    # Draw connection from hidden to output\n",
    "    ax.plot([0.5, 0.9], [hidden_y, output_y], 'g-', alpha=0.5, linewidth=2)\n",
    "    \n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('8-Input Constraint: Each Neuron Receives Only 8 Inputs', fontsize=11)\n",
    "    \n",
    "    # Add annotation\n",
    "    ax.annotate('Max 8 inputs', xy=(0.3, 0.6), fontsize=10, color='blue',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "illustrate_8input_constraint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Inspect the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soen_toolkit.core.model_yaml import build_model_from_yaml\n",
    "\n",
    "model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec_7x112_8input.yaml\")\n",
    "model = build_model_from_yaml(model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MNIST SOEN MODEL (8 Inputs Per Neuron)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(\"\\nLayer dimensions:\")\n",
    "for layer_id, dim in model.layer_nodes.items():\n",
    "    print(f\"  Layer {layer_id}: {dim} neurons\")\n",
    "\n",
    "print(\"\\nConnections (sparse with 8 fan-in):\")\n",
    "for name, param in model.connections.items():\n",
    "    # Check actual sparsity\n",
    "    mask = model.connection_masks.get(name)\n",
    "    if mask is not None:\n",
    "        active = (mask > 0).sum().item()\n",
    "        total = mask.numel()\n",
    "        sparsity = 1 - active / total\n",
    "        fan_in = mask.sum(dim=1).mean().item()\n",
    "        print(f\"  {name}: {param.shape}, active: {int(active)}/{total} ({sparsity:.1%} sparse), fan-in: {fan_in:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "x_test = torch.randn(2, 7, 112)\n",
    "with torch.no_grad():\n",
    "    output, states = model(x_test)\n",
    "print(f\"  Input: {x_test.shape}\")\n",
    "print(f\"  Output: {output.shape}\")\n",
    "print(\"  Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SOEN_NO_PROGRESS_BAR\"] = \"1\"\n",
    "\n",
    "from soen_toolkit.training.trainers.experiment import run_from_config\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SOEN MODEL (8 Inputs Per Neuron)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nHardware constraints enforced:\")\n",
    "print(\"  • Each hidden neuron: 8 feedforward + 8 recurrent inputs\")\n",
    "print(\"  • Each output neuron: 8 inputs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "run_from_config(\"training/training_configs/mnist_soen_7x112_8input.yaml\", script_dir=Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint():\n",
    "    ckpt_patterns = [\n",
    "        \"training/temp/**/checkpoints/**/*.ckpt\",\n",
    "        \"training/temp/**/*.ckpt\",\n",
    "    ]\n",
    "    \n",
    "    all_ckpts = []\n",
    "    for pattern in ckpt_patterns:\n",
    "        all_ckpts.extend(glob.glob(pattern, recursive=True))\n",
    "    \n",
    "    # Prefer 8input checkpoints\n",
    "    ckpts_8input = [c for c in all_ckpts if '8input' in c]\n",
    "    if not ckpts_8input:\n",
    "        ckpts_8input = all_ckpts\n",
    "    \n",
    "    if not ckpts_8input:\n",
    "        print(\"No checkpoint found. Run training first.\")\n",
    "        return None, None\n",
    "    \n",
    "    latest_ckpt = max(ckpts_8input, key=lambda x: Path(x).stat().st_mtime)\n",
    "    print(f\"Loading checkpoint: {latest_ckpt}\")\n",
    "    \n",
    "    model = build_model_from_yaml(model_path)\n",
    "    ckpt = torch.load(latest_ckpt, map_location='cpu')\n",
    "    state_dict = ckpt.get('state_dict', ckpt)\n",
    "    \n",
    "    clean_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('model.'):\n",
    "            clean_state_dict[k[6:]] = v\n",
    "        else:\n",
    "            clean_state_dict[k] = v\n",
    "    \n",
    "    model.load_state_dict(clean_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model, latest_ckpt\n",
    "\n",
    "trained_model, ckpt_path = load_best_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, data_path, batch_size=128):\n",
    "    if model is None:\n",
    "        print(\"No model loaded.\")\n",
    "        return\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    print(f\"Evaluating on {len(test_labels)} test samples...\")\n",
    "    \n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(test_data), batch_size)):\n",
    "            batch_data = test_data[i:i+batch_size]\n",
    "            x = torch.tensor(batch_data, dtype=torch.float32).to(device)\n",
    "            \n",
    "            output, _ = model(x)\n",
    "            \n",
    "            if output.dim() == 3:\n",
    "                pooled = output.max(dim=1)[0]\n",
    "            else:\n",
    "                pooled = output\n",
    "            \n",
    "            probs = torch.softmax(pooled, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    accuracy = (all_preds == test_labels).mean()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"TEST SET RESULTS (8 Inputs Per Neuron)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Correct: {(all_preds == test_labels).sum()}/{len(test_labels)}\")\n",
    "    \n",
    "    return all_preds, all_probs, accuracy\n",
    "\n",
    "if trained_model is not None:\n",
    "    predictions, probabilities, test_accuracy = evaluate_on_test_set(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_path, n_samples=20):\n",
    "    if model is None:\n",
    "        print(\"No model loaded.\")\n",
    "        return\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(test_data), n_samples, replace=False)\n",
    "    samples = test_data[indices]\n",
    "    labels = test_labels[indices]\n",
    "    \n",
    "    # Reconstruct 28×28 for visualization\n",
    "    samples_28x28 = samples.reshape(n_samples, 7, 4, 28).reshape(n_samples, 28, 28)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(samples, dtype=torch.float32)\n",
    "        output, _ = model(x)\n",
    "        if output.dim() == 3:\n",
    "            pooled = output.max(dim=1)[0]\n",
    "        else:\n",
    "            pooled = output\n",
    "        probs = torch.softmax(pooled, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).numpy()\n",
    "        confidence = probs.max(dim=1)[0].numpy()\n",
    "    \n",
    "    n_cols = 5\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(2.5*n_cols, 3*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle('MNIST Predictions (8-Input SOEN Model)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(samples_28x28[i], cmap='gray')\n",
    "        is_correct = preds[i] == labels[i]\n",
    "        color = 'green' if is_correct else 'red'\n",
    "        symbol = '✓' if is_correct else '✗'\n",
    "        ax.set_title(f\"{symbol} Pred: {preds[i]} ({confidence[i]:.0%})\\nTrue: {labels[i]}\",\n",
    "                     fontsize=9, color=color, fontweight='bold' if not is_correct else 'normal')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = (preds == labels).mean()\n",
    "    print(f\"\\nSample accuracy: {accuracy:.1%} ({(preds == labels).sum()}/{n_samples})\")\n",
    "\n",
    "if trained_model is not None:\n",
    "    visualize_predictions(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated training a **hardware-compatible** SOEN model where:\n",
    "\n",
    "| Constraint | Value | Notes |\n",
    "|------------|-------|-------|\n",
    "| Max inputs per neuron | **8** | Enforced via sparse masks |\n",
    "| Input shape | 7 × 112 | 7 timesteps, 112 features/timestep |\n",
    "| Hidden layer | 128 neurons | Each receives 8 feedforward + 8 recurrent |\n",
    "| Output layer | 10 neurons | Each receives 8 hidden inputs |\n",
    "\n",
    "### Connectivity Summary\n",
    "\n",
    "| Connection | Dense Size | Sparse Size | Sparsity |\n",
    "|------------|------------|-------------|----------|\n",
    "| J_0_to_1 (Input→Hidden) | 112×128 = 14,336 | 128×8 = 1,024 | 92.9% |\n",
    "| J_1_to_1 (Hidden→Hidden) | 128×128 = 16,384 | 128×8 = 1,024 | 93.8% |\n",
    "| J_1_to_2 (Hidden→Output) | 128×10 = 1,280 | 10×8 = 80 | 93.8% |\n",
    "| **Total** | 32,000 | 2,128 | **93.4%** |\n",
    "\n",
    "### Hardware Mapping\n",
    "\n",
    "Each neuron in this model can be directly mapped to hardware neurons with 8 input ports."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
