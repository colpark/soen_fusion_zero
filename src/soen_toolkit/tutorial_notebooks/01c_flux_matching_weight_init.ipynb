{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Flux-Matching Weight Initialization\n\nThis notebook demonstrates the **iterative flux-matching** algorithm for initializing SOEN network weights.\n\n---\n\n## ðŸ”Š NOISE CONFIGURATION: ENABLED (Default)\n\n> **This tutorial runs with NOISE INJECTION (documented defaults).**\n>\n> | Parameter | Default | Description |\n> |-----------|---------|-------------|\n> | `phi` | **0.01** | Noise on input flux |\n> | `s` | **0.005** | Noise on state |\n> | `relative` | **False** | Absolute scaling |\n>\n> **To toggle noise on/off:** Use the `NOISE_ENABLED` variable in the next code cell.\n\n---\n\n## Why Flux-Matching?\n\nThe SOEN source function (RateArray/Heaviside) is periodic with **maximum response at Ï†_total = 0.5**:\n\n$$\\phi_{\\text{total}} = \\phi_{\\text{exc}} + \\phi_{\\text{offset}}$$\n\nFor optimal network operation, we want each neuron's total input flux near this sweet spot. The flux-matching algorithm:\n\n1. Runs forward passes with your training data\n2. Observes actual mean states of each neuron\n3. Adjusts weights so total incoming flux hits the target\n4. Iterates until convergence"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup: Ensure soen_toolkit is importable\nimport sys\nfrom pathlib import Path\n\n# Add src directory to path if running from notebook location\nnotebook_dir = Path.cwd()\nfor parent in [notebook_dir] + list(notebook_dir.parents):\n    candidate = parent / \"src\"\n    if (candidate / \"soen_toolkit\").exists():\n        sys.path.insert(0, str(candidate))\n        break\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\n# SOEN Toolkit imports\nfrom soen_toolkit.core import SOENModelCore\nfrom soen_toolkit.core.model_yaml import build_model_from_yaml\nfrom soen_toolkit.utils.flux_matching_init import (\n    FluxMatchingConfig,\n    load_hdf5_batches,\n    run_flux_matching_iterations,\n)\n\n# Set up plotting style\nplt.rcParams['figure.figsize'] = (12, 5)\nplt.rcParams['font.size'] = 11\n\nprint(\"Setup complete!\")"
  },
  {
   "cell_type": "code",
   "source": "# ==============================================================================\n# NOISE CONFIGURATION TOGGLE\n# ==============================================================================\n# Set NOISE_ENABLED = False to run with ideal conditions (no noise)\n# Set NOISE_ENABLED = True for noise injection (default)\n\nNOISE_ENABLED = True  # Toggle this to enable/disable noise\n\n# Default noise parameters (documented defaults)\nNOISE_DEFAULTS = {\n    \"phi\": 0.01,           # Noise on input flux\n    \"s\": 0.005,            # Noise on state\n    \"g\": 0.0,              # Source function noise\n    \"bias_current\": 0.0,   # Bias current noise\n    \"j\": 0.0,              # Connection weight noise\n    \"relative\": False,     # Absolute scaling\n}\n\ndef set_model_noise(model, enabled=True, noise_values=None):\n    \"\"\"\n    Toggle noise injection on/off for a SOEN model.\n    \n    Args:\n        model: SOENModelCore instance\n        enabled: If True, apply noise; if False, set all noise to 0\n        noise_values: Dict of noise parameters (uses NOISE_DEFAULTS if None)\n    \n    Returns:\n        model: The modified model (for chaining)\n    \"\"\"\n    from soen_toolkit.core.configs import NoiseConfig\n    \n    if noise_values is None:\n        noise_values = NOISE_DEFAULTS\n    \n    # Update layer noise configurations\n    for cfg in model.layers_config:\n        if enabled:\n            cfg.noise = NoiseConfig(\n                phi=noise_values.get(\"phi\", 0.01),\n                s=noise_values.get(\"s\", 0.005),\n                g=noise_values.get(\"g\", 0.0),\n                bias_current=noise_values.get(\"bias_current\", 0.0),\n                j=noise_values.get(\"j\", 0.0),\n                relative=noise_values.get(\"relative\", False),\n                extras=getattr(cfg.noise, \"extras\", {}),\n            )\n        else:\n            cfg.noise = NoiseConfig(\n                phi=0.0, s=0.0, g=0.0, bias_current=0.0, j=0.0,\n                relative=False,\n                extras=getattr(cfg.noise, \"extras\", {}),\n            )\n    \n    # Update connection noise configurations\n    for conn_cfg in model.connections_config:\n        if enabled:\n            conn_cfg.noise = NoiseConfig(\n                phi=0.0, g=0.0, s=0.0, bias_current=0.0,\n                j=noise_values.get(\"j\", 0.0),\n                relative=noise_values.get(\"relative\", False),\n                extras={},\n            )\n        else:\n            conn_cfg.noise = NoiseConfig(\n                phi=0.0, g=0.0, s=0.0, bias_current=0.0, j=0.0,\n                relative=False, extras={},\n            )\n    \n    status = \"ENABLED\" if enabled else \"DISABLED\"\n    print(f\"âœ“ Noise injection {status}\")\n    if enabled:\n        print(f\"  phi={noise_values['phi']}, s={noise_values['s']}, \"\n              f\"relative={noise_values['relative']}\")\n    \n    return model\n\nprint(f\"Noise injection: {'ENABLED' if NOISE_ENABLED else 'DISABLED'}\")\nif NOISE_ENABLED:\n    print(f\"  Default values: phi={NOISE_DEFAULTS['phi']}, s={NOISE_DEFAULTS['s']}, \"\n          f\"relative={NOISE_DEFAULTS['relative']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration\n",
    "\n",
    "Set your paths and algorithm parameters below. Modify these to use your own model and data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# USER CONFIGURATION - Modify these paths and settings\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Path to your model YAML file\n",
    "MODEL_YAML_PATH = \"path/to/your/model.yaml\"\n",
    "\n",
    "\n",
    "# Path to your HDF5 dataset\n",
    "DATA_HDF5_PATH = \"path/to/your/data.hdf5\"\n",
    "\n",
    "# Dataset split to use ('train', 'val', 'test', or 'all_data')\n",
    "DATA_SPLIT = \"train\"\n",
    "\n",
    "# Data scaling - normalize input data to this range\n",
    "# Set both to None to skip scaling\n",
    "DATA_SCALE_MIN = 0.0  # Target minimum value\n",
    "DATA_SCALE_MAX = 1.0  # Target maximum value\n",
    "\n",
    "# Path to save the initialized model\n",
    "OUTPUT_MODEL_PATH = \"flux_matched_model.soen\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ALGORITHM SETTINGS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Target TOTAL flux (phi_total = phi_exc + phi_offset)\n",
    "# The algorithm reads each node's phi_offset and computes the required phi_exc.\n",
    "# The optimal operating point is phi_total = 0.5 (maximum source function response).\n",
    "\n",
    "# Option 1: Single target for all nodes\n",
    "PHI_TOTAL_TARGET = 0.5\n",
    "\n",
    "# Option 2: Symmetry breaking with a range of targets\n",
    "# When both min and max are specified, targets are uniformly distributed\n",
    "# across dendrites within each layer (from min at node 0 to max at node N-1).\n",
    "# This breaks symmetry deterministically without adding noise.\n",
    "# Set both to None to use the single PHI_TOTAL_TARGET value instead.\n",
    "PHI_TOTAL_TARGET_MIN = 0.45  # Lower bound of target phi_total\n",
    "PHI_TOTAL_TARGET_MAX = 0.55  # Upper bound of target phi_total\n",
    "\n",
    "# Number of flux-matching iterations\n",
    "NUM_ITERATIONS = 100\n",
    "\n",
    "# Batch size for forward passes\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Number of batches to use (None = use all data, or set a number for faster runs)\n",
    "NUM_BATCHES = 20  # Set to None to use all data\n",
    "\n",
    "# Minimum state clamp (prevents division by zero)\n",
    "MIN_STATE_CLAMP = 0.01\n",
    "\n",
    "# Step size for weight updates (0=no update, 1=full update, 0.5=smooth updates)\n",
    "ALPHA = 0.1\n",
    "\n",
    "# Weight update mode: \"connection_wise\" or \"node_wise\"\n",
    "#   - connection_wise: Each J_ij is computed from individual source state s_j (more precise)\n",
    "#   - node_wise: All J for a destination use averaged upstream states (simpler)\n",
    "WEIGHT_UPDATE_MODE = \"connection_wise\"\n",
    "\n",
    "# Device ('cpu' or 'cuda')\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"  Model: {MODEL_YAML_PATH}\")\n",
    "print(f\"  Data: {DATA_HDF5_PATH}\")\n",
    "if PHI_TOTAL_TARGET_MIN is not None and PHI_TOTAL_TARGET_MAX is not None:\n",
    "    print(f\"  Target phi_total range: {PHI_TOTAL_TARGET_MIN} to {PHI_TOTAL_TARGET_MAX} (symmetry breaking)\")\n",
    "else:\n",
    "    print(f\"  Target phi_total: {PHI_TOTAL_TARGET}\")\n",
    "print(f\"  Iterations: {NUM_ITERATIONS}\")\n",
    "print(f\"  Mode: {WEIGHT_UPDATE_MODE}\")\n",
    "print(f\"  Alpha: {ALPHA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Paths and Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if files exist\n",
    "model_path = Path(MODEL_YAML_PATH)\n",
    "data_path = Path(DATA_HDF5_PATH)\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"Model file not found: {model_path}\")\n",
    "    print(\"Please update MODEL_YAML_PATH in the configuration cell above.\")\n",
    "else:\n",
    "    print(f\"Model file found: {model_path}\")\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(f\"Data file not found: {data_path}\")\n",
    "    print(\"Please update DATA_HDF5_PATH in the configuration cell above.\")\n",
    "else:\n",
    "    print(f\"Data file found: {data_path}\")\n",
    "\n",
    "    # Show data info\n",
    "    import h5py\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        print(\"\\nDataset contents:\")\n",
    "        for key in f.keys():\n",
    "            if hasattr(f[key], 'shape'):\n",
    "                print(f\"  {key}: {f[key].shape}\")\n",
    "            else:\n",
    "                print(f\"  {key}/ (group)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Model and Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (supports both .yaml and .soen formats)\n",
    "print(\"Loading model...\")\n",
    "if model_path.suffix.lower() in ['.soen', '.pth']:\n",
    "    model = SOENModelCore.load(str(model_path))\n",
    "else:\n",
    "    model = build_model_from_yaml(model_path)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(f\"  Layers: {len(model.layers_config)}\")\n",
    "for cfg in model.layers_config:\n",
    "    dim = cfg.params.get('dim', '?')\n",
    "    print(f\"    Layer {cfg.layer_id}: {cfg.layer_type} (dim={dim})\")\n",
    "\n",
    "print(f\"\\n  Connections: {len(model.connections_config)}\")\n",
    "for conn in model.connections_config:\n",
    "    print(f\"    {conn.from_layer} -> {conn.to_layer} ({conn.connection_type})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data batches\n",
    "print(f\"Loading data from {DATA_SPLIT} split...\")\n",
    "data_batches = load_hdf5_batches(\n",
    "    data_path,\n",
    "    split=DATA_SPLIT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_batches=NUM_BATCHES,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Scale data if requested\n",
    "if DATA_SCALE_MIN is not None and DATA_SCALE_MAX is not None:\n",
    "    # Find global min/max across all batches\n",
    "    all_data = torch.cat(data_batches, dim=0)\n",
    "    data_min = all_data.min()\n",
    "    data_max = all_data.max()\n",
    "    print(f\"\\nOriginal data range: [{data_min:.4f}, {data_max:.4f}]\")\n",
    "\n",
    "    # Scale to target range\n",
    "    scale = (DATA_SCALE_MAX - DATA_SCALE_MIN) / (data_max - data_min + 1e-8)\n",
    "    data_batches = [\n",
    "        (batch - data_min) * scale + DATA_SCALE_MIN\n",
    "        for batch in data_batches\n",
    "    ]\n",
    "    print(f\"Scaled to range: [{DATA_SCALE_MIN}, {DATA_SCALE_MAX}]\")\n",
    "\n",
    "print(f\"\\nLoaded {len(data_batches)} batches\")\n",
    "if data_batches:\n",
    "    sample = data_batches[0]\n",
    "    print(f\"  Batch shape: {sample.shape}\")\n",
    "    print(f\"  Data range: [{sample.min():.4f}, {sample.max():.4f}]\")\n",
    "    print(\"  (batch_size, sequence_length, input_dim)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Run Flux-Matching Algorithm\n",
    "\n",
    "Now let's run the iterative flux-matching to optimize the weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the algorithm\n",
    "config = FluxMatchingConfig(\n",
    "    phi_total_target=PHI_TOTAL_TARGET,\n",
    "    phi_total_target_min=PHI_TOTAL_TARGET_MIN,  # Set to None to disable symmetry breaking\n",
    "    phi_total_target_max=PHI_TOTAL_TARGET_MAX,  # Set to None to disable symmetry breaking\n",
    "    num_iterations=NUM_ITERATIONS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_batches=NUM_BATCHES,\n",
    "    min_state_clamp=MIN_STATE_CLAMP,\n",
    "    alpha=ALPHA,\n",
    "    weight_update_mode=WEIGHT_UPDATE_MODE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"Starting Flux-Matching Optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run the algorithm\n",
    "result = run_flux_matching_iterations(model, data_batches, config)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if result.converged:\n",
    "    print(\"CONVERGED to target phi_total!\")\n",
    "else:\n",
    "    print(\"Did not fully converge. Consider more iterations or smaller alpha.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Visualize Convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(result, target_flux=None, target_min=None, target_max=None):\n",
    "    \"\"\"Plot flux convergence over iterations.\n",
    "    \n",
    "    Args:\n",
    "        result: FluxMatchingResult from run_flux_matching_iterations\n",
    "        target_flux: Single target flux value (used if min/max not provided)\n",
    "        target_min: Lower bound of target flux range\n",
    "        target_max: Upper bound of target flux range\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract layers with flux data\n",
    "    layers_with_flux = set()\n",
    "    for stats in result.iteration_stats:\n",
    "        layers_with_flux.update(stats[\"flux_per_layer\"].keys())\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "    # Plot 1: Flux Convergence\n",
    "    ax1 = axes[0]\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(layers_with_flux)))\n",
    "\n",
    "    for i, layer_id in enumerate(sorted(layers_with_flux)):\n",
    "        means = []\n",
    "        stds = []\n",
    "        for stats in result.iteration_stats:\n",
    "            if layer_id in stats[\"flux_per_layer\"]:\n",
    "                means.append(stats[\"flux_per_layer\"][layer_id][\"mean\"])\n",
    "                stds.append(stats[\"flux_per_layer\"][layer_id][\"std\"])\n",
    "\n",
    "        iterations = list(range(1, len(means) + 1))\n",
    "        ax1.fill_between(iterations,\n",
    "                         [m - s for m, s in zip(means, stds, strict=False)],\n",
    "                         [m + s for m, s in zip(means, stds, strict=False)],\n",
    "                         alpha=0.2, color=colors[i])\n",
    "        ax1.plot(iterations, means, 'o-', color=colors[i],\n",
    "                 label=f'Layer {layer_id}', linewidth=2, markersize=6)\n",
    "\n",
    "    # Draw target as either a range or single line\n",
    "    if target_min is not None and target_max is not None:\n",
    "        ax1.axhspan(target_min, target_max, color='red', alpha=0.15, label=f'Target range ({target_min}-{target_max})')\n",
    "        mid = (target_min + target_max) / 2\n",
    "        ax1.axhline(y=mid, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label=f'Midpoint ({mid:.2f})')\n",
    "    elif target_flux is not None:\n",
    "        ax1.axhline(y=target_flux, color='red', linestyle='--', linewidth=2, label=f'Target ({target_flux})')\n",
    "\n",
    "    ax1.set_xlabel('Iteration', fontsize=12)\n",
    "    ax1.set_ylabel('Mean Flux per Node', fontsize=12)\n",
    "    ax1.set_title('Flux Convergence', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.set_xlim(0.5, len(result.iteration_stats) + 0.5)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Mean State Evolution\n",
    "    ax2 = axes[1]\n",
    "    all_layers = set()\n",
    "    for stats in result.iteration_stats:\n",
    "        all_layers.update(stats[\"mean_states\"].keys())\n",
    "\n",
    "    colors2 = plt.cm.plasma(np.linspace(0.2, 0.8, len(all_layers)))\n",
    "\n",
    "    for i, layer_id in enumerate(sorted(all_layers)):\n",
    "        means = [stats[\"mean_states\"].get(layer_id, float('nan')) for stats in result.iteration_stats]\n",
    "        iterations = list(range(1, len(means) + 1))\n",
    "        ax2.plot(iterations, means, 's-', color=colors2[i], label=f'Layer {layer_id}', linewidth=2, markersize=6)\n",
    "\n",
    "    ax2.set_xlabel('Iteration', fontsize=12)\n",
    "    ax2.set_ylabel('Mean State', fontsize=12)\n",
    "    ax2.set_title('Mean State per Layer', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.set_xlim(0.5, len(result.iteration_stats) + 0.5)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Error Reduction\n",
    "    ax3 = axes[2]\n",
    "\n",
    "    for i, layer_id in enumerate(sorted(layers_with_flux)):\n",
    "        errors = [stats[\"flux_error_per_layer\"].get(layer_id, float('nan')) for stats in result.iteration_stats]\n",
    "        iterations = list(range(1, len(errors) + 1))\n",
    "        ax3.semilogy(iterations, errors, 'o-', color=colors[i], label=f'Layer {layer_id}', linewidth=2, markersize=6)\n",
    "\n",
    "    ax3.axhline(y=0.02, color='green', linestyle=':', linewidth=2, label='Convergence threshold')\n",
    "    ax3.set_xlabel('Iteration', fontsize=12)\n",
    "    ax3.set_ylabel('Flux Error (log scale)', fontsize=12)\n",
    "    ax3.set_title('Error Reduction', fontsize=14, fontweight='bold')\n",
    "    ax3.legend(loc='best')\n",
    "    ax3.set_xlim(0.5, len(result.iteration_stats) + 0.5)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate the plot\n",
    "fig = plot_convergence(\n",
    "    result,\n",
    "    target_flux=PHI_TOTAL_TARGET,\n",
    "    target_min=PHI_TOTAL_TARGET_MIN,\n",
    "    target_max=PHI_TOTAL_TARGET_MAX,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('flux_matching_convergence.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\nPlot saved to: flux_matching_convergence.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Final Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final statistics\n",
    "final_stats = result.iteration_stats[-1]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL STATE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Determine target info for display\n",
    "using_range = PHI_TOTAL_TARGET_MIN is not None and PHI_TOTAL_TARGET_MAX is not None\n",
    "if using_range:\n",
    "    target_mid = (PHI_TOTAL_TARGET_MIN + PHI_TOTAL_TARGET_MAX) / 2\n",
    "    print(f\"\\nTarget phi_total range: {PHI_TOTAL_TARGET_MIN} to {PHI_TOTAL_TARGET_MAX} (symmetry breaking)\")\n",
    "    print(f\"Expected mean phi_total: {target_mid:.3f}\")\n",
    "else:\n",
    "    target_mid = PHI_TOTAL_TARGET\n",
    "    print(f\"\\nTarget phi_total: {PHI_TOTAL_TARGET}\")\n",
    "\n",
    "print(f\"Iterations:  {NUM_ITERATIONS}\")\n",
    "print(f\"Converged:   {'Yes' if result.converged else 'No'}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "if using_range:\n",
    "    print(f\"{'Layer':<8} {'Mean State':<12} {'phi_total [min, max]':<22} {'Mean':<10} {'vs Target':<15}\")\n",
    "else:\n",
    "    print(f\"{'Layer':<8} {'Mean State':<12} {'phi_total (mean +/- std)':<27} {'Error %':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for layer_id in sorted(final_stats[\"mean_states\"].keys()):\n",
    "    mean_s = final_stats[\"mean_states\"][layer_id]\n",
    "    if layer_id in final_stats[\"flux_per_layer\"]:\n",
    "        flux_info = final_stats[\"flux_per_layer\"][layer_id]\n",
    "        error = final_stats[\"flux_error_per_layer\"][layer_id]\n",
    "        error_pct = (error / target_mid) * 100\n",
    "        if using_range:\n",
    "            range_str = f\"[{flux_info['min']:.3f}, {flux_info['max']:.3f}]\"\n",
    "            target_range = f\"[{PHI_TOTAL_TARGET_MIN}, {PHI_TOTAL_TARGET_MAX}]\"\n",
    "            print(f\"{layer_id:<8} {mean_s:<12.4f} {range_str:<22} {flux_info['mean']:<10.4f} {target_range:<15}\")\n",
    "        else:\n",
    "            flux_str = f\"{flux_info['mean']:.4f} +/- {flux_info['std']:.4f}\"\n",
    "            print(f\"{layer_id:<8} {mean_s:<12.4f} {flux_str:<27} {error_pct:>6.2f}%\")\n",
    "    else:\n",
    "        print(f\"{layer_id:<8} {mean_s:<12.4f} {'(input layer)':<27}\")\n",
    "\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Optional: Impose an Inhibitory Fraction (Preserve Target Flux)\n",
    "\n",
    "Flux-matching can yield mostly-positive weights (especially when mean upstream states are mostly positive). If you want (for example) **20% inhibitory** synapses per destination node (per incoming edge), you can apply a post-processing step that:\n",
    "\n",
    "- flips a random fraction of active synapses to negative\n",
    "- rescales the remaining active synapses so each destination node still matches its target external flux\n",
    "\n",
    "This uses the same `mean_states` estimate that flux matching used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soen_toolkit.utils.flux_matching_init import apply_inhibitory_fraction_preserving_flux\n",
    "\n",
    "# Apply after flux matching, before saving (optional)\n",
    "# Uses the final mean_states from the last iteration\n",
    "apply_inhibitory_fraction_preserving_flux(\n",
    "    model,\n",
    "    result.final_mean_states,\n",
    "    config=config,\n",
    "    inhibitory_fraction=0.2,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "print(\"Applied inhibitory fraction post-processing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Save the Initialized Model\n",
    "\n",
    "Save the model with optimized weights using `.soen` format (binary format that preserves weights, masks, and configuration).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as .soen (includes weights, masks, and config)\n",
    "output_path = Path(OUTPUT_MODEL_PATH)\n",
    "\n",
    "print(f\"Saving initialized model to: {output_path}\")\n",
    "model.save(str(output_path))\n",
    "\n",
    "print(\"\\nModel saved successfully!\")\n",
    "print(\"\\nTo load this model later:\")\n",
    "print(\"  from soen_toolkit.core import SOENModelCore\")\n",
    "print(f\"  model = SOENModelCore.load('{output_path}')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Weight Distribution (Optional)\n",
    "\n",
    "Visualize the final weight distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weight distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "conn_keys = list(model.connections.keys())\n",
    "\n",
    "for i, key in enumerate(conn_keys[:6]):  # Show up to 6 connections\n",
    "    ax = axes[i]\n",
    "    weights = model.connections[key].detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Filter by mask if available\n",
    "    mask = model.connection_masks.get(key)\n",
    "    if mask is not None:\n",
    "        mask_np = mask.cpu().numpy().flatten()\n",
    "        weights = weights[mask_np > 0]  # Only show active weights\n",
    "\n",
    "    ax.hist(weights, bins=50, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "    ax.axvline(x=weights.mean(), color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {weights.mean():.4f}')\n",
    "    ax.set_title(key, fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Weight Value')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(conn_keys), 6):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Weight Distributions After Flux-Matching', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "You have successfully:\n",
    "\n",
    "1. **Loaded** your model and training data\n",
    "2. **Ran** the iterative flux-matching algorithm  \n",
    "3. **Visualized** the convergence process\n",
    "4. **Saved** the optimized model (`.soen` format with weights)\n",
    "\n",
    "### Parameter Reference\n",
    "\n",
    "| Parameter | Description | Default |\n",
    "|-----------|-------------|---------|\n",
    "| `phi_total_target` | Target total flux (phi_exc + phi_offset). 0.5 is the optimal operating point. | 0.5 |\n",
    "| `phi_total_target_min` | Lower bound of target phi_total range (for symmetry breaking). Set to None to use single target. | None |\n",
    "| `phi_total_target_max` | Upper bound of target phi_total range (for symmetry breaking). Set to None to use single target. | None |\n",
    "| `num_iterations` | Number of optimization iterations | 5 |\n",
    "| `batch_size` | Batch size for forward passes | 32 |\n",
    "| `num_batches` | Number of batches to use (None = all data) | None |\n",
    "| `min_state_clamp` | Minimum state value to prevent division by zero | 0.01 |\n",
    "| `alpha` | Step size for weight updates (0=none, 1=full, 0.5=smooth) | 1.0 |\n",
    "| `weight_update_mode` | `\"connection_wise\"` or `\"node_wise\"` (see below) | `\"connection_wise\"` |\n",
    "\n",
    "### Per-Node phi_offset Handling\n",
    "\n",
    "The algorithm automatically reads each node's `phi_offset` from the layer and computes the required external flux:\n",
    "\n",
    "```\n",
    "phi_exc_target[i] = phi_total_target[i] - phi_offset[i]\n",
    "```\n",
    "\n",
    "This means you specify the actual operating point (`phi_total`) and the algorithm figures out what weights are needed to achieve it, regardless of how phi_offset varies across nodes.\n",
    "\n",
    "### Symmetry Breaking\n",
    "\n",
    "When `phi_total_target_min` and `phi_total_target_max` are both specified, target phi_total values are **uniformly distributed** across dendrites within each layer:\n",
    "- Node 0 gets target = `phi_total_target_min`\n",
    "- Node N-1 gets target = `phi_total_target_max`\n",
    "- Intermediate nodes are linearly interpolated\n",
    "\n",
    "This breaks symmetry deterministically without adding noise. Example:\n",
    "```python\n",
    "config = FluxMatchingConfig(\n",
    "    phi_total_target_min=0.45,\n",
    "    phi_total_target_max=0.55,\n",
    "    ...\n",
    ")\n",
    "```\n",
    "\n",
    "For a layer with 100 nodes, targets would range from 0.45 (node 0) to 0.55 (node 99).\n",
    "\n",
    "### Weight Update Modes\n",
    "\n",
    "**Connection-wise** (recommended): Computes individual J_ij for each connection:\n",
    "```\n",
    "J_ij = phi_exc_target[i] / (num_sources * fan_in_i * s_j)\n",
    "```\n",
    "Each weight uses the actual state s_j of its specific source neuron.\n",
    "\n",
    "**Node-wise**: Computes uniform J for each destination node:\n",
    "```\n",
    "J_i = phi_exc_target[i] / (num_sources * fan_in_i * mean_upstream_i)\n",
    "```\n",
    "Uses averaged upstream states (simpler but less precise).\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **Forward pass**: Run input data through the network\n",
    "2. **State collection**: Record mean neuron states across time and batches  \n",
    "3. **Flux calculation**: Compute current phi_total for each neuron (phi_exc + phi_offset)\n",
    "4. **Weight adjustment**: Compute target phi_exc accounting for each node's phi_offset, then blend weights toward target\n",
    "5. **Repeat**: Iterate until phi_total converges to target\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Use the initialized model for training\n",
    "- Compare training convergence: random init vs flux-matched init\n",
    "- Experiment with different `phi_total_target` values or ranges\n",
    "- Try smaller `alpha` (e.g., 0.5) if oscillations occur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary (Updated Notes)\n",
    "\n",
    "This tutorial now supports two extra concepts that arenâ€™t reflected in the older Summary section above:\n",
    "\n",
    "- **Target allocation across incoming edges**: if a destination layer has multiple incoming weight matrices, the per-node target external flux is allocated across those incoming edges using `flux_allocation_mode` (`\"equal_per_incoming_connection\"` or `\"proportional_to_fan_in\"`).\n",
    "- **Inhibitory fraction post-step**: you can impose a chosen fraction of inhibitory (negative) synapses after flux matching while preserving each nodeâ€™s target external flux.\n",
    "\n",
    "### Correct per-edge weight formulas\n",
    "\n",
    "Within a single incoming edge:\n",
    "\n",
    "**Connection-wise**:\n",
    "\n",
    "```\n",
    "phi_exc_target_for_edge[i] = allocation(phi_exc_target[i])\n",
    "J_edge[i,j] = phi_exc_target_for_edge[i] / (fan_in_edge[i] * s_j)\n",
    "```\n",
    "\n",
    "**Node-wise**:\n",
    "\n",
    "```\n",
    "phi_exc_target_for_edge[i] = allocation(phi_exc_target[i])\n",
    "J_edge[i,:] = phi_exc_target_for_edge[i] / (fan_in_edge[i] * mean_upstream_edge[i])\n",
    "```\n",
    "\n",
    "### Inhibitory fraction (preserve flux)\n",
    "\n",
    "After `run_flux_matching_iterations(...)`:\n",
    "\n",
    "```\n",
    "apply_inhibitory_fraction_preserving_flux(\n",
    "    model,\n",
    "    result.final_mean_states,\n",
    "    config=config,\n",
    "    inhibitory_fraction=0.2,\n",
    "    seed=0,\n",
    ")\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (soen-toolkit)",
   "language": "python",
   "name": "soen_toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}