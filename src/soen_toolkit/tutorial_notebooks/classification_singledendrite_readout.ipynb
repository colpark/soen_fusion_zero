{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with SingleDendrite Readout Layer\n",
    "\n",
    "In this notebook, we use **SingleDendrite neurons for the readout layer** instead of a passive linear readout.\n",
    "\n",
    "## Key Differences from Previous Notebooks\n",
    "\n",
    "| Component | Previous | This Notebook |\n",
    "|-----------|----------|---------------|\n",
    "| Hidden Layers | SingleDendrite | SingleDendrite |\n",
    "| Readout Layer | Input (linear) | SingleDendrite |\n",
    "| Readout phi_offset | N/A | **0.23 (at threshold)** |\n",
    "\n",
    "## Why phi_offset = 0.23?\n",
    "\n",
    "Setting `phi_offset = 0.23` initializes the readout neuron **at the threshold** of its nonlinear response curve.\n",
    "This makes training easier because:\n",
    "- Small changes in input flux cause meaningful changes in output\n",
    "- The neuron is \"ready to fire\" and gradient flow is maximized\n",
    "- Avoids dead zones where the neuron is saturated or off\n",
    "\n",
    "## Hardware Motivation\n",
    "\n",
    "In a real SOEN hardware implementation, the readout would also be a physical SingleDendrite neuron,\n",
    "not an idealized linear projection. This notebook explores fully hardware-faithful architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from soen_toolkit.core import (\n",
    "    ConnectionConfig,\n",
    "    LayerConfig,\n",
    "    SimulationConfig,\n",
    "    SOENModelCore,\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Circle-in-Ring Dataset\n",
    "\n",
    "Same nonlinear binary classification task as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle_ring_data(n_samples=500, inner_radius=0.3, outer_radius_min=0.5, \n",
    "                               outer_radius_max=0.8, noise=0.05):\n",
    "    \"\"\"\n",
    "    Generate 2D classification data: circle inside a ring.\n",
    "    \n",
    "    Class 0: Points inside inner circle (r < inner_radius)\n",
    "    Class 1: Points in outer ring (outer_radius_min < r < outer_radius_max)\n",
    "    \"\"\"\n",
    "    n_each = n_samples // 2\n",
    "    \n",
    "    # Class 0: Inner circle\n",
    "    theta_inner = np.random.uniform(0, 2*np.pi, n_each)\n",
    "    r_inner = np.random.uniform(0, inner_radius, n_each)\n",
    "    x_inner = r_inner * np.cos(theta_inner) + np.random.normal(0, noise, n_each)\n",
    "    y_inner = r_inner * np.sin(theta_inner) + np.random.normal(0, noise, n_each)\n",
    "    \n",
    "    # Class 1: Outer ring\n",
    "    theta_outer = np.random.uniform(0, 2*np.pi, n_each)\n",
    "    r_outer = np.random.uniform(outer_radius_min, outer_radius_max, n_each)\n",
    "    x_outer = r_outer * np.cos(theta_outer) + np.random.normal(0, noise, n_each)\n",
    "    y_outer = r_outer * np.sin(theta_outer) + np.random.normal(0, noise, n_each)\n",
    "    \n",
    "    # Combine\n",
    "    X = np.vstack([\n",
    "        np.column_stack([x_inner, y_inner]),\n",
    "        np.column_stack([x_outer, y_outer])\n",
    "    ])\n",
    "    y = np.array([0] * n_each + [1] * n_each)\n",
    "    \n",
    "    # Shuffle\n",
    "    idx = np.random.permutation(len(y))\n",
    "    X, y = X[idx], y[idx]\n",
    "    \n",
    "    # Scale to SOEN operating range [0, 0.3]\n",
    "    X = (X + 1) / 2 * 0.25 + 0.025  # Map [-1, 1] to [0.025, 0.275]\n",
    "    \n",
    "    return torch.FloatTensor(X), torch.FloatTensor(y)\n",
    "\n",
    "\n",
    "# Generate data\n",
    "N_SAMPLES = 500\n",
    "X_data, y_data = generate_circle_ring_data(N_SAMPLES)\n",
    "\n",
    "print(f\"Dataset shape: X={X_data.shape}, y={y_data.shape}\")\n",
    "print(f\"Class distribution: {(y_data == 0).sum().item()} inner, {(y_data == 1).sum().item()} outer\")\n",
    "print(f\"X range: [{X_data.min():.3f}, {X_data.max():.3f}]\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 8))\n",
    "colors = ['blue', 'red']\n",
    "for c in [0, 1]:\n",
    "    mask = y_data == c\n",
    "    label = 'Inner circle (class 0)' if c == 0 else 'Outer ring (class 1)'\n",
    "    plt.scatter(X_data[mask, 0], X_data[mask, 1], c=colors[c], \n",
    "                alpha=0.6, s=30, label=label)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Binary Classification: Circle vs Ring')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for SOEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50  # Time steps for SOEN dynamics to settle\n",
    "\n",
    "# Expand to sequence: [N, T, 2]\n",
    "X_seq = X_data.unsqueeze(1).expand(-1, SEQ_LEN, -1).clone()\n",
    "y_labels = y_data.unsqueeze(1)  # [N, 1]\n",
    "\n",
    "print(f\"SOEN input shape: {X_seq.shape}\")\n",
    "print(f\"Labels shape: {y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Builders: Linear vs SingleDendrite Readout\n",
    "\n",
    "We create two builders:\n",
    "1. **Linear readout**: Output layer is `Input` type (linear projection)\n",
    "2. **SingleDendrite readout**: Output layer is `SingleDendrite` with phi_offset=0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_linear_readout(hidden_dims, input_dim=2, dt=50.0):\n",
    "    \"\"\"\n",
    "    Build a SOEN classifier with LINEAR readout (Input layer).\n",
    "    \n",
    "    Architecture: 2 (input) → [hidden SingleDendrites] → 1 (linear readout)\n",
    "    \"\"\"\n",
    "    sim_cfg = SimulationConfig(\n",
    "        dt=dt,\n",
    "        input_type=\"state\",\n",
    "        track_phi=False,\n",
    "        track_power=False,\n",
    "    )\n",
    "    \n",
    "    layers = []\n",
    "    connections = []\n",
    "    \n",
    "    # Input layer (dim=2 for x, y)\n",
    "    layers.append(LayerConfig(\n",
    "        layer_id=0,\n",
    "        layer_type=\"Input\",\n",
    "        params={\"dim\": input_dim},\n",
    "    ))\n",
    "    \n",
    "    # Hidden layers (SingleDendrite)\n",
    "    prev_dim = input_dim\n",
    "    for i, hidden_dim in enumerate(hidden_dims):\n",
    "        layer_id = i + 1\n",
    "        \n",
    "        layers.append(LayerConfig(\n",
    "            layer_id=layer_id,\n",
    "            layer_type=\"SingleDendrite\",\n",
    "            params={\n",
    "                \"dim\": hidden_dim,\n",
    "                \"solver\": \"FE\",\n",
    "                \"source_func\": \"Heaviside_fit_state_dep\",\n",
    "                \"phi_offset\": 0.02,\n",
    "                \"bias_current\": 1.98,\n",
    "                \"gamma_plus\": 0.0005,\n",
    "                \"gamma_minus\": 1e-6,\n",
    "                \"learnable_params\": {\n",
    "                    \"phi_offset\": False,\n",
    "                    \"bias_current\": False,\n",
    "                    \"gamma_plus\": False,\n",
    "                    \"gamma_minus\": False,\n",
    "                },\n",
    "            },\n",
    "        ))\n",
    "        \n",
    "        connections.append(ConnectionConfig(\n",
    "            from_layer=layer_id - 1,\n",
    "            to_layer=layer_id,\n",
    "            connection_type=\"all_to_all\",\n",
    "            learnable=True,\n",
    "            params={\"init\": \"xavier_uniform\"},\n",
    "        ))\n",
    "        \n",
    "        prev_dim = hidden_dim\n",
    "    \n",
    "    # Output layer - LINEAR (Input type)\n",
    "    output_layer_id = len(hidden_dims) + 1\n",
    "    layers.append(LayerConfig(\n",
    "        layer_id=output_layer_id,\n",
    "        layer_type=\"Input\",  # Linear readout\n",
    "        params={\"dim\": 1},\n",
    "    ))\n",
    "    \n",
    "    connections.append(ConnectionConfig(\n",
    "        from_layer=output_layer_id - 1,\n",
    "        to_layer=output_layer_id,\n",
    "        connection_type=\"all_to_all\",\n",
    "        learnable=True,\n",
    "        params={\"init\": \"xavier_uniform\"},\n",
    "    ))\n",
    "    \n",
    "    model = SOENModelCore(\n",
    "        sim_config=sim_cfg,\n",
    "        layers_config=layers,\n",
    "        connections_config=connections,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_classifier_singledendrite_readout(hidden_dims, input_dim=2, dt=50.0, \n",
    "                                             readout_phi_offset=0.23):\n",
    "    \"\"\"\n",
    "    Build a SOEN classifier with SINGLEDENDRITE readout.\n",
    "    \n",
    "    Architecture: 2 (input) → [hidden SingleDendrites] → 1 (SingleDendrite readout)\n",
    "    \n",
    "    The readout SingleDendrite has phi_offset=0.23 (at threshold) for easier training.\n",
    "    \"\"\"\n",
    "    sim_cfg = SimulationConfig(\n",
    "        dt=dt,\n",
    "        input_type=\"state\",\n",
    "        track_phi=False,\n",
    "        track_power=False,\n",
    "    )\n",
    "    \n",
    "    layers = []\n",
    "    connections = []\n",
    "    \n",
    "    # Input layer (dim=2 for x, y)\n",
    "    layers.append(LayerConfig(\n",
    "        layer_id=0,\n",
    "        layer_type=\"Input\",\n",
    "        params={\"dim\": input_dim},\n",
    "    ))\n",
    "    \n",
    "    # Hidden layers (SingleDendrite)\n",
    "    prev_dim = input_dim\n",
    "    for i, hidden_dim in enumerate(hidden_dims):\n",
    "        layer_id = i + 1\n",
    "        \n",
    "        layers.append(LayerConfig(\n",
    "            layer_id=layer_id,\n",
    "            layer_type=\"SingleDendrite\",\n",
    "            params={\n",
    "                \"dim\": hidden_dim,\n",
    "                \"solver\": \"FE\",\n",
    "                \"source_func\": \"Heaviside_fit_state_dep\",\n",
    "                \"phi_offset\": 0.02,\n",
    "                \"bias_current\": 1.98,\n",
    "                \"gamma_plus\": 0.0005,\n",
    "                \"gamma_minus\": 1e-6,\n",
    "                \"learnable_params\": {\n",
    "                    \"phi_offset\": False,\n",
    "                    \"bias_current\": False,\n",
    "                    \"gamma_plus\": False,\n",
    "                    \"gamma_minus\": False,\n",
    "                },\n",
    "            },\n",
    "        ))\n",
    "        \n",
    "        connections.append(ConnectionConfig(\n",
    "            from_layer=layer_id - 1,\n",
    "            to_layer=layer_id,\n",
    "            connection_type=\"all_to_all\",\n",
    "            learnable=True,\n",
    "            params={\"init\": \"xavier_uniform\"},\n",
    "        ))\n",
    "        \n",
    "        prev_dim = hidden_dim\n",
    "    \n",
    "    # Output layer - SINGLEDENDRITE with phi_offset=0.23\n",
    "    output_layer_id = len(hidden_dims) + 1\n",
    "    layers.append(LayerConfig(\n",
    "        layer_id=output_layer_id,\n",
    "        layer_type=\"SingleDendrite\",  # SingleDendrite readout!\n",
    "        params={\n",
    "            \"dim\": 1,\n",
    "            \"solver\": \"FE\",\n",
    "            \"source_func\": \"Heaviside_fit_state_dep\",\n",
    "            \"phi_offset\": readout_phi_offset,  # At threshold!\n",
    "            \"bias_current\": 1.98,\n",
    "            \"gamma_plus\": 0.0005,\n",
    "            \"gamma_minus\": 1e-6,\n",
    "            \"learnable_params\": {\n",
    "                \"phi_offset\": False,\n",
    "                \"bias_current\": False,\n",
    "                \"gamma_plus\": False,\n",
    "                \"gamma_minus\": False,\n",
    "            },\n",
    "        },\n",
    "    ))\n",
    "    \n",
    "    connections.append(ConnectionConfig(\n",
    "        from_layer=output_layer_id - 1,\n",
    "        to_layer=output_layer_id,\n",
    "        connection_type=\"all_to_all\",\n",
    "        learnable=True,\n",
    "        params={\"init\": \"xavier_uniform\"},\n",
    "    ))\n",
    "    \n",
    "    model = SOENModelCore(\n",
    "        sim_config=sim_cfg,\n",
    "        layers_config=layers,\n",
    "        connections_config=connections,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Test builders\n",
    "print(\"Testing model builders...\")\n",
    "print(\"\\nLinear readout models:\")\n",
    "for hidden_dims, name in [([4], \"2→4→1\"), ([8], \"2→8→1\")]:\n",
    "    model = build_classifier_linear_readout(hidden_dims)\n",
    "    n_params = count_params(model)\n",
    "    layer_types = [l.__class__.__name__ for l in model.layers]\n",
    "    print(f\"  {name}: layers={layer_types}, params={n_params}\")\n",
    "\n",
    "print(\"\\nSingleDendrite readout models:\")\n",
    "for hidden_dims, name in [([4], \"2→4→1\"), ([8], \"2→8→1\")]:\n",
    "    model = build_classifier_singledendrite_readout(hidden_dims)\n",
    "    n_params = count_params(model)\n",
    "    layer_types = [l.__class__.__name__ for l in model.layers]\n",
    "    print(f\"  {name}: layers={layer_types}, params={n_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X_train, y_train, n_epochs=300, lr=0.02, verbose=False):\n",
    "    \"\"\"\n",
    "    Train SOEN classifier with BCE loss.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        final_hist, _ = model(X_train)\n",
    "        logits = final_hist[:, -1, :]  # [N, 1]\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(logits, y_train)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        with torch.no_grad():\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            acc = (preds == y_train).float().mean().item()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 50 == 0:\n",
    "            print(f\"  Epoch {epoch+1}: Loss={loss.item():.4f}, Acc={acc:.4f}\")\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "\n",
    "def evaluate_classifier(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate classifier and return predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_hist, _ = model(X_test)\n",
    "        logits = final_hist[:, -1, :]\n",
    "        probs = torch.sigmoid(logits).squeeze().numpy()\n",
    "        preds = (probs > 0.5).astype(float)\n",
    "    \n",
    "    y_true = y_test.squeeze().numpy()\n",
    "    accuracy = (preds == y_true).mean()\n",
    "    \n",
    "    return preds, probs, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison: Linear vs SingleDendrite Readout\n",
    "\n",
    "We compare the same hidden architectures with two different readout types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architectures to compare\n",
    "HIDDEN_CONFIGS = {\n",
    "    \"4 hidden\": [4],\n",
    "    \"8 hidden\": [8],\n",
    "    \"16 hidden\": [16],\n",
    "    \"4→4 deep\": [4, 4],\n",
    "    \"8→8 deep\": [8, 8],\n",
    "}\n",
    "\n",
    "N_EPOCHS = 400\n",
    "LR = 0.02\n",
    "\n",
    "results_linear = {}\n",
    "results_sd = {}  # SingleDendrite readout\n",
    "\n",
    "print(\"Training all architectures...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, hidden_dims in HIDDEN_CONFIGS.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Linear readout\n",
    "    model_linear = build_classifier_linear_readout(hidden_dims)\n",
    "    n_params_linear = count_params(model_linear)\n",
    "    losses_l, accs_l = train_classifier(model_linear, X_seq, y_labels, n_epochs=N_EPOCHS, lr=LR)\n",
    "    _, _, final_acc_l = evaluate_classifier(model_linear, X_seq, y_labels)\n",
    "    results_linear[name] = {\n",
    "        'hidden_dims': hidden_dims,\n",
    "        'n_params': n_params_linear,\n",
    "        'losses': losses_l,\n",
    "        'accuracies': accs_l,\n",
    "        'final_acc': final_acc_l,\n",
    "        'model': model_linear,\n",
    "    }\n",
    "    print(f\"  Linear readout:       Acc={final_acc_l:.4f}, Params={n_params_linear}\")\n",
    "    \n",
    "    # SingleDendrite readout (phi_offset=0.23)\n",
    "    model_sd = build_classifier_singledendrite_readout(hidden_dims, readout_phi_offset=0.23)\n",
    "    n_params_sd = count_params(model_sd)\n",
    "    losses_sd, accs_sd = train_classifier(model_sd, X_seq, y_labels, n_epochs=N_EPOCHS, lr=LR)\n",
    "    _, _, final_acc_sd = evaluate_classifier(model_sd, X_seq, y_labels)\n",
    "    results_sd[name] = {\n",
    "        'hidden_dims': hidden_dims,\n",
    "        'n_params': n_params_sd,\n",
    "        'losses': losses_sd,\n",
    "        'accuracies': accs_sd,\n",
    "        'final_acc': final_acc_sd,\n",
    "        'model': model_sd,\n",
    "    }\n",
    "    print(f\"  SD readout (φ=0.23): Acc={final_acc_sd:.4f}, Params={n_params_sd}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Top row: Loss curves\n",
    "ax1, ax2 = axes[0]\n",
    "\n",
    "ax1.set_title('Linear Readout - Loss')\n",
    "for name, res in results_linear.items():\n",
    "    ax1.plot(res['losses'], label=name, lw=1.5)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('BCE Loss')\n",
    "ax1.legend(fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_title('SingleDendrite Readout (φ=0.23) - Loss')\n",
    "for name, res in results_sd.items():\n",
    "    ax2.plot(res['losses'], label=name, lw=1.5)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('BCE Loss')\n",
    "ax2.legend(fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom row: Accuracy curves\n",
    "ax3, ax4 = axes[1]\n",
    "\n",
    "ax3.set_title('Linear Readout - Accuracy')\n",
    "for name, res in results_linear.items():\n",
    "    ax3.plot(res['accuracies'], label=name, lw=1.5)\n",
    "ax3.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(y=1.0, color='red', linestyle='--', alpha=0.3)\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.legend(fontsize=8)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0.4, 1.05)\n",
    "\n",
    "ax4.set_title('SingleDendrite Readout (φ=0.23) - Accuracy')\n",
    "for name, res in results_sd.items():\n",
    "    ax4.plot(res['accuracies'], label=name, lw=1.5)\n",
    "ax4.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax4.axhline(y=1.0, color='red', linestyle='--', alpha=0.3)\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.legend(fontsize=8)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_ylim(0.4, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Direct Comparison: Linear vs SingleDendrite Readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "names = list(HIDDEN_CONFIGS.keys())\n",
    "x = np.arange(len(names))\n",
    "width = 0.35\n",
    "\n",
    "linear_accs = [results_linear[n]['final_acc'] for n in names]\n",
    "sd_accs = [results_sd[n]['final_acc'] for n in names]\n",
    "\n",
    "# Bar chart comparison\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.bar(x - width/2, linear_accs, width, label='Linear Readout', color='steelblue')\n",
    "bars2 = ax1.bar(x + width/2, sd_accs, width, label='SingleDendrite Readout (φ=0.23)', color='coral')\n",
    "\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(names, rotation=30, ha='right')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Final Accuracy: Linear vs SingleDendrite Readout')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0.4, 1.05)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars1, linear_accs):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "for bar, acc in zip(bars2, sd_accs):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Difference plot\n",
    "ax2 = axes[1]\n",
    "diffs = [sd - lin for sd, lin in zip(sd_accs, linear_accs)]\n",
    "colors = ['green' if d > 0 else 'red' for d in diffs]\n",
    "bars = ax2.bar(x, diffs, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=0, color='black', linewidth=1)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(names, rotation=30, ha='right')\n",
    "ax2.set_ylabel('Accuracy Difference (SD - Linear)')\n",
    "ax2.set_title('SingleDendrite Readout Advantage')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, diff in zip(bars, diffs):\n",
    "    sign = '+' if diff > 0 else ''\n",
    "    y_pos = diff + 0.005 if diff > 0 else diff - 0.015\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, y_pos, \n",
    "             f'{sign}{diff:.3f}', ha='center', va='bottom' if diff > 0 else 'top', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Decision Boundary Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X_data, y_data, ax, title, resolution=100):\n",
    "    \"\"\"Plot decision boundary for a 2D classifier.\"\"\"\n",
    "    x_min, x_max = X_data[:, 0].min() - 0.02, X_data[:, 0].max() + 0.02\n",
    "    y_min, y_max = X_data[:, 1].min() - 0.02, X_data[:, 1].max() + 0.02\n",
    "    \n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, resolution),\n",
    "        np.linspace(y_min, y_max, resolution)\n",
    "    )\n",
    "    \n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_tensor = torch.FloatTensor(grid_points)\n",
    "    grid_seq = grid_tensor.unsqueeze(1).expand(-1, SEQ_LEN, -1).clone()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_hist, _ = model(grid_seq)\n",
    "        logits = final_hist[:, -1, :]\n",
    "        probs = torch.sigmoid(logits).squeeze().numpy()\n",
    "    \n",
    "    Z = probs.reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, levels=50, cmap='RdBu', alpha=0.7)\n",
    "    ax.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "    \n",
    "    for c, color in enumerate(['blue', 'red']):\n",
    "        mask = y_data.squeeze() == c\n",
    "        ax.scatter(X_data[mask, 0], X_data[mask, 1], c=color, \n",
    "                   s=15, alpha=0.5, edgecolors='white', linewidths=0.3)\n",
    "    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "X_np = X_data.numpy()\n",
    "y_np = y_data.numpy()\n",
    "\n",
    "# Compare decision boundaries for each architecture\n",
    "n_configs = len(HIDDEN_CONFIGS)\n",
    "fig, axes = plt.subplots(n_configs, 2, figsize=(12, 4*n_configs))\n",
    "\n",
    "for idx, name in enumerate(HIDDEN_CONFIGS.keys()):\n",
    "    ax_lin = axes[idx, 0]\n",
    "    ax_sd = axes[idx, 1]\n",
    "    \n",
    "    res_lin = results_linear[name]\n",
    "    res_sd = results_sd[name]\n",
    "    \n",
    "    plot_decision_boundary(\n",
    "        res_lin['model'], X_np, y_np, ax_lin,\n",
    "        f\"{name} - Linear Readout\\nAcc={res_lin['final_acc']:.3f}\"\n",
    "    )\n",
    "    \n",
    "    plot_decision_boundary(\n",
    "        res_sd['model'], X_np, y_np, ax_sd,\n",
    "        f\"{name} - SD Readout (φ=0.23)\\nAcc={res_sd['final_acc']:.3f}\"\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Effect of Readout phi_offset\n",
    "\n",
    "Let's test different `phi_offset` values for the readout layer to see how threshold positioning affects training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different phi_offset values for readout\n",
    "PHI_OFFSETS = [0.02, 0.10, 0.15, 0.20, 0.23, 0.25, 0.30]\n",
    "HIDDEN_DIM = [8]  # Use 8 hidden neurons\n",
    "\n",
    "phi_results = {}\n",
    "\n",
    "print(\"Testing different phi_offset values for readout layer...\")\n",
    "print(\"Hidden architecture: 2 → 8 → 1 (SingleDendrite readout)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for phi in PHI_OFFSETS:\n",
    "    model = build_classifier_singledendrite_readout(HIDDEN_DIM, readout_phi_offset=phi)\n",
    "    losses, accs = train_classifier(model, X_seq, y_labels, n_epochs=N_EPOCHS, lr=LR)\n",
    "    _, _, final_acc = evaluate_classifier(model, X_seq, y_labels)\n",
    "    \n",
    "    phi_results[phi] = {\n",
    "        'losses': losses,\n",
    "        'accuracies': accs,\n",
    "        'final_acc': final_acc,\n",
    "    }\n",
    "    print(f\"  phi_offset={phi:.2f}: Final Accuracy = {final_acc:.4f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(PHI_OFFSETS)))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "for (phi, res), color in zip(phi_results.items(), colors):\n",
    "    ax1.plot(res['losses'], label=f'φ={phi:.2f}', color=color, lw=1.5)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('BCE Loss')\n",
    "ax1.set_title('Training Loss by Readout phi_offset')\n",
    "ax1.legend(fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2 = axes[1]\n",
    "for (phi, res), color in zip(phi_results.items(), colors):\n",
    "    ax2.plot(res['accuracies'], label=f'φ={phi:.2f}', color=color, lw=1.5)\n",
    "ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy by Readout phi_offset')\n",
    "ax2.legend(fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0.4, 1.05)\n",
    "\n",
    "# Final accuracy vs phi_offset\n",
    "ax3 = axes[2]\n",
    "final_accs = [phi_results[phi]['final_acc'] for phi in PHI_OFFSETS]\n",
    "ax3.plot(PHI_OFFSETS, final_accs, 'o-', markersize=10, lw=2, color='steelblue')\n",
    "ax3.axvline(x=0.23, color='red', linestyle='--', alpha=0.7, label='Threshold (0.23)')\n",
    "ax3.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Readout phi_offset')\n",
    "ax3.set_ylabel('Final Accuracy')\n",
    "ax3.set_title('Final Accuracy vs Readout phi_offset')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0.4, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Summary comparison\n",
    "summary_data = []\n",
    "for name in HIDDEN_CONFIGS.keys():\n",
    "    res_lin = results_linear[name]\n",
    "    res_sd = results_sd[name]\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Architecture': name,\n",
    "        'Hidden Neurons': sum(res_lin['hidden_dims']),\n",
    "        'Params (Linear)': res_lin['n_params'],\n",
    "        'Params (SD)': res_sd['n_params'],\n",
    "        'Acc (Linear)': f\"{res_lin['final_acc']:.4f}\",\n",
    "        'Acc (SD φ=0.23)': f\"{res_sd['final_acc']:.4f}\",\n",
    "        'Difference': f\"{res_sd['final_acc'] - res_lin['final_acc']:+.4f}\",\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"COMPARISON: LINEAR vs SINGLEDENDRITE READOUT\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nTask: Binary classification (Circle vs Ring)\")\n",
    "print(f\"SingleDendrite readout: phi_offset = 0.23 (at threshold)\")\n",
    "print(f\"Training epochs: {N_EPOCHS}\")\n",
    "print()\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CONCLUSIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Analyze results\n",
    "linear_best = max(results_linear.values(), key=lambda x: x['final_acc'])\n",
    "sd_best = max(results_sd.values(), key=lambda x: x['final_acc'])\n",
    "\n",
    "print(\"\\n1. READOUT COMPARISON:\")\n",
    "print(f\"   Best Linear Readout:       {max(r['final_acc'] for r in results_linear.values()):.4f}\")\n",
    "print(f\"   Best SD Readout (φ=0.23):  {max(r['final_acc'] for r in results_sd.values()):.4f}\")\n",
    "\n",
    "# Count wins\n",
    "sd_wins = sum(1 for n in HIDDEN_CONFIGS.keys() \n",
    "              if results_sd[n]['final_acc'] > results_linear[n]['final_acc'])\n",
    "linear_wins = len(HIDDEN_CONFIGS) - sd_wins\n",
    "\n",
    "print(f\"\\n2. WIN COUNT:\")\n",
    "print(f\"   SingleDendrite readout wins: {sd_wins}/{len(HIDDEN_CONFIGS)}\")\n",
    "print(f\"   Linear readout wins: {linear_wins}/{len(HIDDEN_CONFIGS)}\")\n",
    "\n",
    "print(\"\\n3. EFFECT OF READOUT phi_offset:\")\n",
    "best_phi = max(phi_results.keys(), key=lambda x: phi_results[x]['final_acc'])\n",
    "worst_phi = min(phi_results.keys(), key=lambda x: phi_results[x]['final_acc'])\n",
    "print(f\"   Best phi_offset:  {best_phi:.2f} (Acc={phi_results[best_phi]['final_acc']:.4f})\")\n",
    "print(f\"   Worst phi_offset: {worst_phi:.2f} (Acc={phi_results[worst_phi]['final_acc']:.4f})\")\n",
    "print(f\"   phi=0.23 (threshold): Acc={phi_results[0.23]['final_acc']:.4f}\")\n",
    "\n",
    "print(\"\\n4. HARDWARE IMPLICATIONS:\")\n",
    "print(\"   • SingleDendrite readout is more hardware-faithful\")\n",
    "print(\"   • phi_offset=0.23 places neuron at threshold for easier training\")\n",
    "print(\"   • Linear readout requires idealized hardware (perfect linear response)\")\n",
    "\n",
    "print(\"\\n5. KEY INSIGHT:\")\n",
    "if sd_wins >= linear_wins:\n",
    "    print(\"   ✓ SingleDendrite readout performs comparably or better than linear\")\n",
    "    print(\"   ✓ Hardware-faithful architectures are viable!\")\n",
    "else:\n",
    "    print(\"   Linear readout has an advantage for this task\")\n",
    "    print(\"   But SingleDendrite is still viable with proper phi_offset tuning\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Output Dynamics\n",
    "\n",
    "Let's visualize how the SingleDendrite readout neuron's state evolves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best SingleDendrite readout model\n",
    "best_sd_name = max(results_sd.keys(), key=lambda x: results_sd[x]['final_acc'])\n",
    "best_model = results_sd[best_sd_name]['model']\n",
    "\n",
    "# Get a few samples from each class\n",
    "class0_idx = torch.where(y_data == 0)[0][:3]\n",
    "class1_idx = torch.where(y_data == 1)[0][:3]\n",
    "\n",
    "sample_idx = torch.cat([class0_idx, class1_idx])\n",
    "X_samples = X_seq[sample_idx]\n",
    "y_samples = y_data[sample_idx]\n",
    "\n",
    "# Forward pass to get full history\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    output_hist, layer_states = best_model(X_samples)\n",
    "\n",
    "# Plot output dynamics\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "time_steps = np.arange(SEQ_LEN)\n",
    "\n",
    "for i, (idx, y_val) in enumerate(zip(sample_idx, y_samples)):\n",
    "    output_state = output_hist[i, :, 0].numpy()  # [T]\n",
    "    color = 'blue' if y_val == 0 else 'red'\n",
    "    label = f'Class {int(y_val)} sample' if i < 2 else None\n",
    "    ax.plot(time_steps, output_state, color=color, alpha=0.7, lw=1.5, label=label)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "ax.set_xlabel('Time Step')\n",
    "ax.set_ylabel('Readout Neuron State (s)')\n",
    "ax.set_title(f'SingleDendrite Readout Dynamics ({best_sd_name})\\nBlue=Class 0 (inner), Red=Class 1 (outer)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal output states:\")\n",
    "for i, (idx, y_val) in enumerate(zip(sample_idx, y_samples)):\n",
    "    final_state = output_hist[i, -1, 0].item()\n",
    "    prob = torch.sigmoid(torch.tensor(final_state)).item()\n",
    "    pred = 1 if prob > 0.5 else 0\n",
    "    status = '✓' if pred == y_val else '✗'\n",
    "    print(f\"  Sample {i}: True={int(y_val)}, State={final_state:.4f}, P(class1)={prob:.4f}, Pred={pred} {status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
