{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST Sliding Window + Hierarchical (14→14→10)\n",
    "\n",
    "**Two-layer hierarchical architecture** with 14 neurons per layer.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Input (8 pixels)\n",
    "       ↓\n",
    "Hidden1 (14 neurons) ←── Each neuron handles 2 adjacent rows\n",
    "       ↓ ↺ recurrent\n",
    "Hidden2 (14 neurons) ←── Processes Hidden1 output\n",
    "       ↓ ↺ recurrent\n",
    "Output (10 neurons)\n",
    "```\n",
    "\n",
    "## Row Assignment\n",
    "\n",
    "- Neuron 0: rows 0-1\n",
    "- Neuron 1: rows 2-3\n",
    "- ...\n",
    "- Neuron 13: rows 26-27\n",
    "\n",
    "Each Hidden1 neuron receives 2×8 = 16 inputs (2 rows × 8 window pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KEY HYPERPARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "# Sliding window\n",
    "WINDOW_SIZE = 8\n",
    "N_ROW_STEPS = 20\n",
    "N_COL_STEPS = 20\n",
    "STEPS_PER_SWEEP = N_ROW_STEPS + N_COL_STEPS  # 40\n",
    "\n",
    "# Timing\n",
    "N_INPUT_STEPS = 100\n",
    "N_SETTLE_STEPS = 1\n",
    "OUTPUT_STEP = 101\n",
    "\n",
    "# HIERARCHICAL: Two layers with 14 neurons each\n",
    "HIDDEN1_DIM = 14  # First hidden layer\n",
    "HIDDEN2_DIM = 14  # Second hidden layer\n",
    "ROWS_PER_NEURON = 2  # 28 rows / 14 neurons = 2 rows each\n",
    "\n",
    "OUTPUT_DIM = 10\n",
    "\n",
    "# SOEN dynamics\n",
    "DT = 0.1\n",
    "GAMMA_PLUS = 0.1\n",
    "GAMMA_MINUS = 0.01\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 0.005\n",
    "\n",
    "print(f\"Hierarchical: {HIDDEN1_DIM} → {HIDDEN2_DIM} → {OUTPUT_DIM}\")\n",
    "print(f\"Each Hidden1 neuron: {ROWS_PER_NEURON} rows × {WINDOW_SIZE} pixels = {ROWS_PER_NEURON * WINDOW_SIZE} inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "def load_mnist():\n",
    "    train_img = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    train_lbl = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_img = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    test_lbl = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(train_img))\n",
    "    n_val = 6000\n",
    "    \n",
    "    val_img, val_lbl = train_img[idx[:n_val]], train_lbl[idx[:n_val]]\n",
    "    train_img, train_lbl = train_img[idx[n_val:]], train_lbl[idx[n_val:]]\n",
    "    \n",
    "    print(f\"Train: {train_img.shape}, Val: {val_img.shape}, Test: {test_img.shape}\")\n",
    "    return (train_img, train_lbl), (val_img, val_lbl), (test_img, test_lbl)\n",
    "\n",
    "(train_data, train_labels), (val_data, val_labels), (test_data, test_labels) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Hierarchical Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_architecture():\n",
    "    \"\"\"Visualize the hierarchical architecture.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Left: Row assignment\n",
    "    ax = axes[0]\n",
    "    row_colors = np.zeros((28, 28))\n",
    "    for neuron in range(14):\n",
    "        row_start = neuron * 2\n",
    "        row_end = row_start + 2\n",
    "        row_colors[row_start:row_end, :] = neuron\n",
    "    \n",
    "    ax.imshow(row_colors, cmap='tab20', aspect='auto')\n",
    "    ax.set_xlabel('Column')\n",
    "    ax.set_ylabel('Row')\n",
    "    ax.set_title('Row → Hidden1 Neuron Assignment')\n",
    "    \n",
    "    # Add neuron labels\n",
    "    for neuron in range(14):\n",
    "        row = neuron * 2 + 0.5\n",
    "        ax.text(29, row, f'N{neuron}', va='center', fontsize=8)\n",
    "    \n",
    "    # Right: Architecture diagram\n",
    "    ax = axes[1]\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    \n",
    "    # Layers\n",
    "    layers = [\n",
    "        {'name': 'Input', 'x': 1, 'y': 5, 'size': '8 px', 'color': 'lightblue'},\n",
    "        {'name': 'Hidden1', 'x': 4, 'y': 5, 'size': '14', 'color': 'lightgreen'},\n",
    "        {'name': 'Hidden2', 'x': 7, 'y': 5, 'size': '14', 'color': 'lightyellow'},\n",
    "        {'name': 'Output', 'x': 10, 'y': 5, 'size': '10', 'color': 'lightcoral'},\n",
    "    ]\n",
    "    \n",
    "    for layer in layers:\n",
    "        circle = plt.Circle((layer['x'], layer['y']), 0.8, \n",
    "                            color=layer['color'], ec='black', linewidth=2)\n",
    "        ax.add_patch(circle)\n",
    "        ax.text(layer['x'], layer['y'], layer['size'], ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "        ax.text(layer['x'], layer['y'] - 1.3, layer['name'], ha='center', fontsize=10)\n",
    "    \n",
    "    # Arrows\n",
    "    for i in range(len(layers) - 1):\n",
    "        ax.annotate('', xy=(layers[i+1]['x'] - 0.9, layers[i+1]['y']),\n",
    "                    xytext=(layers[i]['x'] + 0.9, layers[i]['y']),\n",
    "                    arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "    \n",
    "    # Recurrent arrows\n",
    "    for layer in layers[1:3]:  # Hidden1 and Hidden2\n",
    "        ax.annotate('', xy=(layer['x'] - 0.3, layer['y'] + 0.9),\n",
    "                    xytext=(layer['x'] + 0.3, layer['y'] + 0.9),\n",
    "                    arrowprops=dict(arrowstyle='->', color='blue', lw=1.5,\n",
    "                                    connectionstyle='arc3,rad=-0.5'))\n",
    "    \n",
    "    ax.text(4, 6.5, 'recurrent', fontsize=8, color='blue', ha='center')\n",
    "    ax.text(7, 6.5, 'recurrent', fontsize=8, color='blue', ha='center')\n",
    "    \n",
    "    ax.set_xlim(-0.5, 11.5)\n",
    "    ax.set_ylim(2, 8)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Hierarchical Architecture: 14 → 14 → 10')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nArchitecture summary:\")\n",
    "    print(f\"  Input: {WINDOW_SIZE} pixels (sliding window)\")\n",
    "    print(f\"  Hidden1: {HIDDEN1_DIM} neurons (each handles {ROWS_PER_NEURON} rows)\")\n",
    "    print(f\"  Hidden2: {HIDDEN2_DIM} neurons (processes Hidden1 output)\")\n",
    "    print(f\"  Output: {OUTPUT_DIM} neurons\")\n",
    "    print(f\"\\nConnections:\")\n",
    "    print(f\"  Input → Hidden1: each neuron gets {ROWS_PER_NEURON}×{WINDOW_SIZE}={ROWS_PER_NEURON*WINDOW_SIZE} inputs\")\n",
    "    print(f\"  Hidden1 → Hidden2: 14 → 14 (dense)\")\n",
    "    print(f\"  Hidden2 → Output: 14 → 10 (dense)\")\n",
    "\n",
    "visualize_architecture()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical Sliding Window SOEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalSlidingSOEN(nn.Module):\n",
    "    \"\"\"\n",
    "    Two-layer hierarchical SOEN with sliding window input.\n",
    "    \n",
    "    Architecture: Input → Hidden1 (14) → Hidden2 (14) → Output (10)\n",
    "    \n",
    "    Each Hidden1 neuron handles 2 adjacent rows of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden1_dim=14, hidden2_dim=14, window_size=8, output_dim=10,\n",
    "                 rows_per_neuron=2, n_row_steps=20, n_col_steps=20,\n",
    "                 n_input_steps=100, n_settle_steps=1, output_step=101,\n",
    "                 dt=0.1, gamma_plus=0.1, gamma_minus=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "        self.window_size = window_size\n",
    "        self.output_dim = output_dim\n",
    "        self.rows_per_neuron = rows_per_neuron\n",
    "        self.input_per_neuron = rows_per_neuron * window_size  # 2 * 8 = 16\n",
    "        self.n_row_steps = n_row_steps\n",
    "        self.n_col_steps = n_col_steps\n",
    "        self.steps_per_sweep = n_row_steps + n_col_steps\n",
    "        self.n_input_steps = n_input_steps\n",
    "        self.n_settle_steps = n_settle_steps\n",
    "        self.output_step = output_step\n",
    "        self.dt = dt\n",
    "        self.gamma_plus = gamma_plus\n",
    "        self.gamma_minus = gamma_minus\n",
    "        \n",
    "        # Layer 1 weights: Input → Hidden1\n",
    "        # Each neuron gets rows_per_neuron × window_size inputs\n",
    "        self.W_i2h1 = nn.Parameter(torch.empty(hidden1_dim, self.input_per_neuron))  # (14, 16)\n",
    "        self.W_h1h1 = nn.Parameter(torch.empty(hidden1_dim, hidden1_dim))  # (14, 14) recurrent\n",
    "        self.bias_h1 = nn.Parameter(torch.zeros(hidden1_dim))\n",
    "        \n",
    "        # Layer 2 weights: Hidden1 → Hidden2\n",
    "        self.W_h1h2 = nn.Parameter(torch.empty(hidden2_dim, hidden1_dim))  # (14, 14)\n",
    "        self.W_h2h2 = nn.Parameter(torch.empty(hidden2_dim, hidden2_dim))  # (14, 14) recurrent\n",
    "        self.bias_h2 = nn.Parameter(torch.zeros(hidden2_dim))\n",
    "        \n",
    "        # Output weights: Hidden2 → Output\n",
    "        self.W_h2o = nn.Parameter(torch.empty(output_dim, hidden2_dim))  # (10, 14)\n",
    "        self.bias_o = nn.Parameter(torch.zeros(output_dim))\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.uniform_(self.W_i2h1, -0.2, 0.2)\n",
    "        nn.init.normal_(self.W_h1h1, 0, 0.1)\n",
    "        nn.init.normal_(self.W_h1h2, 0, 0.15)\n",
    "        nn.init.normal_(self.W_h2h2, 0, 0.1)\n",
    "        nn.init.normal_(self.W_h2o, 0, 0.2)\n",
    "        with torch.no_grad():\n",
    "            self.W_h1h1.fill_diagonal_(0)\n",
    "            self.W_h2h2.fill_diagonal_(0)\n",
    "    \n",
    "    def source_function(self, phi):\n",
    "        return torch.sigmoid(5 * phi)\n",
    "    \n",
    "    def get_hierarchical_input(self, images, step):\n",
    "        \"\"\"\n",
    "        Extract input for hierarchical layer.\n",
    "        \n",
    "        Each of 14 neurons gets 2 adjacent rows × 8 pixel window = 16 inputs.\n",
    "        \n",
    "        Returns: (batch, 14, 16)\n",
    "        \"\"\"\n",
    "        batch_size = images.shape[0]\n",
    "        step_in_sweep = step % self.steps_per_sweep\n",
    "        \n",
    "        if step_in_sweep < self.n_row_steps:\n",
    "            # ROW PHASE\n",
    "            window_start = step_in_sweep\n",
    "            window_end = min(window_start + self.window_size, 28)\n",
    "            window_start = window_end - self.window_size\n",
    "            \n",
    "            # Get window for all rows: (batch, 28, 8)\n",
    "            all_windows = images[:, :, window_start:window_end]\n",
    "            \n",
    "            # Group into pairs of rows for each neuron\n",
    "            # Reshape: (batch, 14, 2, 8) then flatten last two dims → (batch, 14, 16)\n",
    "            grouped = all_windows.reshape(batch_size, self.hidden1_dim, self.rows_per_neuron, self.window_size)\n",
    "            hierarchical_input = grouped.reshape(batch_size, self.hidden1_dim, -1)\n",
    "            \n",
    "        else:\n",
    "            # COLUMN PHASE\n",
    "            col_step = step_in_sweep - self.n_row_steps\n",
    "            window_start = col_step\n",
    "            window_end = min(window_start + self.window_size, 28)\n",
    "            window_start = window_end - self.window_size\n",
    "            \n",
    "            # Get window for all columns: (batch, 8, 28) then transpose → (batch, 28, 8)\n",
    "            all_windows = images[:, window_start:window_end, :].transpose(1, 2)\n",
    "            \n",
    "            # Group into pairs\n",
    "            grouped = all_windows.reshape(batch_size, self.hidden1_dim, self.rows_per_neuron, self.window_size)\n",
    "            hierarchical_input = grouped.reshape(batch_size, self.hidden1_dim, -1)\n",
    "        \n",
    "        return hierarchical_input  # (batch, 14, 16)\n",
    "    \n",
    "    def step(self, s1, s2, h_input=None):\n",
    "        \"\"\"\n",
    "        Single timestep update for both hidden layers.\n",
    "        \n",
    "        Args:\n",
    "            s1: Hidden1 state (batch, 14)\n",
    "            s2: Hidden2 state (batch, 14)\n",
    "            h_input: Hierarchical input (batch, 14, 16) or None\n",
    "        \n",
    "        Returns:\n",
    "            s1_new, s2_new\n",
    "        \"\"\"\n",
    "        # LAYER 1 UPDATE\n",
    "        if h_input is not None:\n",
    "            # Each neuron applies its weights to its 16 inputs\n",
    "            # h_input: (batch, 14, 16), W_i2h1: (14, 16)\n",
    "            input_contrib1 = (h_input * self.W_i2h1.unsqueeze(0)).sum(dim=2)  # (batch, 14)\n",
    "        else:\n",
    "            input_contrib1 = 0\n",
    "        \n",
    "        recurrent1 = F.linear(s1, self.W_h1h1)\n",
    "        phi1 = input_contrib1 + recurrent1 + self.bias_h1\n",
    "        g1 = self.source_function(phi1)\n",
    "        ds1 = self.gamma_plus * g1 - self.gamma_minus * s1\n",
    "        s1_new = s1 + self.dt * ds1\n",
    "        \n",
    "        # LAYER 2 UPDATE (receives from layer 1)\n",
    "        forward12 = F.linear(s1_new, self.W_h1h2)  # (batch, 14)\n",
    "        recurrent2 = F.linear(s2, self.W_h2h2)\n",
    "        phi2 = forward12 + recurrent2 + self.bias_h2\n",
    "        g2 = self.source_function(phi2)\n",
    "        ds2 = self.gamma_plus * g2 - self.gamma_minus * s2\n",
    "        s2_new = s2 + self.dt * ds2\n",
    "        \n",
    "        return s1_new, s2_new\n",
    "    \n",
    "    def forward(self, images, return_all=False):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \"\"\"\n",
    "        batch_size = images.shape[0]\n",
    "        \n",
    "        # Initialize states\n",
    "        s1 = torch.zeros(batch_size, self.hidden1_dim, device=images.device)\n",
    "        s2 = torch.zeros(batch_size, self.hidden2_dim, device=images.device)\n",
    "        \n",
    "        all_outputs = []\n",
    "        all_s1 = [] if return_all else None\n",
    "        all_s2 = [] if return_all else None\n",
    "        \n",
    "        # INPUT PHASE\n",
    "        for t in range(self.n_input_steps):\n",
    "            h_input = self.get_hierarchical_input(images, t)\n",
    "            s1, s2 = self.step(s1, s2, h_input)\n",
    "            output = F.linear(s2, self.W_h2o, self.bias_o)\n",
    "            all_outputs.append(output)\n",
    "            \n",
    "            if return_all:\n",
    "                all_s1.append(s1.clone())\n",
    "                all_s2.append(s2.clone())\n",
    "        \n",
    "        # SETTLE PHASE\n",
    "        for t in range(self.n_settle_steps):\n",
    "            s1, s2 = self.step(s1, s2, h_input=None)\n",
    "            output = F.linear(s2, self.W_h2o, self.bias_o)\n",
    "            all_outputs.append(output)\n",
    "            \n",
    "            if return_all:\n",
    "                all_s1.append(s1.clone())\n",
    "                all_s2.append(s2.clone())\n",
    "        \n",
    "        # Get output at specified step\n",
    "        output_idx = min(self.output_step - 1, len(all_outputs) - 1)\n",
    "        final_output = all_outputs[output_idx]\n",
    "        \n",
    "        return final_output, {\n",
    "            'all_outputs': all_outputs,\n",
    "            'all_s1': all_s1,\n",
    "            'all_s2': all_s2,\n",
    "            'final_s1': s1,\n",
    "            'final_s2': s2\n",
    "        }\n",
    "\n",
    "# Create model\n",
    "model = HierarchicalSlidingSOEN(\n",
    "    hidden1_dim=HIDDEN1_DIM,\n",
    "    hidden2_dim=HIDDEN2_DIM,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    rows_per_neuron=ROWS_PER_NEURON,\n",
    "    n_row_steps=N_ROW_STEPS,\n",
    "    n_col_steps=N_COL_STEPS,\n",
    "    n_input_steps=N_INPUT_STEPS,\n",
    "    n_settle_steps=N_SETTLE_STEPS,\n",
    "    output_step=OUTPUT_STEP,\n",
    "    dt=DT,\n",
    "    gamma_plus=GAMMA_PLUS,\n",
    "    gamma_minus=GAMMA_MINUS\n",
    ").to(device)\n",
    "\n",
    "print(f\"Hierarchical Model Created\")\n",
    "print(f\"  W_i2h1: {model.W_i2h1.shape} (input → hidden1)\")\n",
    "print(f\"  W_h1h1: {model.W_h1h1.shape} (hidden1 recurrent)\")\n",
    "print(f\"  W_h1h2: {model.W_h1h2.shape} (hidden1 → hidden2)\")\n",
    "print(f\"  W_h2h2: {model.W_h2h2.shape} (hidden2 recurrent)\")\n",
    "print(f\"  W_h2o:  {model.W_h2o.shape} (hidden2 → output)\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                epochs=30, batch_size=128, lr=0.005):\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_data, dtype=torch.float32),\n",
    "        torch.tensor(train_labels, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(val_data, dtype=torch.float32),\n",
    "        torch.tensor(val_labels, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"HIERARCHICAL SLIDING WINDOW TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Architecture: {model.hidden1_dim} → {model.hidden2_dim} → {model.output_dim}\")\n",
    "    print(f\"Each Hidden1 neuron: {model.rows_per_neuron} rows × {model.window_size} pixels\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for x, labels in pbar:\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(x)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.W_h1h1.fill_diagonal_(0)\n",
    "                model.W_h2h2.fill_diagonal_(0)\n",
    "            \n",
    "            pred = output.argmax(dim=1)\n",
    "            epoch_correct += (pred == labels).sum().item()\n",
    "            epoch_total += len(labels)\n",
    "            epoch_loss += loss.item() * len(labels)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{epoch_correct/epoch_total:.3f}'})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss = epoch_loss / epoch_total\n",
    "        train_acc = epoch_correct / epoch_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, labels in val_loader:\n",
    "                x, labels = x.to(device), labels.to(device)\n",
    "                output, _ = model(x)\n",
    "                loss = F.cross_entropy(output, labels)\n",
    "                val_loss += loss.item() * len(labels)\n",
    "                val_correct += (output.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += len(labels)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, \"\n",
    "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f} {'*' if val_acc == best_val_acc else ''}\")\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                      epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss (Hierarchical 14→14)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy (Hierarchical 14→14)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_data, dtype=torch.float32),\n",
    "        torch.tensor(test_labels, dtype=torch.long)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for x, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        output, _ = model(x)\n",
    "        all_preds.append(output.argmax(dim=1).cpu())\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY (Hierarchical 14→14): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "test_acc = evaluate(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Layer Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layers(model, image, label):\n",
    "    \"\"\"Visualize activations in both hidden layers.\"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output, states = model(x, return_all=True)\n",
    "    \n",
    "    all_s1 = torch.stack(states['all_s1']).squeeze().cpu().numpy()\n",
    "    all_s2 = torch.stack(states['all_s2']).squeeze().cpu().numpy()\n",
    "    all_outputs = torch.stack(states['all_outputs']).squeeze().cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(image, cmap='gray')\n",
    "    axes[0, 0].set_title(f'Input (Label: {label})')\n",
    "    \n",
    "    # Hidden1 activations\n",
    "    im1 = axes[0, 1].imshow(all_s1.T, aspect='auto', cmap='viridis')\n",
    "    axes[0, 1].set_xlabel('Timestep')\n",
    "    axes[0, 1].set_ylabel('Hidden1 Neuron')\n",
    "    axes[0, 1].set_title('Hidden Layer 1 (14 neurons)')\n",
    "    plt.colorbar(im1, ax=axes[0, 1])\n",
    "    \n",
    "    # Hidden2 activations\n",
    "    im2 = axes[1, 0].imshow(all_s2.T, aspect='auto', cmap='viridis')\n",
    "    axes[1, 0].set_xlabel('Timestep')\n",
    "    axes[1, 0].set_ylabel('Hidden2 Neuron')\n",
    "    axes[1, 0].set_title('Hidden Layer 2 (14 neurons)')\n",
    "    plt.colorbar(im2, ax=axes[1, 0])\n",
    "    \n",
    "    # Output evolution\n",
    "    for i in range(10):\n",
    "        axes[1, 1].plot(all_outputs[:, i], label=f'{i}', alpha=0.7)\n",
    "    axes[1, 1].axvline(x=model.n_input_steps - 0.5, color='green', linestyle='--')\n",
    "    axes[1, 1].set_xlabel('Timestep')\n",
    "    axes[1, 1].set_ylabel('Logit')\n",
    "    axes[1, 1].set_title('Output Evolution')\n",
    "    axes[1, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    plt.suptitle(f'Hierarchical Network Activations (True: {label}, Pred: {output.argmax().item()})',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for i in range(3):\n",
    "    visualize_layers(model, test_data[i], test_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | Single Layer (28) | Hierarchical (14→14) |\n",
    "|--------|------------------|----------------------|\n",
    "| Hidden neurons | 28 | 14 + 14 = 28 |\n",
    "| Layers | 1 | 2 |\n",
    "| Input per neuron | 8 | 16 (2 rows × 8) |\n",
    "| Feature hierarchy | None | Low → High level |\n",
    "\n",
    "### Why Hierarchical Helps\n",
    "\n",
    "1. **Feature composition**: Layer 2 learns combinations of Layer 1 features\n",
    "2. **Grouped input**: Each neuron sees 2 adjacent rows (local receptive field)\n",
    "3. **More processing depth**: Gradients flow through 2 layers of dynamics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
