{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST Sliding Window + Temporal Ensemble\n",
    "\n",
    "**Improvement over sliding window**: Take output every 20 steps and ensemble (mean).\n",
    "\n",
    "## Ensemble Strategy\n",
    "\n",
    "```\n",
    "Step 20  → Output₁ ──┐\n",
    "Step 40  → Output₂ ──┼── Mean → Final Prediction\n",
    "Step 60  → Output₃ ──┤\n",
    "Step 80  → Output₄ ──┤\n",
    "Step 100 → Output₅ ──┤\n",
    "Step 101 → Output₆ ──┘\n",
    "```\n",
    "\n",
    "## Why This Helps\n",
    "\n",
    "- Different timesteps capture different integration states\n",
    "- Averaging reduces variance\n",
    "- Mistakes at one timestep can be corrected by others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KEY HYPERPARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "# Sliding window\n",
    "WINDOW_SIZE = 8\n",
    "N_ROW_STEPS = 20\n",
    "N_COL_STEPS = 20\n",
    "STEPS_PER_SWEEP = N_ROW_STEPS + N_COL_STEPS  # 40\n",
    "\n",
    "# Timing\n",
    "N_INPUT_STEPS = 100\n",
    "N_SETTLE_STEPS = 1\n",
    "\n",
    "# ENSEMBLE: Take output every ENSEMBLE_INTERVAL steps\n",
    "ENSEMBLE_INTERVAL = 20\n",
    "# This gives outputs at steps: 20, 40, 60, 80, 100, 101\n",
    "\n",
    "# Network\n",
    "HIDDEN_DIM = 28\n",
    "INPUT_DIM = WINDOW_SIZE\n",
    "OUTPUT_DIM = 10\n",
    "\n",
    "# SOEN dynamics\n",
    "DT = 0.1\n",
    "GAMMA_PLUS = 0.1\n",
    "GAMMA_MINUS = 0.01\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 0.005\n",
    "\n",
    "# Calculate ensemble steps\n",
    "ensemble_steps = list(range(ENSEMBLE_INTERVAL, N_INPUT_STEPS + 1, ENSEMBLE_INTERVAL))\n",
    "ensemble_steps.append(N_INPUT_STEPS + N_SETTLE_STEPS)  # Add final settle step\n",
    "print(f\"Ensemble at steps: {ensemble_steps}\")\n",
    "print(f\"Number of ensemble members: {len(ensemble_steps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "def load_mnist():\n",
    "    train_img = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    train_lbl = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_img = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    test_lbl = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(train_img))\n",
    "    n_val = 6000\n",
    "    \n",
    "    val_img, val_lbl = train_img[idx[:n_val]], train_lbl[idx[:n_val]]\n",
    "    train_img, train_lbl = train_img[idx[n_val:]], train_lbl[idx[n_val:]]\n",
    "    \n",
    "    print(f\"Train: {train_img.shape}, Val: {val_img.shape}, Test: {test_img.shape}\")\n",
    "    return (train_img, train_lbl), (val_img, val_lbl), (test_img, test_lbl)\n",
    "\n",
    "(train_data, train_labels), (val_data, val_labels), (test_data, test_labels) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Ensemble Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ensemble_strategy():\n",
    "    \"\"\"Visualize which timesteps are used for ensemble.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    \n",
    "    total_steps = N_INPUT_STEPS + N_SETTLE_STEPS\n",
    "    \n",
    "    # Draw sweeps\n",
    "    for sweep in range(3):\n",
    "        start = sweep * STEPS_PER_SWEEP\n",
    "        if start >= N_INPUT_STEPS:\n",
    "            break\n",
    "        \n",
    "        # Row phase\n",
    "        row_end = min(start + N_ROW_STEPS, N_INPUT_STEPS)\n",
    "        if row_end > start:\n",
    "            ax.barh(0, row_end - start, left=start, height=0.4, \n",
    "                    color='blue', alpha=0.5, edgecolor='black')\n",
    "        \n",
    "        # Column phase\n",
    "        col_start = start + N_ROW_STEPS\n",
    "        col_end = min(col_start + N_COL_STEPS, N_INPUT_STEPS)\n",
    "        if col_end > col_start:\n",
    "            ax.barh(0, col_end - col_start, left=col_start, height=0.4,\n",
    "                    color='orange', alpha=0.5, edgecolor='black')\n",
    "    \n",
    "    # Settle phase\n",
    "    ax.barh(0, N_SETTLE_STEPS, left=N_INPUT_STEPS, height=0.4,\n",
    "            color='green', alpha=0.5, edgecolor='black')\n",
    "    \n",
    "    # Mark ensemble steps\n",
    "    for i, step in enumerate(ensemble_steps):\n",
    "        ax.axvline(x=step - 0.5, color='red', linewidth=2, linestyle='--')\n",
    "        ax.scatter([step - 0.5], [0], color='red', s=150, zorder=5, marker='v')\n",
    "        ax.text(step - 0.5, 0.35, f'E{i+1}\\n(step {step})', ha='center', fontsize=8, \n",
    "                color='red', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlim(-1, total_steps + 2)\n",
    "    ax.set_ylim(-0.5, 0.6)\n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_title(f'Temporal Ensemble: Average outputs from {len(ensemble_steps)} timesteps')\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='blue', alpha=0.5, label='Row phase'),\n",
    "        Patch(facecolor='orange', alpha=0.5, label='Col phase'),\n",
    "        Patch(facecolor='green', alpha=0.5, label='Settle'),\n",
    "        Patch(facecolor='red', label='Ensemble output'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nEnsemble strategy:\")\n",
    "    print(f\"  • Take output every {ENSEMBLE_INTERVAL} steps\")\n",
    "    print(f\"  • Ensemble steps: {ensemble_steps}\")\n",
    "    print(f\"  • Final prediction = mean of {len(ensemble_steps)} outputs\")\n",
    "\n",
    "visualize_ensemble_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sliding Window SOEN with Temporal Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowEnsembleSOEN(nn.Module):\n",
    "    \"\"\"\n",
    "    SOEN model with sliding window input and temporal ensemble.\n",
    "    \n",
    "    Takes output every `ensemble_interval` steps and averages for final prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=28, window_size=8, output_dim=10,\n",
    "                 n_row_steps=20, n_col_steps=20,\n",
    "                 n_input_steps=100, n_settle_steps=1,\n",
    "                 ensemble_interval=20,\n",
    "                 dt=0.1, gamma_plus=0.1, gamma_minus=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.window_size = window_size\n",
    "        self.output_dim = output_dim\n",
    "        self.n_row_steps = n_row_steps\n",
    "        self.n_col_steps = n_col_steps\n",
    "        self.steps_per_sweep = n_row_steps + n_col_steps\n",
    "        self.n_input_steps = n_input_steps\n",
    "        self.n_settle_steps = n_settle_steps\n",
    "        self.ensemble_interval = ensemble_interval\n",
    "        self.dt = dt\n",
    "        self.gamma_plus = gamma_plus\n",
    "        self.gamma_minus = gamma_minus\n",
    "        \n",
    "        # Pre-compute ensemble steps (1-indexed)\n",
    "        self.ensemble_steps = list(range(ensemble_interval, n_input_steps + 1, ensemble_interval))\n",
    "        self.ensemble_steps.append(n_input_steps + n_settle_steps)\n",
    "        \n",
    "        # Weights\n",
    "        self.W_i2h = nn.Parameter(torch.empty(hidden_dim, window_size))\n",
    "        self.W_h2h = nn.Parameter(torch.empty(hidden_dim, hidden_dim))\n",
    "        self.W_h2o = nn.Parameter(torch.empty(output_dim, hidden_dim))\n",
    "        self.bias_h = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.bias_o = nn.Parameter(torch.zeros(output_dim))\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.uniform_(self.W_i2h, -0.2, 0.2)\n",
    "        nn.init.normal_(self.W_h2h, 0, 0.1)\n",
    "        nn.init.normal_(self.W_h2o, 0, 0.2)\n",
    "        with torch.no_grad():\n",
    "            self.W_h2h.fill_diagonal_(0)\n",
    "    \n",
    "    def source_function(self, phi):\n",
    "        return torch.sigmoid(5 * phi)\n",
    "    \n",
    "    def get_window_input(self, images, step):\n",
    "        \"\"\"Extract 8-pixel window for each neuron.\"\"\"\n",
    "        step_in_sweep = step % self.steps_per_sweep\n",
    "        \n",
    "        if step_in_sweep < self.n_row_steps:\n",
    "            window_start = step_in_sweep\n",
    "            window_end = min(window_start + self.window_size, 28)\n",
    "            window_start = window_end - self.window_size\n",
    "            window = images[:, :, window_start:window_end]\n",
    "        else:\n",
    "            col_step = step_in_sweep - self.n_row_steps\n",
    "            window_start = col_step\n",
    "            window_end = min(window_start + self.window_size, 28)\n",
    "            window_start = window_end - self.window_size\n",
    "            window = images[:, window_start:window_end, :].transpose(1, 2)\n",
    "        \n",
    "        return window\n",
    "    \n",
    "    def step(self, s, window_input=None):\n",
    "        \"\"\"Single timestep update.\"\"\"\n",
    "        if window_input is not None:\n",
    "            input_contrib = (window_input * self.W_i2h.unsqueeze(0)).sum(dim=2)\n",
    "        else:\n",
    "            input_contrib = 0\n",
    "        \n",
    "        recurrent_contrib = F.linear(s, self.W_h2h)\n",
    "        phi = input_contrib + recurrent_contrib + self.bias_h\n",
    "        \n",
    "        g = self.source_function(phi)\n",
    "        dsdt = self.gamma_plus * g - self.gamma_minus * s\n",
    "        s_new = s + self.dt * dsdt\n",
    "        \n",
    "        return s_new\n",
    "    \n",
    "    def forward(self, images, return_all=False):\n",
    "        \"\"\"\n",
    "        Forward pass with temporal ensemble.\n",
    "        \n",
    "        Args:\n",
    "            images: (batch, 28, 28)\n",
    "            return_all: If True, return all individual outputs\n",
    "        \n",
    "        Returns:\n",
    "            output: Ensembled output (batch, 10)\n",
    "            states: Dict with intermediate states\n",
    "        \"\"\"\n",
    "        batch_size = images.shape[0]\n",
    "        s = torch.zeros(batch_size, self.hidden_dim, device=images.device)\n",
    "        \n",
    "        all_states = []\n",
    "        all_outputs = []\n",
    "        ensemble_outputs = []  # Outputs at ensemble steps\n",
    "        \n",
    "        current_step = 0\n",
    "        \n",
    "        # INPUT PHASE\n",
    "        for t in range(self.n_input_steps):\n",
    "            window = self.get_window_input(images, t)\n",
    "            s = self.step(s, window)\n",
    "            current_step += 1\n",
    "            \n",
    "            output = F.linear(s, self.W_h2o, self.bias_o)\n",
    "            all_outputs.append(output)\n",
    "            \n",
    "            # Check if this is an ensemble step\n",
    "            if current_step in self.ensemble_steps:\n",
    "                ensemble_outputs.append(output)\n",
    "            \n",
    "            if return_all:\n",
    "                all_states.append(s.clone())\n",
    "        \n",
    "        # SETTLE PHASE\n",
    "        for t in range(self.n_settle_steps):\n",
    "            s = self.step(s, window_input=None)\n",
    "            current_step += 1\n",
    "            \n",
    "            output = F.linear(s, self.W_h2o, self.bias_o)\n",
    "            all_outputs.append(output)\n",
    "            \n",
    "            if current_step in self.ensemble_steps:\n",
    "                ensemble_outputs.append(output)\n",
    "            \n",
    "            if return_all:\n",
    "                all_states.append(s.clone())\n",
    "        \n",
    "        # ENSEMBLE: Average outputs from all ensemble steps\n",
    "        ensemble_stack = torch.stack(ensemble_outputs, dim=0)  # (n_ensemble, batch, 10)\n",
    "        ensembled_output = ensemble_stack.mean(dim=0)  # (batch, 10)\n",
    "        \n",
    "        return ensembled_output, {\n",
    "            'all_outputs': all_outputs,\n",
    "            'ensemble_outputs': ensemble_outputs,\n",
    "            'ensemble_steps': self.ensemble_steps,\n",
    "            'all_states': all_states if return_all else None,\n",
    "            'final_state': s\n",
    "        }\n",
    "\n",
    "# Create model\n",
    "model = SlidingWindowEnsembleSOEN(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_row_steps=N_ROW_STEPS,\n",
    "    n_col_steps=N_COL_STEPS,\n",
    "    n_input_steps=N_INPUT_STEPS,\n",
    "    n_settle_steps=N_SETTLE_STEPS,\n",
    "    ensemble_interval=ENSEMBLE_INTERVAL,\n",
    "    dt=DT,\n",
    "    gamma_plus=GAMMA_PLUS,\n",
    "    gamma_minus=GAMMA_MINUS\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created with temporal ensemble\")\n",
    "print(f\"  Ensemble steps: {model.ensemble_steps}\")\n",
    "print(f\"  Number of ensemble members: {len(model.ensemble_steps)}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                epochs=30, batch_size=128, lr=0.005):\n",
    "    \"\"\"\n",
    "    Train the ensemble SOEN model.\n",
    "    \"\"\"\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_data, dtype=torch.float32),\n",
    "        torch.tensor(train_labels, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(val_data, dtype=torch.float32),\n",
    "        torch.tensor(val_labels, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"SLIDING WINDOW + TEMPORAL ENSEMBLE TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Ensemble steps: {model.ensemble_steps}\")\n",
    "    print(f\"Ensemble members: {len(model.ensemble_steps)}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for x, labels in pbar:\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(x)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.W_h2h.fill_diagonal_(0)\n",
    "            \n",
    "            pred = output.argmax(dim=1)\n",
    "            epoch_correct += (pred == labels).sum().item()\n",
    "            epoch_total += len(labels)\n",
    "            epoch_loss += loss.item() * len(labels)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{epoch_correct/epoch_total:.3f}'})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss = epoch_loss / epoch_total\n",
    "        train_acc = epoch_correct / epoch_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, labels in val_loader:\n",
    "                x, labels = x.to(device), labels.to(device)\n",
    "                output, _ = model(x)\n",
    "                loss = F.cross_entropy(output, labels)\n",
    "                val_loss += loss.item() * len(labels)\n",
    "                val_correct += (output.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += len(labels)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, \"\n",
    "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f} {'*' if val_acc == best_val_acc else ''}\")\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                      epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss (Sliding Window + Ensemble)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy (Sliding Window + Ensemble)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_data, dtype=torch.float32),\n",
    "        torch.tensor(test_labels, dtype=torch.long)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for x, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        output, _ = model(x)\n",
    "        all_preds.append(output.argmax(dim=1).cpu())\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY (Ensemble): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "test_acc = evaluate(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Ensemble vs Individual Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compare_ensemble_vs_individual(model, test_data, test_labels, max_samples=2000):\n",
    "    \"\"\"\n",
    "    Compare ensemble accuracy vs individual timestep accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    x = torch.tensor(test_data[:max_samples], dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(test_labels[:max_samples], dtype=torch.long)\n",
    "    \n",
    "    ensembled_output, states = model(x)\n",
    "    ensemble_outputs = states['ensemble_outputs']\n",
    "    \n",
    "    # Individual accuracies\n",
    "    individual_accs = []\n",
    "    for i, (step, output) in enumerate(zip(model.ensemble_steps, ensemble_outputs)):\n",
    "        pred = output.argmax(dim=1).cpu()\n",
    "        acc = (pred == labels).float().mean().item()\n",
    "        individual_accs.append((step, acc))\n",
    "        print(f\"Step {step:3d}: {acc:.4f}\")\n",
    "    \n",
    "    # Ensemble accuracy\n",
    "    ensemble_pred = ensembled_output.argmax(dim=1).cpu()\n",
    "    ensemble_acc = (ensemble_pred == labels).float().mean().item()\n",
    "    print(f\"\\nENSEMBLE: {ensemble_acc:.4f}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    steps = [s for s, a in individual_accs]\n",
    "    accs = [a for s, a in individual_accs]\n",
    "    \n",
    "    ax.bar(range(len(steps)), accs, color='blue', alpha=0.7, label='Individual')\n",
    "    ax.axhline(y=ensemble_acc, color='red', linewidth=2, linestyle='--', \n",
    "               label=f'Ensemble: {ensemble_acc:.4f}')\n",
    "    \n",
    "    ax.set_xticks(range(len(steps)))\n",
    "    ax.set_xticklabels([f'Step {s}' for s in steps], rotation=45, ha='right')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Ensemble vs Individual Timestep Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Improvement stats\n",
    "    best_individual = max(accs)\n",
    "    mean_individual = np.mean(accs)\n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"  Best individual: {best_individual:.4f}\")\n",
    "    print(f\"  Mean individual: {mean_individual:.4f}\")\n",
    "    print(f\"  Ensemble:        {ensemble_acc:.4f}\")\n",
    "    print(f\"  Improvement over best: {(ensemble_acc - best_individual)*100:+.2f}%\")\n",
    "    print(f\"  Improvement over mean: {(ensemble_acc - mean_individual)*100:+.2f}%\")\n",
    "\n",
    "compare_ensemble_vs_individual(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Ensemble Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_ensemble_agreement(model, image, label):\n",
    "    \"\"\"\n",
    "    Visualize how individual ensemble members vote.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    ensembled_output, states = model(x)\n",
    "    ensemble_outputs = states['ensemble_outputs']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(image, cmap='gray')\n",
    "    axes[0, 0].set_title(f'Input (Label: {label})')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Individual predictions\n",
    "    all_probs = []\n",
    "    for i, (step, output) in enumerate(zip(model.ensemble_steps[:6], ensemble_outputs[:6])):\n",
    "        if i >= 6:\n",
    "            break\n",
    "        row, col = divmod(i + 1, 4)\n",
    "        if i + 1 < 4:\n",
    "            row, col = 0, i + 1\n",
    "        else:\n",
    "            row, col = 1, i + 1 - 4\n",
    "        \n",
    "        probs = F.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "        all_probs.append(probs)\n",
    "        pred = probs.argmax()\n",
    "        \n",
    "        colors = ['green' if j == label else 'blue' for j in range(10)]\n",
    "        colors[pred] = 'red' if pred != label else 'green'\n",
    "        \n",
    "        axes[row, col].bar(range(10), probs, color=colors, alpha=0.7)\n",
    "        axes[row, col].set_title(f'Step {step}: pred={pred} {\"✓\" if pred == label else \"✗\"}', \n",
    "                                  fontsize=10)\n",
    "        axes[row, col].set_xticks(range(10))\n",
    "        axes[row, col].set_ylim(0, 1)\n",
    "    \n",
    "    # Ensemble result\n",
    "    axes[1, 3].clear()\n",
    "    ensemble_probs = F.softmax(ensembled_output, dim=1).squeeze().cpu().numpy()\n",
    "    ensemble_pred = ensemble_probs.argmax()\n",
    "    colors = ['green' if j == label else 'blue' for j in range(10)]\n",
    "    colors[ensemble_pred] = 'red' if ensemble_pred != label else 'green'\n",
    "    \n",
    "    axes[1, 3].bar(range(10), ensemble_probs, color=colors, alpha=0.9, edgecolor='black', linewidth=2)\n",
    "    axes[1, 3].set_title(f'ENSEMBLE: pred={ensemble_pred} {\"✓\" if ensemble_pred == label else \"✗\"}',\n",
    "                          fontsize=12, fontweight='bold')\n",
    "    axes[1, 3].set_xticks(range(10))\n",
    "    axes[1, 3].set_ylim(0, 1)\n",
    "    \n",
    "    plt.suptitle(f'Temporal Ensemble Voting (True label: {label})', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print vote summary\n",
    "    print(\"\\nIndividual predictions:\")\n",
    "    for i, (step, output) in enumerate(zip(model.ensemble_steps, ensemble_outputs)):\n",
    "        pred = output.argmax(dim=1).item()\n",
    "        print(f\"  Step {step:3d}: {pred} {'✓' if pred == label else '✗'}\")\n",
    "    print(f\"\\n  ENSEMBLE: {ensemble_pred} {'✓' if ensemble_pred == label else '✗'}\")\n",
    "\n",
    "# Visualize a few samples\n",
    "for i in range(3):\n",
    "    visualize_ensemble_agreement(model, test_data[i], test_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | Single Output | Temporal Ensemble |\n",
    "|--------|--------------|-------------------|\n",
    "| Output source | Step 101 only | Steps 20, 40, 60, 80, 100, 101 |\n",
    "| Variance | Higher | **Lower** |\n",
    "| Robustness | Less | **More** |\n",
    "\n",
    "### Why Ensemble Helps\n",
    "\n",
    "1. **Different integration states**: Each timestep captures different features\n",
    "2. **Error averaging**: Mistakes at one step can be corrected by others\n",
    "3. **Redundancy**: Row and column phases both contribute\n",
    "4. **No extra parameters**: Same model, just different outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
