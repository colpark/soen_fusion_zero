{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST with Sliding Window Input (8 pixels at a time)\n",
    "\n",
    "**Redundant input with sliding windows**: Each neuron receives only 8 pixels at a time,\n",
    "with windows sliding across rows then columns.\n",
    "\n",
    "## Input Scheme\n",
    "\n",
    "```\n",
    "SWEEP (40 steps):\n",
    "├── Row Phase (20 steps): Slide 8-pixel window across each row\n",
    "│   Step 0:  [0:8]   → pixels 0-7\n",
    "│   Step 1:  [1:9]   → pixels 1-8\n",
    "│   ...     \n",
    "│   Step 19: [19:27] → pixels 19-26\n",
    "│\n",
    "└── Column Phase (20 steps): Slide 8-pixel window down each column\n",
    "    Step 20: row [0:8]   → rows 0-7\n",
    "    Step 21: row [1:9]   → rows 1-8\n",
    "    ...     \n",
    "    Step 39: row [19:27] → rows 19-26\n",
    "\n",
    "Repeat sweeps until 100 input steps → 2.5 sweeps\n",
    "```\n",
    "\n",
    "## Hardware Constraint: 8 inputs per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KEY HYPERPARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "# Sliding window parameters\n",
    "WINDOW_SIZE = 8         # Each neuron receives 8 pixels (hardware constraint)\n",
    "N_ROW_STEPS = 20        # Sliding window steps across rows\n",
    "N_COL_STEPS = 20        # Sliding window steps down columns\n",
    "STEPS_PER_SWEEP = N_ROW_STEPS + N_COL_STEPS  # 40\n",
    "\n",
    "# Timing\n",
    "N_INPUT_STEPS = 100     # Total input presentation steps\n",
    "N_SETTLE_STEPS = 1      # Steps without input after\n",
    "OUTPUT_STEP = 101       # Output at first settle step (after 100 input steps)\n",
    "\n",
    "# Network\n",
    "HIDDEN_DIM = 28         # One neuron per row/column\n",
    "INPUT_DIM = WINDOW_SIZE # 8 inputs per neuron\n",
    "OUTPUT_DIM = 10         # 10 digit classes\n",
    "\n",
    "# SOEN dynamics\n",
    "DT = 0.1\n",
    "GAMMA_PLUS = 0.1\n",
    "GAMMA_MINUS = 0.01\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 0.005\n",
    "\n",
    "n_sweeps = N_INPUT_STEPS / STEPS_PER_SWEEP\n",
    "print(f\"Sliding window: {WINDOW_SIZE} pixels\")\n",
    "print(f\"Sweep: {N_ROW_STEPS} row steps + {N_COL_STEPS} col steps = {STEPS_PER_SWEEP} steps\")\n",
    "print(f\"Total: {N_INPUT_STEPS} input steps = {n_sweeps:.1f} sweeps\")\n",
    "print(f\"Output at step: {OUTPUT_STEP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "def load_mnist():\n",
    "    train_img = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    train_lbl = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_img = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    test_lbl = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(train_img))\n",
    "    n_val = 6000\n",
    "    \n",
    "    val_img, val_lbl = train_img[idx[:n_val]], train_lbl[idx[:n_val]]\n",
    "    train_img, train_lbl = train_img[idx[n_val:]], train_lbl[idx[n_val:]]\n",
    "    \n",
    "    print(f\"Train: {train_img.shape}, Val: {val_img.shape}, Test: {test_img.shape}\")\n",
    "    return (train_img, train_lbl), (val_img, val_lbl), (test_img, test_lbl)\n",
    "\n",
    "(train_data, train_labels), (val_data, val_labels), (test_data, test_labels) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sliding Window Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sliding_window(image, label):\n",
    "    \"\"\"Visualize the sliding window input scheme.\"\"\"\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Original image\n",
    "    ax1 = fig.add_subplot(2, 3, 1)\n",
    "    ax1.imshow(image, cmap='gray')\n",
    "    ax1.set_title(f'Original Image (Label: {label})')\n",
    "    \n",
    "    # Row phase visualization (show a few steps)\n",
    "    ax2 = fig.add_subplot(2, 3, 2)\n",
    "    row_vis = np.zeros((28, 28))\n",
    "    for step in [0, 5, 10, 15, 19]:\n",
    "        row_vis[:, step:step+8] += 0.2\n",
    "    ax2.imshow(row_vis, cmap='Blues', vmin=0, vmax=1)\n",
    "    ax2.set_title('Row Phase: Window slides →')\n",
    "    ax2.set_xlabel('Column (window slides this way)')\n",
    "    ax2.set_ylabel('Row (each neuron = one row)')\n",
    "    \n",
    "    # Column phase visualization\n",
    "    ax3 = fig.add_subplot(2, 3, 3)\n",
    "    col_vis = np.zeros((28, 28))\n",
    "    for step in [0, 5, 10, 15, 19]:\n",
    "        col_vis[step:step+8, :] += 0.2\n",
    "    ax3.imshow(col_vis, cmap='Oranges', vmin=0, vmax=1)\n",
    "    ax3.set_title('Column Phase: Window slides ↓')\n",
    "    ax3.set_xlabel('Column (each neuron = one column)')\n",
    "    ax3.set_ylabel('Row (window slides this way)')\n",
    "    \n",
    "    # Timeline\n",
    "    ax4 = fig.add_subplot(2, 1, 2)\n",
    "    \n",
    "    # Draw sweeps\n",
    "    colors = ['blue', 'orange']\n",
    "    for sweep in range(3):  # Show ~2.5 sweeps\n",
    "        start = sweep * STEPS_PER_SWEEP\n",
    "        if start >= N_INPUT_STEPS:\n",
    "            break\n",
    "        \n",
    "        # Row phase\n",
    "        row_end = min(start + N_ROW_STEPS, N_INPUT_STEPS)\n",
    "        if row_end > start:\n",
    "            ax4.barh(0, row_end - start, left=start, height=0.4, \n",
    "                     color='blue', alpha=0.7, edgecolor='black')\n",
    "            if row_end - start > 5:\n",
    "                ax4.text((start + row_end)/2, 0, 'Row', ha='center', va='center', \n",
    "                         color='white', fontweight='bold', fontsize=8)\n",
    "        \n",
    "        # Column phase\n",
    "        col_start = start + N_ROW_STEPS\n",
    "        col_end = min(col_start + N_COL_STEPS, N_INPUT_STEPS)\n",
    "        if col_end > col_start:\n",
    "            ax4.barh(0, col_end - col_start, left=col_start, height=0.4,\n",
    "                     color='orange', alpha=0.7, edgecolor='black')\n",
    "            if col_end - col_start > 5:\n",
    "                ax4.text((col_start + col_end)/2, 0, 'Col', ha='center', va='center',\n",
    "                         color='white', fontweight='bold', fontsize=8)\n",
    "    \n",
    "    # Settle phase\n",
    "    ax4.barh(0, N_SETTLE_STEPS, left=N_INPUT_STEPS, height=0.4,\n",
    "             color='green', alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Output marker\n",
    "    ax4.axvline(x=OUTPUT_STEP - 0.5, color='red', linewidth=2, linestyle='--')\n",
    "    ax4.scatter([OUTPUT_STEP - 0.5], [0], color='red', s=100, zorder=5, marker='v')\n",
    "    ax4.text(OUTPUT_STEP, 0.3, f'Output\\n(step {OUTPUT_STEP})', ha='center', fontsize=9, color='red')\n",
    "    \n",
    "    ax4.set_xlim(-1, N_INPUT_STEPS + N_SETTLE_STEPS + 2)\n",
    "    ax4.set_ylim(-0.5, 0.5)\n",
    "    ax4.set_xlabel('Timestep')\n",
    "    ax4.set_title(f'Timeline: {N_INPUT_STEPS} input steps ({N_INPUT_STEPS/STEPS_PER_SWEEP:.1f} sweeps) + {N_SETTLE_STEPS} settle')\n",
    "    ax4.set_yticks([])\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='blue', alpha=0.7, label='Row phase (20 steps)'),\n",
    "        Patch(facecolor='orange', alpha=0.7, label='Col phase (20 steps)'),\n",
    "        Patch(facecolor='green', alpha=0.7, label='Settle'),\n",
    "    ]\n",
    "    ax4.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInput scheme summary:\")\n",
    "    print(f\"  • Each neuron receives {WINDOW_SIZE} pixels at a time (hardware constraint)\")\n",
    "    print(f\"  • Row phase: slide window across 28 columns in {N_ROW_STEPS} steps\")\n",
    "    print(f\"  • Col phase: slide window down 28 rows in {N_COL_STEPS} steps\")\n",
    "    print(f\"  • One sweep = {STEPS_PER_SWEEP} steps\")\n",
    "    print(f\"  • Total: {N_INPUT_STEPS} steps = {N_INPUT_STEPS/STEPS_PER_SWEEP:.1f} sweeps\")\n",
    "\n",
    "visualize_sliding_window(train_data[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sliding Window SOEN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowSOEN(nn.Module):\n",
    "    \"\"\"\n",
    "    SOEN model with sliding window input.\n",
    "    \n",
    "    Each neuron receives 8 pixels at a time (hardware constraint).\n",
    "    Window slides across rows, then columns, then repeats.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=28, window_size=8, output_dim=10,\n",
    "                 n_row_steps=20, n_col_steps=20,\n",
    "                 n_input_steps=100, n_settle_steps=1, output_step=101,\n",
    "                 dt=0.1, gamma_plus=0.1, gamma_minus=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.window_size = window_size\n",
    "        self.output_dim = output_dim\n",
    "        self.n_row_steps = n_row_steps\n",
    "        self.n_col_steps = n_col_steps\n",
    "        self.steps_per_sweep = n_row_steps + n_col_steps\n",
    "        self.n_input_steps = n_input_steps\n",
    "        self.n_settle_steps = n_settle_steps\n",
    "        self.output_step = output_step\n",
    "        self.dt = dt\n",
    "        self.gamma_plus = gamma_plus\n",
    "        self.gamma_minus = gamma_minus\n",
    "        \n",
    "        # Input weights: each neuron has weights for 8-pixel window\n",
    "        self.W_i2h = nn.Parameter(torch.empty(hidden_dim, window_size))  # (28, 8)\n",
    "        \n",
    "        # Recurrent weights\n",
    "        self.W_h2h = nn.Parameter(torch.empty(hidden_dim, hidden_dim))  # (28, 28)\n",
    "        \n",
    "        # Output weights\n",
    "        self.W_h2o = nn.Parameter(torch.empty(output_dim, hidden_dim))  # (10, 28)\n",
    "        \n",
    "        # Biases\n",
    "        self.bias_h = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.bias_o = nn.Parameter(torch.zeros(output_dim))\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.uniform_(self.W_i2h, -0.2, 0.2)\n",
    "        nn.init.normal_(self.W_h2h, 0, 0.1)\n",
    "        nn.init.normal_(self.W_h2o, 0, 0.2)\n",
    "        with torch.no_grad():\n",
    "            self.W_h2h.fill_diagonal_(0)\n",
    "    \n",
    "    def source_function(self, phi):\n",
    "        return torch.sigmoid(5 * phi)\n",
    "    \n",
    "    def get_window_input(self, images, step):\n",
    "        \"\"\"\n",
    "        Extract 8-pixel window for each neuron at given step.\n",
    "        \n",
    "        Args:\n",
    "            images: (batch, 28, 28)\n",
    "            step: Current timestep (0-indexed)\n",
    "        \n",
    "        Returns:\n",
    "            window: (batch, 28, 8) - 28 neurons, 8 inputs each\n",
    "        \"\"\"\n",
    "        batch_size = images.shape[0]\n",
    "        step_in_sweep = step % self.steps_per_sweep\n",
    "        \n",
    "        if step_in_sweep < self.n_row_steps:\n",
    "            # ROW PHASE: Each neuron i receives window from row i\n",
    "            # Window slides across columns\n",
    "            window_start = step_in_sweep\n",
    "            window_end = window_start + self.window_size\n",
    "            \n",
    "            # Handle edge case: clamp to valid range\n",
    "            if window_end > 28:\n",
    "                window_end = 28\n",
    "                window_start = window_end - self.window_size\n",
    "            \n",
    "            # Extract: images[:, row, window_start:window_end]\n",
    "            # For all rows at once: images[:, :, window_start:window_end]\n",
    "            window = images[:, :, window_start:window_end]  # (batch, 28, 8)\n",
    "            \n",
    "        else:\n",
    "            # COLUMN PHASE: Each neuron i receives window from column i\n",
    "            # Window slides down rows\n",
    "            col_step = step_in_sweep - self.n_row_steps\n",
    "            window_start = col_step\n",
    "            window_end = window_start + self.window_size\n",
    "            \n",
    "            if window_end > 28:\n",
    "                window_end = 28\n",
    "                window_start = window_end - self.window_size\n",
    "            \n",
    "            # Extract: images[:, window_start:window_end, col]\n",
    "            # For all columns: images[:, window_start:window_end, :]\n",
    "            # Then transpose to get (batch, 28 cols, 8 rows)\n",
    "            window = images[:, window_start:window_end, :].transpose(1, 2)  # (batch, 28, 8)\n",
    "        \n",
    "        return window\n",
    "    \n",
    "    def step(self, s, window_input=None):\n",
    "        \"\"\"\n",
    "        Single timestep update.\n",
    "        \n",
    "        Args:\n",
    "            s: Hidden state (batch, 28)\n",
    "            window_input: (batch, 28, 8) or None for settle phase\n",
    "        \"\"\"\n",
    "        # Input contribution: each neuron applies its weights to its 8-pixel window\n",
    "        if window_input is not None:\n",
    "            # window_input: (batch, 28, 8)\n",
    "            # W_i2h: (28, 8)\n",
    "            # For each neuron i: sum_j(W_i2h[i,j] * window_input[b,i,j])\n",
    "            input_contrib = (window_input * self.W_i2h.unsqueeze(0)).sum(dim=2)  # (batch, 28)\n",
    "        else:\n",
    "            input_contrib = 0\n",
    "        \n",
    "        # Recurrent contribution\n",
    "        recurrent_contrib = F.linear(s, self.W_h2h)  # (batch, 28)\n",
    "        \n",
    "        # Total flux\n",
    "        phi = input_contrib + recurrent_contrib + self.bias_h\n",
    "        \n",
    "        # SingleDendrite dynamics\n",
    "        g = self.source_function(phi)\n",
    "        dsdt = self.gamma_plus * g - self.gamma_minus * s\n",
    "        s_new = s + self.dt * dsdt\n",
    "        \n",
    "        return s_new\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward pass with sliding window input.\n",
    "        \n",
    "        Args:\n",
    "            images: (batch, 28, 28)\n",
    "        \n",
    "        Returns:\n",
    "            output: (batch, 10)\n",
    "            states: Dict with intermediate states\n",
    "        \"\"\"\n",
    "        batch_size = images.shape[0]\n",
    "        s = torch.zeros(batch_size, self.hidden_dim, device=images.device)\n",
    "        \n",
    "        all_states = [s.clone()]\n",
    "        all_outputs = []\n",
    "        \n",
    "        # INPUT PHASE: n_input_steps with sliding window\n",
    "        for t in range(self.n_input_steps):\n",
    "            window = self.get_window_input(images, t)\n",
    "            s = self.step(s, window)\n",
    "            all_states.append(s.clone())\n",
    "            all_outputs.append(F.linear(s, self.W_h2o, self.bias_o))\n",
    "        \n",
    "        # SETTLE PHASE: no input\n",
    "        for t in range(self.n_settle_steps):\n",
    "            s = self.step(s, window_input=None)\n",
    "            all_states.append(s.clone())\n",
    "            all_outputs.append(F.linear(s, self.W_h2o, self.bias_o))\n",
    "        \n",
    "        # Get output at specified step (1-indexed)\n",
    "        output_idx = min(self.output_step - 1, len(all_outputs) - 1)\n",
    "        output = all_outputs[output_idx]\n",
    "        \n",
    "        return output, {\n",
    "            'all_states': all_states,\n",
    "            'all_outputs': all_outputs,\n",
    "            'final_state': s\n",
    "        }\n",
    "\n",
    "# Create model\n",
    "model = SlidingWindowSOEN(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_row_steps=N_ROW_STEPS,\n",
    "    n_col_steps=N_COL_STEPS,\n",
    "    n_input_steps=N_INPUT_STEPS,\n",
    "    n_settle_steps=N_SETTLE_STEPS,\n",
    "    output_step=OUTPUT_STEP,\n",
    "    dt=DT,\n",
    "    gamma_plus=GAMMA_PLUS,\n",
    "    gamma_minus=GAMMA_MINUS\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created\")\n",
    "print(f\"  W_i2h: {model.W_i2h.shape} (each neuron has {WINDOW_SIZE} input weights)\")\n",
    "print(f\"  W_h2h: {model.W_h2h.shape} (recurrent)\")\n",
    "print(f\"  W_h2o: {model.W_h2o.shape} (output)\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Window Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_window_extraction(model, image):\n",
    "    \"\"\"Verify that window extraction is working correctly.\"\"\"\n",
    "    x = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle('Window Extraction Verification', fontsize=14)\n",
    "    \n",
    "    # Row phase examples\n",
    "    for i, step in enumerate([0, 5, 10, 15, 19]):\n",
    "        window = model.get_window_input(x, step).squeeze().cpu().numpy()\n",
    "        axes[0, i].imshow(window, cmap='viridis', aspect='auto')\n",
    "        axes[0, i].set_title(f'Row step {step}')\n",
    "        axes[0, i].set_xlabel('Pixel in window')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel('Neuron (row)')\n",
    "    \n",
    "    # Column phase examples\n",
    "    for i, step in enumerate([20, 25, 30, 35, 39]):\n",
    "        window = model.get_window_input(x, step).squeeze().cpu().numpy()\n",
    "        axes[1, i].imshow(window, cmap='viridis', aspect='auto')\n",
    "        axes[1, i].set_title(f'Col step {step}')\n",
    "        axes[1, i].set_xlabel('Pixel in window')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('Neuron (col)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "verify_window_extraction(model, train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                epochs=30, batch_size=128, lr=0.005):\n",
    "    \"\"\"\n",
    "    Train the sliding window SOEN model.\n",
    "    \"\"\"\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_data, dtype=torch.float32),\n",
    "        torch.tensor(train_labels, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(val_data, dtype=torch.float32),\n",
    "        torch.tensor(val_labels, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"SLIDING WINDOW SOEN TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Window size: {model.window_size} pixels (hardware constraint)\")\n",
    "    print(f\"Sweep: {model.n_row_steps} row + {model.n_col_steps} col = {model.steps_per_sweep} steps\")\n",
    "    print(f\"Total: {model.n_input_steps} input + {model.n_settle_steps} settle steps\")\n",
    "    print(f\"Output at step: {model.output_step}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for x, labels in pbar:\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(x)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.W_h2h.fill_diagonal_(0)\n",
    "            \n",
    "            pred = output.argmax(dim=1)\n",
    "            epoch_correct += (pred == labels).sum().item()\n",
    "            epoch_total += len(labels)\n",
    "            epoch_loss += loss.item() * len(labels)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{epoch_correct/epoch_total:.3f}'})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_loss = epoch_loss / epoch_total\n",
    "        train_acc = epoch_correct / epoch_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, labels in val_loader:\n",
    "                x, labels = x.to(device), labels.to(device)\n",
    "                output, _ = model(x)\n",
    "                loss = F.cross_entropy(output, labels)\n",
    "                val_loss += loss.item() * len(labels)\n",
    "                val_correct += (output.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += len(labels)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, \"\n",
    "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f} {'*' if val_acc == best_val_acc else ''}\")\n",
    "    \n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                      epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss (Sliding Window SOEN)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy (Sliding Window SOEN)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_data, dtype=torch.float32),\n",
    "        torch.tensor(test_labels, dtype=torch.long)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for x, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        output, _ = model(x)\n",
    "        all_preds.append(output.argmax(dim=1).cpu())\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY (Sliding Window SOEN): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "test_acc = evaluate(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dynamics(model, image, label):\n",
    "    model.eval()\n",
    "    x = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output, states = model(x)\n",
    "    \n",
    "    all_states = torch.stack(states['all_states']).squeeze().cpu().numpy()\n",
    "    all_outputs = torch.stack(states['all_outputs']).squeeze().cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(image, cmap='gray')\n",
    "    axes[0, 0].set_title(f'Input Image (Label: {label})')\n",
    "    \n",
    "    # Hidden state evolution\n",
    "    im = axes[0, 1].imshow(all_states.T, aspect='auto', cmap='viridis')\n",
    "    # Mark sweep boundaries\n",
    "    for sweep in range(3):\n",
    "        pos = sweep * model.steps_per_sweep\n",
    "        if pos < model.n_input_steps:\n",
    "            axes[0, 1].axvline(x=pos + 0.5, color='white', linestyle=':', alpha=0.5)\n",
    "        pos = sweep * model.steps_per_sweep + model.n_row_steps\n",
    "        if pos < model.n_input_steps:\n",
    "            axes[0, 1].axvline(x=pos + 0.5, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[0, 1].axvline(x=model.n_input_steps + 0.5, color='green', linestyle='--', label='Settle')\n",
    "    axes[0, 1].set_xlabel('Timestep')\n",
    "    axes[0, 1].set_ylabel('Neuron')\n",
    "    axes[0, 1].set_title('Hidden State Evolution')\n",
    "    plt.colorbar(im, ax=axes[0, 1])\n",
    "    \n",
    "    # Output evolution\n",
    "    for i in range(10):\n",
    "        axes[1, 0].plot(all_outputs[:, i], label=f'{i}', alpha=0.7)\n",
    "    axes[1, 0].axvline(x=model.n_input_steps - 0.5, color='green', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Timestep')\n",
    "    axes[1, 0].set_ylabel('Logit')\n",
    "    axes[1, 0].set_title('Output Logits Over Time')\n",
    "    axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    \n",
    "    # Final prediction\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    probs = F.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "    colors = ['green' if i == label else 'blue' for i in range(10)]\n",
    "    colors[pred] = 'red' if pred != label else 'green'\n",
    "    axes[1, 1].bar(range(10), probs, color=colors)\n",
    "    axes[1, 1].set_xlabel('Class')\n",
    "    axes[1, 1].set_ylabel('Probability')\n",
    "    axes[1, 1].set_title(f'Prediction: {pred} (True: {label}) {\"✓\" if pred == label else \"✗\"}')\n",
    "    axes[1, 1].set_xticks(range(10))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for i in range(3):\n",
    "    visualize_dynamics(model, test_data[i], test_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Explore Output Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_output_steps(model, test_data, test_labels, max_samples=1000):\n",
    "    model.eval()\n",
    "    \n",
    "    x = torch.tensor(test_data[:max_samples], dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(test_labels[:max_samples], dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, states = model(x)\n",
    "    \n",
    "    all_outputs = states['all_outputs']\n",
    "    \n",
    "    # Sample steps to show\n",
    "    sample_steps = list(range(0, len(all_outputs), 10)) + [len(all_outputs) - 1]\n",
    "    sample_steps = sorted(set(sample_steps))\n",
    "    \n",
    "    results = []\n",
    "    for step in sample_steps:\n",
    "        output = all_outputs[step]\n",
    "        pred = output.argmax(dim=1).cpu()\n",
    "        acc = (pred == labels).float().mean().item()\n",
    "        \n",
    "        if step < model.n_input_steps:\n",
    "            step_in_sweep = step % model.steps_per_sweep\n",
    "            if step_in_sweep < model.n_row_steps:\n",
    "                phase = 'row'\n",
    "            else:\n",
    "                phase = 'col'\n",
    "        else:\n",
    "            phase = 'settle'\n",
    "        \n",
    "        results.append((step + 1, acc, phase))  # 1-indexed\n",
    "        print(f\"Step {step+1:3d} ({phase:6s}): {acc:.4f}\")\n",
    "    \n",
    "    # Plot\n",
    "    steps = [r[0] for r in results]\n",
    "    accs = [r[1] for r in results]\n",
    "    colors = {'row': 'blue', 'col': 'orange', 'settle': 'green'}\n",
    "    bar_colors = [colors[r[2]] for r in results]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.bar(range(len(steps)), accs, color=bar_colors)\n",
    "    plt.xticks(range(len(steps)), steps)\n",
    "    plt.xlabel('Output Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Output Step')\n",
    "    \n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='blue', label='Row phase'),\n",
    "        Patch(facecolor='orange', label='Col phase'),\n",
    "        Patch(facecolor='green', label='Settle'),\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    best_idx = np.argmax(accs)\n",
    "    print(f\"\\nBest step: {steps[best_idx]} (accuracy: {accs[best_idx]:.4f})\")\n",
    "\n",
    "explore_output_steps(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | Value |\n",
    "|--------|-------|\n",
    "| **Hardware constraint** | 8 inputs per neuron |\n",
    "| Window size | 8 pixels |\n",
    "| Row steps | 20 |\n",
    "| Column steps | 20 |\n",
    "| Steps per sweep | 40 |\n",
    "| Total input steps | 100 (2.5 sweeps) |\n",
    "| Settle steps | 1 |\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Hardware compatible**: Each neuron only receives 8 inputs at a time\n",
    "2. **Redundant coverage**: Multiple sweeps see the same data\n",
    "3. **Row + Column**: Both orientations captured\n",
    "4. **Sliding window**: Overlapping windows for smooth transitions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
