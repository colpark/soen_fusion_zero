{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Forward-Forward MNIST Classification (Binary: Digit 1 vs 2)\n\nBinary classification using Forward-Forward algorithm with minimal hidden neurons (12).\n\n## Architecture\n\n```\nInput: 784 (28×28 flattened) + 2 (one-hot label) = 786\nHidden: 12 SingleDendrite neurons\nOutput: Goodness (sum of squared activations)\n```\n\n## Inference (2 forward passes)\n\n```\nFor each class c ∈ {0, 1}:  # 0=digit1, 1=digit2\n    X_embedded = [image_pixels, one_hot(c)]\n    goodness_c = forward(X_embedded)\nPredict: argmax(goodness_0, goodness_1)\n```\n\n## Hardware Compatibility\n\n- Goodness = mean(I²) = power measurement\n- Label embedding = optical input modulation\n- No backward pass needed for inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport gzip\nimport urllib.request\n\nfrom soen_toolkit.core import (\n    ConnectionConfig,\n    LayerConfig,\n    SimulationConfig,\n    SOENModelCore,\n)\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nprint(f\"PyTorch version: {torch.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Direct MNIST download without torchvision\ndef download_mnist(data_dir='./data/mnist'):\n    \"\"\"Download MNIST dataset without torchvision.\"\"\"\n    os.makedirs(data_dir, exist_ok=True)\n    \n    base_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/'\n    files = {\n        'train_images': 'train-images-idx3-ubyte.gz',\n        'train_labels': 'train-labels-idx1-ubyte.gz',\n        'test_images': 't10k-images-idx3-ubyte.gz',\n        'test_labels': 't10k-labels-idx1-ubyte.gz',\n    }\n    \n    paths = {}\n    for key, filename in files.items():\n        filepath = os.path.join(data_dir, filename)\n        if not os.path.exists(filepath):\n            print(f\"Downloading {filename}...\")\n            urllib.request.urlretrieve(base_url + filename, filepath)\n        paths[key] = filepath\n    \n    return paths\n\n\ndef load_mnist_images(filepath):\n    \"\"\"Load MNIST images from gzipped IDX file.\"\"\"\n    with gzip.open(filepath, 'rb') as f:\n        magic = int.from_bytes(f.read(4), 'big')\n        n_images = int.from_bytes(f.read(4), 'big')\n        n_rows = int.from_bytes(f.read(4), 'big')\n        n_cols = int.from_bytes(f.read(4), 'big')\n        data = np.frombuffer(f.read(), dtype=np.uint8)\n        return data.reshape(n_images, n_rows * n_cols).astype(np.float32) / 255.0\n\n\ndef load_mnist_labels(filepath):\n    \"\"\"Load MNIST labels from gzipped IDX file.\"\"\"\n    with gzip.open(filepath, 'rb') as f:\n        magic = int.from_bytes(f.read(4), 'big')\n        n_labels = int.from_bytes(f.read(4), 'big')\n        return np.frombuffer(f.read(), dtype=np.uint8)\n\n\n# Download and load MNIST\npaths = download_mnist()\nX_train_full = torch.from_numpy(load_mnist_images(paths['train_images']))\ny_train_full = torch.from_numpy(load_mnist_labels(paths['train_labels'])).long()\nX_test_full = torch.from_numpy(load_mnist_images(paths['test_images']))\ny_test_full = torch.from_numpy(load_mnist_labels(paths['test_labels'])).long()\n\nprint(f\"Full dataset: Train={X_train_full.shape}, Test={X_test_full.shape}\")\n\n# Filter to only digits 1 and 2\nDIGIT_A, DIGIT_B = 1, 2\ntrain_mask = (y_train_full == DIGIT_A) | (y_train_full == DIGIT_B)\ntest_mask = (y_test_full == DIGIT_A) | (y_test_full == DIGIT_B)\n\nX_train_filtered = X_train_full[train_mask]\ny_train_filtered = y_train_full[train_mask]\nX_test_filtered = X_test_full[test_mask]\ny_test_filtered = y_test_full[test_mask]\n\n# Remap labels: DIGIT_A -> 0, DIGIT_B -> 1\ny_train_filtered = (y_train_filtered == DIGIT_B).long()\ny_test_filtered = (y_test_filtered == DIGIT_B).long()\n\nprint(f\"Filtered to digits {DIGIT_A} and {DIGIT_B}:\")\nprint(f\"  Train: {X_train_filtered.shape[0]} samples\")\nprint(f\"  Test: {X_test_filtered.shape[0]} samples\")\n\n# Use subset for experimentation\nN_TRAIN = 2000\nN_TEST = 500\n\ntorch.manual_seed(42)\ntrain_idx = torch.randperm(len(X_train_filtered))[:N_TRAIN]\ntest_idx = torch.randperm(len(X_test_filtered))[:N_TEST]\n\nX_train = X_train_filtered[train_idx]\ny_train = y_train_filtered[train_idx]\nX_test = X_test_filtered[test_idx]\ny_test = y_test_filtered[test_idx]\n\n# Scale to SOEN operating range [0.025, 0.275]\nX_train = X_train * 0.25 + 0.025\nX_test = X_test * 0.25 + 0.025\n\nprint(f\"\\nUsing subset:\")\nprint(f\"  Training set: {X_train.shape}, labels: {y_train.shape}\")\nprint(f\"  Test set: {X_test.shape}, labels: {y_test.shape}\")\nprint(f\"  X range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\nprint(f\"  Class distribution (train): 0={DIGIT_A}→{(y_train==0).sum().item()}, 1={DIGIT_B}→{(y_train==1).sum().item()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = X_train[i].view(28, 28).numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f'Label: {y_train[i].item()}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('MNIST Samples (scaled to SOEN range)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Forward-Forward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "N_CLASSES = 2  # Binary classification: digit 1 vs digit 2\nSEQ_LEN = 1    # Single timestep (no temporal simulation needed for training)\nLABEL_SCALE = 0.25  # Strong label signal\n\ndef embed_label(X, y, n_classes=N_CLASSES, label_scale=LABEL_SCALE):\n    \"\"\"\n    Embed one-hot label into input.\n    \n    Args:\n        X: [N, 784] flattened MNIST images\n        y: [N] class labels (0 or 1)\n    \n    Returns:\n        X_embedded: [N, 786] image + one-hot label (784 + 2)\n    \"\"\"\n    N = X.shape[0]\n    one_hot = torch.zeros(N, n_classes)\n    one_hot.scatter_(1, y.unsqueeze(1), label_scale)\n    return torch.cat([X, one_hot], dim=1)\n\n\ndef create_positive_negative_pairs(X, y, n_classes=N_CLASSES, label_scale=LABEL_SCALE):\n    \"\"\"\n    Create positive and negative samples for Forward-Forward.\n    \n    Positive: image with correct label\n    Negative: image with wrong label (for binary, just flip)\n    \"\"\"\n    N = X.shape[0]\n    \n    # Positive: correct labels\n    X_pos = embed_label(X, y, n_classes, label_scale)\n    \n    # Negative: wrong labels (flip for binary)\n    y_wrong = 1 - y  # 0 -> 1, 1 -> 0\n    X_neg = embed_label(X, y_wrong, n_classes, label_scale)\n    \n    return X_pos, X_neg\n\n\n# Test embedding\nX_pos, X_neg = create_positive_negative_pairs(X_train[:5], y_train[:5])\nprint(f\"Embedded shape: {X_pos.shape}\")\nprint(f\"Input dim: 784 pixels + {N_CLASSES} label = {784 + N_CLASSES}\")\nprint(f\"SEQ_LEN = {SEQ_LEN} (single-step forward pass)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_goodness(activations):\n",
    "    \"\"\"\n",
    "    Compute goodness as mean of squared activations.\n",
    "    Hardware-compatible: measures mean power in the layer.\n",
    "    \"\"\"\n",
    "    return (activations ** 2).mean(dim=1)\n",
    "\n",
    "\n",
    "def forward_forward_loss(goodness_pos, goodness_neg, threshold=0.1, margin=0.05):\n",
    "    \"\"\"\n",
    "    Forward-Forward loss with contrastive term.\n",
    "    \"\"\"\n",
    "    loss_pos = F.softplus(threshold - goodness_pos).mean()\n",
    "    loss_neg = F.softplus(goodness_neg - threshold).mean()\n",
    "    contrastive = F.softplus(margin - (goodness_pos - goodness_neg)).mean()\n",
    "    return loss_pos + loss_neg + contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Build SOEN Model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "INPUT_DIM = 784 + N_CLASSES  # 786 for binary classification\n\ndef build_ff_mnist_model(hidden_dims, input_dim=INPUT_DIM, dt=50.0):\n    \"\"\"\n    Build a SOEN model for Forward-Forward MNIST.\n    \n    Args:\n        hidden_dims: List of hidden layer dimensions (e.g., [12] or [12, 12])\n        input_dim: 784 pixels + N_CLASSES label\n    \"\"\"\n    sim_cfg = SimulationConfig(\n        dt=dt,\n        input_type=\"state\",\n        track_phi=False,\n        track_power=False,\n    )\n    \n    layers = []\n    connections = []\n    \n    # Input layer\n    layers.append(LayerConfig(\n        layer_id=0,\n        layer_type=\"Input\",\n        params={\"dim\": input_dim},\n    ))\n    \n    # Hidden layers\n    for i, hidden_dim in enumerate(hidden_dims):\n        layer_id = i + 1\n        \n        layers.append(LayerConfig(\n            layer_id=layer_id,\n            layer_type=\"SingleDendrite\",\n            params={\n                \"dim\": hidden_dim,\n                \"solver\": \"FE\",\n                \"source_func\": \"Heaviside_fit_state_dep\",\n                \"phi_offset\": 0.02,\n                \"bias_current\": 1.98,\n                \"gamma_plus\": 0.0005,\n                \"gamma_minus\": 1e-6,\n                \"learnable_params\": {\n                    \"phi_offset\": False,\n                    \"bias_current\": False,\n                    \"gamma_plus\": False,\n                    \"gamma_minus\": False,\n                },\n            },\n        ))\n        \n        connections.append(ConnectionConfig(\n            from_layer=layer_id - 1,\n            to_layer=layer_id,\n            connection_type=\"all_to_all\",\n            learnable=True,\n            params={\"init\": \"xavier_uniform\"},\n        ))\n    \n    model = SOENModelCore(\n        sim_config=sim_cfg,\n        layers_config=layers,\n        connections_config=connections,\n    )\n    \n    return model\n\n\n# Test model\nHIDDEN_DIMS = [12]  # Only 12 hidden neurons!\ntest_model = build_ff_mnist_model(HIDDEN_DIMS)\nprint(f\"Model architecture: {INPUT_DIM} → {HIDDEN_DIMS} → goodness\")\nprint(f\"Parameters: {sum(p.numel() for p in test_model.parameters() if p.requires_grad)}\")\nprint(f\"  ({INPUT_DIM} × 12 = {INPUT_DIM * 12} weights for first layer)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_ff_mnist_fast(model, X, y, batch_size=200, seq_len=1):\n    \"\"\"\n    Fast evaluation by batching all class hypotheses together.\n    \"\"\"\n    model.eval()\n    N = X.shape[0]\n    all_predictions = []\n    \n    with torch.no_grad():\n        for start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n            X_batch = X[start:end]\n            B = X_batch.shape[0]\n            \n            # Repeat each sample N_CLASSES times\n            X_repeated = X_batch.unsqueeze(1).expand(-1, N_CLASSES, -1).reshape(B * N_CLASSES, 784)\n            y_hypotheses = torch.arange(N_CLASSES).unsqueeze(0).expand(B, -1).reshape(B * N_CLASSES)\n            \n            X_embedded = embed_label(X_repeated, y_hypotheses)\n            X_seq = X_embedded.unsqueeze(1).expand(-1, seq_len, -1)\n            \n            _, layer_states = model(X_seq)\n            \n            total_goodness = torch.zeros(B * N_CLASSES)\n            for layer_idx in range(1, len(model.layers)):\n                act = layer_states[layer_idx][:, -1, :]\n                total_goodness += compute_goodness(act)\n            \n            goodness_matrix = total_goodness.reshape(B, N_CLASSES)\n            predictions = goodness_matrix.argmax(dim=1)\n            all_predictions.append(predictions)\n    \n    all_predictions = torch.cat(all_predictions)\n    accuracy = (all_predictions == y).float().mean().item()\n    model.train()\n    return accuracy\n\n\ndef train_forward_forward_mnist(model, X_train, y_train, X_test, y_test,\n                                 n_epochs=100, lr=0.01, threshold=0.1, \n                                 batch_size=100, eval_subset=500, verbose=True):\n    \"\"\"\n    Train SOEN model with Forward-Forward on MNIST.\n    Shows batch-level progress during training.\n    \n    Uses SEQ_LEN=1 for fast single-step forward passes.\n    \"\"\"\n    model.train()\n    \n    # Layer-wise optimizers\n    hidden_layer_indices = [i for i, l in enumerate(model.layers) if l.layer_type != 'Input']\n    layer_optimizers = []\n    for conn_key in model.connections.keys():\n        conn_params = [model.connections[conn_key]]\n        layer_optimizers.append(torch.optim.Adam(conn_params, lr=lr))\n    \n    history = {\n        'loss': [],\n        'train_acc': [],\n        'test_acc': [],\n        'goodness_pos': [],\n        'goodness_neg': [],\n    }\n    \n    N = X_train.shape[0]\n    n_batches = (N + batch_size - 1) // batch_size\n    \n    # Subset for fast evaluation during training\n    eval_idx = torch.randperm(N)[:min(eval_subset, N)]\n    X_train_eval = X_train[eval_idx]\n    y_train_eval = y_train[eval_idx]\n    \n    for epoch in range(n_epochs):\n        epoch_loss = 0\n        epoch_g_pos = []\n        epoch_g_neg = []\n        \n        # Shuffle data\n        perm = torch.randperm(N)\n        X_shuffled = X_train[perm]\n        y_shuffled = y_train[perm]\n        \n        for batch_idx in range(n_batches):\n            start = batch_idx * batch_size\n            end = min(start + batch_size, N)\n            \n            X_batch = X_shuffled[start:end]\n            y_batch = y_shuffled[start:end]\n            \n            # Create pos/neg pairs\n            X_pos, X_neg = create_positive_negative_pairs(X_batch, y_batch)\n            \n            # Expand to sequence (SEQ_LEN=1 for fast training)\n            X_pos_seq = X_pos.unsqueeze(1)  # [B, 1, 786]\n            X_neg_seq = X_neg.unsqueeze(1)  # [B, 1, 786]\n            \n            # Forward pass\n            _, layer_states_pos = model(X_pos_seq)\n            _, layer_states_neg = model(X_neg_seq)\n            \n            # Train each layer\n            batch_loss = 0\n            batch_g_pos = 0\n            batch_g_neg = 0\n            for layer_idx, opt in zip(hidden_layer_indices, layer_optimizers):\n                opt.zero_grad()\n                \n                act_pos = layer_states_pos[layer_idx][:, -1, :]\n                act_neg = layer_states_neg[layer_idx][:, -1, :]\n                \n                g_pos = compute_goodness(act_pos)\n                g_neg = compute_goodness(act_neg)\n                \n                batch_g_pos = g_pos.mean().item()\n                batch_g_neg = g_neg.mean().item()\n                epoch_g_pos.append(batch_g_pos)\n                epoch_g_neg.append(batch_g_neg)\n                \n                layer_loss = forward_forward_loss(g_pos, g_neg, threshold)\n                batch_loss += layer_loss.item()\n                \n                layer_loss.backward(retain_graph=True)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                opt.step()\n            \n            epoch_loss += batch_loss\n            \n            # Print batch progress\n            if verbose:\n                print(f\"\\rEpoch {epoch+1}/{n_epochs} | Batch {batch_idx+1}/{n_batches} | \"\n                      f\"Loss: {batch_loss:.4f} | G+: {batch_g_pos:.4f} | G-: {batch_g_neg:.4f}\", end=\"\")\n        \n        # Fast evaluation\n        train_acc = evaluate_ff_mnist_fast(model, X_train_eval, y_train_eval)\n        test_acc = evaluate_ff_mnist_fast(model, X_test, y_test)\n        \n        history['loss'].append(epoch_loss / n_batches)\n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)\n        history['goodness_pos'].append(np.mean(epoch_g_pos))\n        history['goodness_neg'].append(np.mean(epoch_g_neg))\n        \n        # Print epoch summary\n        if verbose:\n            print(f\"\\rEpoch {epoch+1}/{n_epochs} | Loss: {epoch_loss/n_batches:.4f} | \"\n                  f\"Train: {train_acc:.4f} | Test: {test_acc:.4f} | \"\n                  f\"G+: {np.mean(epoch_g_pos):.4f} | G-: {np.mean(epoch_g_neg):.4f}    \")\n    \n    return history\n\n\ndef evaluate_ff_mnist(model, X, y, batch_size=200):\n    \"\"\"Full evaluation (for final results).\"\"\"\n    return evaluate_ff_mnist_fast(model, X, y, batch_size, seq_len=SEQ_LEN)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# Build model with only 12 hidden neurons\nHIDDEN_DIMS = [12]\nTHRESHOLD = 0.1\nN_EPOCHS = 20\nLR = 0.01\nBATCH_SIZE = 100\n\nprint(f\"Training Forward-Forward MNIST classifier (digits {DIGIT_A} vs {DIGIT_B})...\")\nprint(f\"Architecture: {INPUT_DIM} → {HIDDEN_DIMS} → goodness\")\nprint(f\"Only {HIDDEN_DIMS[0]} hidden neurons for binary MNIST!\")\nprint(f\"Threshold: {THRESHOLD}\")\nprint(f\"Training samples: {N_TRAIN}, Test samples: {N_TEST}\")\nprint(\"=\" * 70)\n\ntorch.manual_seed(42)\nmodel = build_ff_mnist_model(HIDDEN_DIMS)\n\nhistory = train_forward_forward_mnist(\n    model, X_train, y_train, X_test, y_test,\n    n_epochs=N_EPOCHS, lr=LR, threshold=THRESHOLD,\n    batch_size=BATCH_SIZE, verbose=True\n)\n\nprint(\"=\" * 70)\nprint(f\"Final train accuracy: {history['train_acc'][-1]:.4f}\")\nprint(f\"Final test accuracy: {history['test_acc'][-1]:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Loss\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(history['loss'], color='steelblue', lw=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Forward-Forward Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Goodness\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(history['goodness_pos'], label='Positive', color='green', lw=2)\n",
    "ax2.plot(history['goodness_neg'], label='Negative', color='red', lw=2)\n",
    "ax2.axhline(y=THRESHOLD, color='black', linestyle='--', label=f'Threshold={THRESHOLD}')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Mean Goodness')\n",
    "ax2.set_title('Goodness Separation')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(history['train_acc'], label='Train', color='coral', lw=2)\n",
    "ax3.plot(history['test_acc'], label='Test', color='steelblue', lw=2)\n",
    "ax3.axhline(y=0.1, color='gray', linestyle='--', alpha=0.5, label='Random (10%)')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_title('Classification Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0, 1.0)\n",
    "\n",
    "# Separation\n",
    "ax4 = axes[1, 1]\n",
    "separation = [p - n for p, n in zip(history['goodness_pos'], history['goodness_neg'])]\n",
    "ax4.plot(separation, color='purple', lw=2)\n",
    "ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('G_pos - G_neg')\n",
    "ax4.set_title('Goodness Separation')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Forward-Forward MNIST (12 hidden neurons)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "def get_predictions_ff(model, X, batch_size=200):\n    \"\"\"Get predictions and goodness for all samples (optimized batched version).\"\"\"\n    model.eval()\n    N = X.shape[0]\n    all_predictions = []\n    all_goodness = []\n    \n    with torch.no_grad():\n        for start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n            X_batch = X[start:end]\n            B = X_batch.shape[0]\n            \n            # Batch all class hypotheses together\n            X_repeated = X_batch.unsqueeze(1).expand(-1, N_CLASSES, -1).reshape(B * N_CLASSES, 784)\n            y_hypotheses = torch.arange(N_CLASSES).unsqueeze(0).expand(B, -1).reshape(B * N_CLASSES)\n            \n            X_embedded = embed_label(X_repeated, y_hypotheses)\n            X_seq = X_embedded.unsqueeze(1)  # [B*N_CLASSES, 1, 786]\n            \n            _, layer_states = model(X_seq)\n            \n            total_goodness = torch.zeros(B * N_CLASSES)\n            for layer_idx in range(1, len(model.layers)):\n                act = layer_states[layer_idx][:, -1, :]\n                total_goodness += compute_goodness(act)\n            \n            goodness_matrix = total_goodness.reshape(B, N_CLASSES)\n            all_goodness.append(goodness_matrix)\n            all_predictions.append(goodness_matrix.argmax(dim=1))\n    \n    return torch.cat(all_predictions), torch.cat(all_goodness)\n\n\ndef compute_confusion_matrix(y_true, y_pred, n_classes=N_CLASSES):\n    \"\"\"Compute confusion matrix without sklearn.\"\"\"\n    cm = np.zeros((n_classes, n_classes), dtype=np.int32)\n    for true, pred in zip(y_true, y_pred):\n        cm[true, pred] += 1\n    return cm\n\n\n# Get test predictions\ntest_preds, test_goodness = get_predictions_ff(model, X_test)\n\n# Confusion matrix (2x2 for binary)\ncm = compute_confusion_matrix(y_test.numpy(), test_preds.numpy())\n\nfig, ax = plt.subplots(figsize=(6, 5))\nim = ax.imshow(cm, cmap='Blues')\nax.set_xticks(range(N_CLASSES))\nax.set_yticks(range(N_CLASSES))\nax.set_xticklabels([f'Pred {DIGIT_A}', f'Pred {DIGIT_B}'])\nax.set_yticklabels([f'True {DIGIT_A}', f'True {DIGIT_B}'])\nax.set_xlabel('Predicted')\nax.set_ylabel('True')\nax.set_title(f'Confusion Matrix (Test Acc: {history[\"test_acc\"][-1]:.2%})')\n\n# Add text annotations\nfor i in range(N_CLASSES):\n    for j in range(N_CLASSES):\n        text = ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=16,\n                       color='white' if cm[i, j] > cm.max()/2 else 'black')\n\nplt.colorbar(im)\nplt.tight_layout()\nplt.show()\n\n# Per-class accuracy\nprint(f\"\\nPer-class accuracy:\")\nprint(f\"  Digit {DIGIT_A}: {(test_preds[y_test==0] == 0).float().mean().item():.2%}\")\nprint(f\"  Digit {DIGIT_B}: {(test_preds[y_test==1] == 1).float().mean().item():.2%}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# Show some predictions\nn_show = 20\nfig, axes = plt.subplots(4, 5, figsize=(15, 12))\n\nfor i, ax in enumerate(axes.flat):\n    if i >= n_show:\n        break\n    \n    img = X_test[i].view(28, 28).numpy()\n    true_label = y_test[i].item()\n    pred_label = test_preds[i].item()\n    \n    # Convert back to actual digit labels\n    true_digit = DIGIT_A if true_label == 0 else DIGIT_B\n    pred_digit = DIGIT_A if pred_label == 0 else DIGIT_B\n    \n    ax.imshow(img, cmap='gray')\n    color = 'green' if pred_label == true_label else 'red'\n    ax.set_title(f'True: {true_digit}, Pred: {pred_digit}', color=color)\n    ax.axis('off')\n\nplt.suptitle(f'Forward-Forward Predictions: Digit {DIGIT_A} vs {DIGIT_B} (green=correct, red=wrong)', fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Show goodness distribution for a few samples\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\n\nfor i, ax in enumerate(axes.flat):\n    goodness_vals = test_goodness[i].numpy()\n    true_label = y_test[i].item()\n    pred_label = test_preds[i].item()\n    \n    colors = ['green' if d == true_label else 'lightgray' for d in range(N_CLASSES)]\n    colors[pred_label] = 'red' if pred_label != true_label else 'green'\n    \n    ax.bar(range(N_CLASSES), goodness_vals, color=colors)\n    ax.set_xticks(range(N_CLASSES))\n    ax.set_xticklabels([f'{DIGIT_A}', f'{DIGIT_B}'])\n    ax.set_xlabel('Digit')\n    ax.set_ylabel('Goodness')\n    true_digit = DIGIT_A if true_label == 0 else DIGIT_B\n    pred_digit = DIGIT_A if pred_label == 0 else DIGIT_B\n    status = '✓' if pred_label == true_label else '✗'\n    ax.set_title(f'True: {true_digit}, Pred: {pred_digit} {status}')\n\nplt.suptitle(f'Goodness Distribution: Digit {DIGIT_A} vs {DIGIT_B}', fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 9. Compare with Different Hidden Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# Compare different hidden layer sizes for binary classification\nhidden_configs = [\n    [4],\n    [8],\n    [12],\n    [16],\n]\n\ncomparison_results = []\n\nprint(f\"Comparing different architectures for digit {DIGIT_A} vs {DIGIT_B}...\")\nprint(\"=\" * 70)\n\nfor hidden_dims in hidden_configs:\n    torch.manual_seed(42)\n    model = build_ff_mnist_model(hidden_dims)\n    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    history = train_forward_forward_mnist(\n        model, X_train, y_train, X_test, y_test,\n        n_epochs=20, lr=0.01, threshold=0.1,\n        batch_size=100, verbose=False\n    )\n    \n    comparison_results.append({\n        'hidden_dims': str(hidden_dims),\n        'n_params': n_params,\n        'train_acc': history['train_acc'][-1],\n        'test_acc': history['test_acc'][-1],\n    })\n    \n    print(f\"Hidden={str(hidden_dims):12s} | Params={n_params:6d} | \"\n          f\"Train={history['train_acc'][-1]:.4f} | Test={history['test_acc'][-1]:.4f}\")\n\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 10. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(f\"CONCLUSIONS: FORWARD-FORWARD MNIST (Digit {DIGIT_A} vs {DIGIT_B})\")\nprint(\"=\" * 70)\n\nprint(f\"\\n1. ARCHITECTURE:\")\nprint(f\"   Input: 784 pixels + {N_CLASSES} label = {INPUT_DIM}\")\nprint(f\"   Hidden: {HIDDEN_DIMS[0]} SingleDendrite neurons\")\nprint(f\"   Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n\nprint(f\"\\n2. PERFORMANCE:\")\nprint(f\"   Train accuracy: {history['train_acc'][-1]:.2%}\")\nprint(f\"   Test accuracy:  {history['test_acc'][-1]:.2%}\")\nprint(f\"   Random baseline: 50%\")\n\nprint(f\"\\n3. HARDWARE COMPATIBILITY:\")\nprint(f\"   ✓ Goodness = mean(I²) = power measurement\")\nprint(f\"   ✓ Label embedding = optical input modulation\")\nprint(f\"   ✓ No backward pass for inference\")\nprint(f\"   ✓ Only {HIDDEN_DIMS[0]} physical neurons needed!\")\n\nprint(f\"\\n4. INFERENCE COST:\")\nprint(f\"   {N_CLASSES} forward passes per sample (one per class)\")\nprint(f\"   Compare goodness to classify: digit {DIGIT_A} vs {DIGIT_B}\")\n\nprint(\"\\n\" + \"=\" * 70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}