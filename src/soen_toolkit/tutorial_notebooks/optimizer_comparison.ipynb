{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PyTorch Optimizer Comparison on SOEN SingleDendrite Model\n",
    "\n",
    "This notebook compares different PyTorch optimizers on a **real SOEN model** with `SingleDendrite` neurons.\n",
    "\n",
    "## Model Architecture\n",
    "- **Input Layer**: 1D flux input (Linear layer, non-physical)\n",
    "- **Hidden Layer**: 3 SingleDendrite neurons (physical SOEN neurons)\n",
    "- **Output Layer**: 2D readout (for binary classification)\n",
    "\n",
    "## Task\n",
    "Binary classification: distinguish single-pulse vs double-pulse input signals.\n",
    "\n",
    "## Optimizers Compared\n",
    "1. **SGD** - Vanilla Stochastic Gradient Descent\n",
    "2. **SGD + Momentum** - SGD with momentum\n",
    "3. **Adam** - Adaptive Moment Estimation\n",
    "4. **AdamW** - Adam with decoupled weight decay\n",
    "5. **RMSprop** - Root Mean Square Propagation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from soen_toolkit.core import (\n",
    "    ConnectionConfig,\n",
    "    LayerConfig,\n",
    "    SimulationConfig,\n",
    "    SOENModelCore,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Pulse Data\n",
    "\n",
    "Create a binary classification dataset:\n",
    "- **Class 0**: Single pulse\n",
    "- **Class 1**: Double pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pulse_data(n_samples=100, seq_len=50, noise_std=0.02):\n",
    "    \"\"\"\n",
    "    Generate single-pulse vs double-pulse classification data.\n",
    "    \n",
    "    Returns:\n",
    "        X: [n_samples, seq_len, 1] - input flux sequences\n",
    "        y: [n_samples] - labels (0=single, 1=double)\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    pulse_width = 5\n",
    "    pulse_amplitude = 0.2\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        signal = torch.zeros(seq_len)\n",
    "        \n",
    "        if i % 2 == 0:  # Single pulse (Class 0)\n",
    "            start = seq_len // 4\n",
    "            signal[start:start+pulse_width] = pulse_amplitude\n",
    "            y.append(0)\n",
    "        else:  # Double pulse (Class 1)\n",
    "            start1 = seq_len // 5\n",
    "            start2 = 3 * seq_len // 5\n",
    "            signal[start1:start1+pulse_width] = pulse_amplitude\n",
    "            signal[start2:start2+pulse_width] = pulse_amplitude\n",
    "            y.append(1)\n",
    "        \n",
    "        # Add noise\n",
    "        signal += noise_std * torch.randn(seq_len)\n",
    "        X.append(signal.unsqueeze(-1))  # [seq_len, 1]\n",
    "    \n",
    "    X = torch.stack(X)  # [n_samples, seq_len, 1]\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "N_SAMPLES = 100\n",
    "SEQ_LEN = 50\n",
    "X_data, y_data = generate_pulse_data(N_SAMPLES, SEQ_LEN)\n",
    "\n",
    "print(f\"Input shape: {X_data.shape}\")\n",
    "print(f\"Labels shape: {y_data.shape}\")\n",
    "print(f\"Class distribution: {torch.bincount(y_data)}\")\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = i if i < 3 else (i - 3 + 1)  # Show alternating classes\n",
    "    ax.plot(X_data[idx, :, 0].numpy())\n",
    "    ax.set_title(f\"Sample {idx}: {'Single' if y_data[idx]==0 else 'Double'} Pulse\")\n",
    "    ax.set_xlabel('Time step')\n",
    "    ax.set_ylabel('Flux')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Build SOEN Model with SingleDendrite Neurons\n",
    "\n",
    "Architecture: 1D → 3D (SingleDendrite) → 2D (Output)\n",
    "\n",
    "- **Learnable parameters**: Connection weights (J matrices)\n",
    "- **SingleDendrite dynamics**: ds/dt = γ+ * g(φ) - γ- * s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_soen_model(hidden_dim=3, output_dim=2, dt=100.0):\n",
    "    \"\"\"\n",
    "    Build a simple SOEN model for binary classification.\n",
    "    \n",
    "    Architecture: 1 (input) → hidden_dim (SingleDendrite) → output_dim (readout)\n",
    "    \"\"\"\n",
    "    sim_cfg = SimulationConfig(\n",
    "        dt=dt,\n",
    "        input_type=\"state\",  # Input directly as state\n",
    "        track_phi=False,\n",
    "        track_power=False,\n",
    "    )\n",
    "    \n",
    "    # Layer 0: Input (1D flux input)\n",
    "    layer0 = LayerConfig(\n",
    "        layer_id=0,\n",
    "        layer_type=\"Input\",\n",
    "        description=\"Input flux\",\n",
    "        params={\"dim\": 1},\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Hidden SingleDendrite neurons\n",
    "    layer1 = LayerConfig(\n",
    "        layer_id=1,\n",
    "        layer_type=\"SingleDendrite\",\n",
    "        description=\"Hidden SOEN neurons\",\n",
    "        params={\n",
    "            \"dim\": hidden_dim,\n",
    "            \"solver\": \"FE\",\n",
    "            \"source_func\": \"Heaviside_fit_state_dep\",\n",
    "            \"phi_offset\": 0.02,\n",
    "            \"bias_current\": 1.98,\n",
    "            \"gamma_plus\": 0.00013,\n",
    "            \"gamma_minus\": 1e-8,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Output (readout)\n",
    "    layer2 = LayerConfig(\n",
    "        layer_id=2,\n",
    "        layer_type=\"Input\",  # Non-dynamic readout\n",
    "        description=\"Output readout\",\n",
    "        params={\"dim\": output_dim},\n",
    "    )\n",
    "    \n",
    "    layers = [layer0, layer1, layer2]\n",
    "    \n",
    "    # Connection 0→1: Input to hidden (learnable)\n",
    "    conn01 = ConnectionConfig(\n",
    "        from_layer=0,\n",
    "        to_layer=1,\n",
    "        connection_type=\"all_to_all\",\n",
    "        learnable=True,\n",
    "        params={\n",
    "            \"init\": \"uniform\",\n",
    "            \"min\": 0.1,\n",
    "            \"max\": 0.24,\n",
    "            \"constraints\": {\"min\": -0.24, \"max\": 0.24},\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # Connection 1→2: Hidden to output (learnable)\n",
    "    conn12 = ConnectionConfig(\n",
    "        from_layer=1,\n",
    "        to_layer=2,\n",
    "        connection_type=\"all_to_all\",\n",
    "        learnable=True,\n",
    "        params={\n",
    "            \"init\": \"uniform\",\n",
    "            \"min\": -0.5,\n",
    "            \"max\": 0.5,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    connections = [conn01, conn12]\n",
    "    \n",
    "    model = SOENModelCore(\n",
    "        sim_config=sim_cfg,\n",
    "        layers_config=layers,\n",
    "        connections_config=connections,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and inspect model\n",
    "test_model = build_soen_model()\n",
    "print(\"Model Structure:\")\n",
    "print(f\"  Layers: {[l.dim for l in test_model.layers]}\")\n",
    "print(f\"  Trainable parameters: {sum(p.numel() for p in test_model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# List trainable parameters\n",
    "print(\"\\nTrainable Parameters:\")\n",
    "for name, param in test_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"  {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture\n",
    "test_model.visualize(show_descriptions=True, theme=\"modern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Define Training Loop\n",
    "\n",
    "Train the SOEN model and track loss/accuracy over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_soen_model(optimizer_class, optimizer_kwargs, X_data, y_data,\n",
    "                     n_epochs=50, batch_size=16, verbose=False):\n",
    "    \"\"\"\n",
    "    Train a SOEN model with the specified optimizer.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with losses, accuracies, and final model state\n",
    "    \"\"\"\n",
    "    # Build fresh model\n",
    "    model = build_soen_model()\n",
    "    model.train()\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_kwargs)\n",
    "    \n",
    "    # Tracking\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    n_samples = len(X_data)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Shuffle data\n",
    "        perm = torch.randperm(n_samples)\n",
    "        X_shuffled = X_data[perm]\n",
    "        y_shuffled = y_data[perm]\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass through SOEN model\n",
    "            # Returns (final_history, all_histories)\n",
    "            final_history, _ = model(X_batch)\n",
    "            \n",
    "            # Time pooling: take mean over sequence\n",
    "            # final_history shape: [batch, seq_len+1, output_dim]\n",
    "            output = final_history[:, 1:, :].mean(dim=1)  # [batch, output_dim]\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(output, y_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * len(X_batch)\n",
    "            _, predicted = output.max(1)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += len(y_batch)\n",
    "        \n",
    "        avg_loss = epoch_loss / n_samples\n",
    "        accuracy = correct / total\n",
    "        losses.append(avg_loss)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"  Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={accuracy:.2%}\")\n",
    "    \n",
    "    return {\n",
    "        'losses': losses,\n",
    "        'accuracies': accuracies,\n",
    "        'final_loss': losses[-1],\n",
    "        'final_accuracy': accuracies[-1],\n",
    "        'model': model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Compare Optimizers on SOEN Training\n",
    "\n",
    "Train the SingleDendrite network with different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer configurations\n",
    "OPTIMIZERS = {\n",
    "    'SGD (lr=0.01)': (torch.optim.SGD, {'lr': 0.01}),\n",
    "    'SGD (lr=0.1)': (torch.optim.SGD, {'lr': 0.1}),\n",
    "    'SGD + Momentum': (torch.optim.SGD, {'lr': 0.01, 'momentum': 0.9}),\n",
    "    'Adam (lr=0.01)': (torch.optim.Adam, {'lr': 0.01}),\n",
    "    'Adam (lr=0.001)': (torch.optim.Adam, {'lr': 0.001}),\n",
    "    'AdamW': (torch.optim.AdamW, {'lr': 0.01}),\n",
    "    'RMSprop': (torch.optim.RMSprop, {'lr': 0.01}),\n",
    "}\n",
    "\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Train with each optimizer\n",
    "results = {}\n",
    "for name, (opt_class, opt_kwargs) in OPTIMIZERS.items():\n",
    "    print(f\"Training with {name}...\")\n",
    "    results[name] = train_soen_model(\n",
    "        opt_class, opt_kwargs, X_data, y_data,\n",
    "        n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, verbose=False\n",
    "    )\n",
    "    print(f\"  Final: Loss={results[name]['final_loss']:.4f}, \"\n",
    "          f\"Acc={results[name]['final_accuracy']:.2%}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(results)))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    ax1.plot(res['losses'], label=name, linewidth=2, color=color)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Cross-Entropy Loss')\n",
    "ax1.set_title('Training Loss (SOEN SingleDendrite Model)')\n",
    "ax1.legend(loc='upper right', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2 = axes[1]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    ax2.plot(res['accuracies'], label=name, linewidth=2, color=color)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy (SOEN SingleDendrite Model)')\n",
    "ax2.legend(loc='lower right', fontsize=9)\n",
    "ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
    "ax2.set_ylim([0.4, 1.05])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Log-Scale Loss Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    ax.plot(res['losses'], label=name, linewidth=2, color=color)\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss (log scale)', fontsize=12)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Training Loss Comparison (Log Scale)', fontsize=14)\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Convergence Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_to_accuracy(accuracies, threshold):\n",
    "    \"\"\"Return number of epochs to reach accuracy threshold.\"\"\"\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        if acc >= threshold:\n",
    "            return i + 1\n",
    "    return None\n",
    "\n",
    "# Analyze convergence\n",
    "thresholds = [0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "print(\"Epochs to reach accuracy threshold:\")\n",
    "print(\"=\" * 80)\n",
    "header = f\"{'Optimizer':<25}\" + \"\".join([f\"Acc>{t:.0%}    \" for t in thresholds])\n",
    "print(header)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, res in results.items():\n",
    "    row = f\"{name:<25}\"\n",
    "    for thresh in thresholds:\n",
    "        epochs = epochs_to_accuracy(res['accuracies'], thresh)\n",
    "        row += f\"{str(epochs) if epochs else 'N/A':<12}\"\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for name, res in results.items():\n",
    "    # Find best accuracy epoch\n",
    "    best_acc_epoch = np.argmax(res['accuracies']) + 1\n",
    "    best_acc = max(res['accuracies'])\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Optimizer': name,\n",
    "        'Final Loss': f\"{res['final_loss']:.4f}\",\n",
    "        'Final Accuracy': f\"{res['final_accuracy']:.1%}\",\n",
    "        'Best Accuracy': f\"{best_acc:.1%}\",\n",
    "        'Best Acc Epoch': best_acc_epoch,\n",
    "        'Loss @ Epoch 10': f\"{res['losses'][9]:.4f}\" if len(res['losses']) > 9 else 'N/A',\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"SOEN OPTIMIZER COMPARISON SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nModel: 1D → 3D (SingleDendrite) → 2D\")\n",
    "print(f\"Task: Binary pulse classification\")\n",
    "print(f\"Epochs: {N_EPOCHS}, Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Samples: {N_SAMPLES}\\n\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 9. Visualize Best Model's Output\n",
    "\n",
    "Show how the trained model processes single vs double pulse inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best performing optimizer\n",
    "best_name = max(results, key=lambda x: results[x]['final_accuracy'])\n",
    "best_model = results[best_name]['model']\n",
    "print(f\"Best optimizer: {best_name} (Acc={results[best_name]['final_accuracy']:.1%})\")\n",
    "\n",
    "# Test on sample inputs\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get one sample of each class\n",
    "    single_pulse_idx = (y_data == 0).nonzero()[0].item()\n",
    "    double_pulse_idx = (y_data == 1).nonzero()[0].item()\n",
    "    \n",
    "    test_inputs = torch.stack([X_data[single_pulse_idx], X_data[double_pulse_idx]])\n",
    "    test_labels = torch.tensor([0, 1])\n",
    "    \n",
    "    final_hist, all_hist = best_model(test_inputs)\n",
    "\n",
    "# Plot state trajectories\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for row, (label, name) in enumerate([(0, 'Single Pulse'), (1, 'Double Pulse')]):\n",
    "    # Input\n",
    "    axes[row, 0].plot(test_inputs[row, :, 0].numpy())\n",
    "    axes[row, 0].set_title(f'{name}: Input Flux')\n",
    "    axes[row, 0].set_xlabel('Time step')\n",
    "    axes[row, 0].set_ylabel('Flux')\n",
    "    axes[row, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hidden layer states (SingleDendrite neurons)\n",
    "    hidden_states = all_hist[1][row, 1:, :].numpy()  # [seq_len, hidden_dim]\n",
    "    for n in range(hidden_states.shape[1]):\n",
    "        axes[row, 1].plot(hidden_states[:, n], label=f'Neuron {n}')\n",
    "    axes[row, 1].set_title(f'{name}: SingleDendrite States (s)')\n",
    "    axes[row, 1].set_xlabel('Time step')\n",
    "    axes[row, 1].set_ylabel('State (s)')\n",
    "    axes[row, 1].legend()\n",
    "    axes[row, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Output layer\n",
    "    output_states = all_hist[2][row, 1:, :].numpy()  # [seq_len, output_dim]\n",
    "    axes[row, 2].plot(output_states[:, 0], label='Class 0 (Single)')\n",
    "    axes[row, 2].plot(output_states[:, 1], label='Class 1 (Double)')\n",
    "    axes[row, 2].set_title(f'{name}: Output Layer')\n",
    "    axes[row, 2].set_xlabel('Time step')\n",
    "    axes[row, 2].set_ylabel('Output')\n",
    "    axes[row, 2].legend()\n",
    "    axes[row, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Best Model ({best_name}) - State Trajectories', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 10. Key Observations\n",
    "\n",
    "### SOEN-Specific Training Insights:\n",
    "\n",
    "| Optimizer | Characteristics for SOEN |\n",
    "|-----------|-------------------------|\n",
    "| **SGD (low lr)** | Stable but slow; may need many epochs for SOEN dynamics |\n",
    "| **SGD (high lr)** | Risk of instability with SOEN's nonlinear dynamics |\n",
    "| **SGD + Momentum** | Helps navigate SOEN's complex loss landscape |\n",
    "| **Adam** | Generally good default; adaptive to SOEN's varying gradients |\n",
    "| **AdamW** | Better regularization for SOEN weights |\n",
    "| **RMSprop** | Good for SOEN's non-stationary gradient statistics |\n",
    "\n",
    "### SOEN Training Considerations:\n",
    "- **Gradient clipping** is often necessary due to exploding gradients through time\n",
    "- **Learning rate** must be tuned carefully for the SingleDendrite dynamics\n",
    "- **Time pooling** strategy (mean, max, final) affects gradient flow\n",
    "- Connection weight constraints (min/max) affect optimization landscape\n",
    "\n",
    "### Physical Mapping:\n",
    "- Each `SingleDendrite` unit corresponds to **one physical neuron** on SOEN hardware\n",
    "- This 3-neuron hidden layer model would map to 3 physical neurons on a SOEN chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook complete!\")\n",
    "print(f\"\\nBest performing optimizer: {best_name}\")\n",
    "print(f\"Final accuracy: {results[best_name]['final_accuracy']:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
