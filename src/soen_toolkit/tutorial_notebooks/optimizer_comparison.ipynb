{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PyTorch Optimizer Comparison on SOEN SingleDendrite Model\n",
    "\n",
    "This notebook compares different PyTorch optimizers on a **minimal SOEN model** with `SingleDendrite` neurons.\n",
    "\n",
    "## Model Architecture\n",
    "- **Input Layer**: 1D flux input\n",
    "- **Hidden Layer**: 1 SingleDendrite neuron (physical SOEN neuron)\n",
    "- **Output Layer**: 1D readout\n",
    "\n",
    "## Trainable Parameters: Exactly 2\n",
    "- **J_input**: Input connection weight (1×1 = 1 parameter)\n",
    "- **J_output**: Output connection weight (1×1 = 1 parameter)\n",
    "\n",
    "## Task\n",
    "Linear regression: learn to map input flux to target output through SingleDendrite dynamics.\n",
    "\n",
    "## Optimizers Compared\n",
    "1. **SGD** - Vanilla Stochastic Gradient Descent\n",
    "2. **SGD + Momentum** - SGD with momentum\n",
    "3. **Adam** - Adaptive Moment Estimation\n",
    "4. **AdamW** - Adam with decoupled weight decay\n",
    "5. **RMSprop** - Root Mean Square Propagation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from soen_toolkit.core import (\n",
    "    ConnectionConfig,\n",
    "    LayerConfig,\n",
    "    SimulationConfig,\n",
    "    SOENModelCore,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Regression Data\n",
    "\n",
    "Create a simple linear regression dataset where the target is a scaled version of the input.\n",
    "The SOEN model will learn to approximate this mapping through its SingleDendrite dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regression_data(n_samples=100, seq_len=30, noise_std=0.01):\n",
    "    \"\"\"\n",
    "    Generate regression data: constant input signals with scalar targets.\n",
    "    \n",
    "    The SOEN model receives a constant flux input and should produce\n",
    "    an output that matches the target (a linear function of the input).\n",
    "    \n",
    "    Returns:\n",
    "        X: [n_samples, seq_len, 1] - input flux sequences (constant per sample)\n",
    "        y: [n_samples, 1] - regression targets\n",
    "    \"\"\"\n",
    "    # Ground truth relationship: y = 2.0 * x + 0.5\n",
    "    TRUE_SCALE = 2.0\n",
    "    TRUE_OFFSET = 0.5\n",
    "    \n",
    "    # Generate input values (flux magnitudes)\n",
    "    x_values = torch.linspace(0.05, 0.2, n_samples)  # Within SOEN operating range\n",
    "    \n",
    "    # Create constant input sequences\n",
    "    X = x_values.unsqueeze(1).unsqueeze(2).expand(-1, seq_len, 1).clone()\n",
    "    \n",
    "    # Add small noise to inputs\n",
    "    X = X + noise_std * torch.randn_like(X)\n",
    "    \n",
    "    # Generate targets (what the final state should approximate)\n",
    "    y = TRUE_SCALE * x_values + TRUE_OFFSET\n",
    "    y = y.unsqueeze(1)  # [n_samples, 1]\n",
    "    \n",
    "    return X, y, TRUE_SCALE, TRUE_OFFSET\n",
    "\n",
    "# Generate data\n",
    "N_SAMPLES = 100\n",
    "SEQ_LEN = 30\n",
    "X_data, y_data, TRUE_SCALE, TRUE_OFFSET = generate_regression_data(N_SAMPLES, SEQ_LEN)\n",
    "\n",
    "print(f\"Input shape: {X_data.shape}\")\n",
    "print(f\"Target shape: {y_data.shape}\")\n",
    "print(f\"Ground truth: y = {TRUE_SCALE} * x + {TRUE_OFFSET}\")\n",
    "print(f\"Input range: [{X_data.mean(dim=1).min():.3f}, {X_data.mean(dim=1).max():.3f}]\")\n",
    "print(f\"Target range: [{y_data.min():.3f}, {y_data.max():.3f}]\")\n",
    "\n",
    "# Visualize data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Input-output relationship\n",
    "x_means = X_data.mean(dim=1).squeeze().numpy()\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(x_means, y_data.squeeze().numpy(), alpha=0.6, label='Data')\n",
    "ax1.plot(x_means, TRUE_SCALE * x_means + TRUE_OFFSET, 'r-', linewidth=2, \n",
    "         label=f'True: y = {TRUE_SCALE}x + {TRUE_OFFSET}')\n",
    "ax1.set_xlabel('Input flux (mean)')\n",
    "ax1.set_ylabel('Target')\n",
    "ax1.set_title('Regression Task')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Sample input sequences\n",
    "ax2 = axes[1]\n",
    "for i in [0, 25, 50, 75, 99]:\n",
    "    ax2.plot(X_data[i, :, 0].numpy(), label=f'Sample {i}')\n",
    "ax2.set_xlabel('Time step')\n",
    "ax2.set_ylabel('Input flux')\n",
    "ax2.set_title('Sample Input Sequences')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Build Minimal SOEN Model (2 Trainable Parameters)\n",
    "\n",
    "Architecture: 1D → 1D (SingleDendrite) → 1D\n",
    "\n",
    "- **J_input** (1×1): Weight from input to SingleDendrite neuron\n",
    "- **J_output** (1×1): Weight from SingleDendrite to output\n",
    "\n",
    "Total: **2 trainable parameters**\n",
    "\n",
    "The SingleDendrite dynamics are:\n",
    "$$\\frac{ds}{dt} = \\gamma^+ \\cdot g(\\phi) - \\gamma^- \\cdot s$$\n",
    "\n",
    "where $\\phi = J_{input} \\cdot x$ is the weighted input flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_minimal_soen_model(dt=50.0, init_j_in=0.15, init_j_out=1.0):\n",
    "    \"\"\"\n",
    "    Build a minimal SOEN model with exactly 2 trainable parameters.\n",
    "    \n",
    "    Architecture: 1 (input) → 1 (SingleDendrite) → 1 (output)\n",
    "    Trainable: J_input (1x1) and J_output (1x1) = 2 parameters\n",
    "    \"\"\"\n",
    "    sim_cfg = SimulationConfig(\n",
    "        dt=dt,\n",
    "        input_type=\"state\",\n",
    "        track_phi=False,\n",
    "        track_power=False,\n",
    "    )\n",
    "    \n",
    "    # Layer 0: Single input channel\n",
    "    layer0 = LayerConfig(\n",
    "        layer_id=0,\n",
    "        layer_type=\"Input\",\n",
    "        description=\"Input flux\",\n",
    "        params={\"dim\": 1},\n",
    "    )\n",
    "    \n",
    "    # Layer 1: Single SingleDendrite neuron\n",
    "    layer1 = LayerConfig(\n",
    "        layer_id=1,\n",
    "        layer_type=\"SingleDendrite\",\n",
    "        description=\"SOEN neuron\",\n",
    "        params={\n",
    "            \"dim\": 1,  # Single neuron\n",
    "            \"solver\": \"FE\",\n",
    "            \"source_func\": \"Heaviside_fit_state_dep\",\n",
    "            \"phi_offset\": 0.02,\n",
    "            \"bias_current\": 1.98,\n",
    "            \"gamma_plus\": 0.0005,  # Faster dynamics for shorter sequences\n",
    "            \"gamma_minus\": 1e-6,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # Layer 2: Single output\n",
    "    layer2 = LayerConfig(\n",
    "        layer_id=2,\n",
    "        layer_type=\"Input\",\n",
    "        description=\"Output\",\n",
    "        params={\"dim\": 1},\n",
    "    )\n",
    "    \n",
    "    layers = [layer0, layer1, layer2]\n",
    "    \n",
    "    # Connection 0→1: Input weight (1 parameter)\n",
    "    conn01 = ConnectionConfig(\n",
    "        from_layer=0,\n",
    "        to_layer=1,\n",
    "        connection_type=\"all_to_all\",  # 1x1 = 1 parameter\n",
    "        learnable=True,\n",
    "        params={\n",
    "            \"init\": \"constant\",\n",
    "            \"value\": init_j_in,\n",
    "            \"constraints\": {\"min\": -0.5, \"max\": 0.5},\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # Connection 1→2: Output weight (1 parameter)\n",
    "    conn12 = ConnectionConfig(\n",
    "        from_layer=1,\n",
    "        to_layer=2,\n",
    "        connection_type=\"all_to_all\",  # 1x1 = 1 parameter\n",
    "        learnable=True,\n",
    "        params={\n",
    "            \"init\": \"constant\",\n",
    "            \"value\": init_j_out,\n",
    "            \"constraints\": {\"min\": -5.0, \"max\": 5.0},\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    connections = [conn01, conn12]\n",
    "    \n",
    "    model = SOENModelCore(\n",
    "        sim_config=sim_cfg,\n",
    "        layers_config=layers,\n",
    "        connections_config=connections,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and verify model\n",
    "test_model = build_minimal_soen_model()\n",
    "print(\"Model Structure:\")\n",
    "print(f\"  Layers: {[l.dim for l in test_model.layers]}\")\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = [(name, p) for name, p in test_model.named_parameters() if p.requires_grad]\n",
    "total_trainable = sum(p.numel() for _, p in trainable_params)\n",
    "\n",
    "print(f\"\\nTrainable Parameters: {total_trainable}\")\n",
    "for name, param in trainable_params:\n",
    "    print(f\"  {name}: shape={list(param.shape)}, value={param.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture\n",
    "test_model.visualize(show_descriptions=True, theme=\"modern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Visualize Loss Landscape\n",
    "\n",
    "Compute MSE loss over a grid of (J_input, J_output) values to see the optimization landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_soen_loss(model, X, y):\n",
    "    \"\"\"Compute MSE loss for SOEN model.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_hist, _ = model(X)\n",
    "        # Take final time step as output\n",
    "        output = final_hist[:, -1, :]  # [batch, 1]\n",
    "        loss = ((output - y) ** 2).mean()\n",
    "    return loss.item()\n",
    "\n",
    "def compute_loss_landscape_soen(X_data, y_data, j_in_range, j_out_range, resolution=30):\n",
    "    \"\"\"\n",
    "    Compute loss landscape by evaluating SOEN model at grid of (J_in, J_out) values.\n",
    "    \"\"\"\n",
    "    j_in_vals = np.linspace(j_in_range[0], j_in_range[1], resolution)\n",
    "    j_out_vals = np.linspace(j_out_range[0], j_out_range[1], resolution)\n",
    "    J_IN, J_OUT = np.meshgrid(j_in_vals, j_out_vals)\n",
    "    \n",
    "    loss_surface = np.zeros_like(J_IN)\n",
    "    \n",
    "    # Use subset of data for faster computation\n",
    "    X_subset = X_data[::5]  # Every 5th sample\n",
    "    y_subset = y_data[::5]\n",
    "    \n",
    "    for i in range(resolution):\n",
    "        for j in range(resolution):\n",
    "            j_in, j_out = J_IN[i, j], J_OUT[i, j]\n",
    "            model = build_minimal_soen_model(init_j_in=j_in, init_j_out=j_out)\n",
    "            loss_surface[i, j] = compute_soen_loss(model, X_subset, y_subset)\n",
    "    \n",
    "    return J_IN, J_OUT, loss_surface\n",
    "\n",
    "# Compute loss landscape\n",
    "print(\"Computing loss landscape (this may take a moment)...\")\n",
    "J_IN_RANGE = (0.05, 0.35)\n",
    "J_OUT_RANGE = (0.5, 3.5)\n",
    "J_IN, J_OUT, loss_surface = compute_loss_landscape_soen(\n",
    "    X_data, y_data, J_IN_RANGE, J_OUT_RANGE, resolution=25\n",
    ")\n",
    "print(\"Done!\")\n",
    "\n",
    "# Find approximate minimum\n",
    "min_idx = np.unravel_index(np.argmin(loss_surface), loss_surface.shape)\n",
    "OPT_J_IN = J_IN[min_idx]\n",
    "OPT_J_OUT = J_OUT[min_idx]\n",
    "print(f\"\\nApproximate optimum: J_in={OPT_J_IN:.3f}, J_out={OPT_J_OUT:.3f}\")\n",
    "print(f\"Minimum loss: {loss_surface[min_idx]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss landscape\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 3D surface\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot_surface(J_IN, J_OUT, loss_surface, cmap='viridis', alpha=0.8)\n",
    "ax1.scatter([OPT_J_IN], [OPT_J_OUT], [loss_surface[min_idx]], \n",
    "            color='red', s=100, marker='*', label='Optimum')\n",
    "ax1.set_xlabel('J_input')\n",
    "ax1.set_ylabel('J_output')\n",
    "ax1.set_zlabel('MSE Loss')\n",
    "ax1.set_title('SOEN Loss Landscape (3D)')\n",
    "\n",
    "# Contour plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "contour = ax2.contour(J_IN, J_OUT, loss_surface, levels=30, cmap='viridis')\n",
    "ax2.clabel(contour, inline=True, fontsize=8)\n",
    "ax2.scatter([OPT_J_IN], [OPT_J_OUT], color='red', s=100, marker='*', \n",
    "            zorder=5, label=f'Optimum ({OPT_J_IN:.2f}, {OPT_J_OUT:.2f})')\n",
    "ax2.set_xlabel('J_input')\n",
    "ax2.set_ylabel('J_output')\n",
    "ax2.set_title('SOEN Loss Landscape (Contour)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Training Function with Trajectory Tracking\n",
    "\n",
    "Train the SOEN model and record the parameter trajectory in (J_in, J_out) space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainable_params(model):\n",
    "    \"\"\"Extract J_input and J_output values from model.\"\"\"\n",
    "    params = {}\n",
    "    for name, p in model.named_parameters():\n",
    "        if p.requires_grad:\n",
    "            if 'connection_0_to_1' in name:\n",
    "                params['j_in'] = p.item()\n",
    "            elif 'connection_1_to_2' in name:\n",
    "                params['j_out'] = p.item()\n",
    "    return params['j_in'], params['j_out']\n",
    "\n",
    "def train_soen_model(optimizer_class, optimizer_kwargs, X_data, y_data,\n",
    "                     n_epochs=100, init_j_in=0.1, init_j_out=0.8, verbose=False):\n",
    "    \"\"\"\n",
    "    Train a minimal SOEN model and track the optimization trajectory.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with losses, trajectory, final parameters\n",
    "    \"\"\"\n",
    "    # Build fresh model with specified initial parameters\n",
    "    model = build_minimal_soen_model(init_j_in=init_j_in, init_j_out=init_j_out)\n",
    "    model.train()\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_kwargs)\n",
    "    \n",
    "    # Tracking\n",
    "    losses = []\n",
    "    trajectory = [get_trainable_params(model)]  # Starting point\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        final_hist, _ = model(X_data)\n",
    "        \n",
    "        # Take final time step as output\n",
    "        output = final_hist[:, -1, :]  # [batch, 1]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, y_data)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        trajectory.append(get_trainable_params(model))\n",
    "        \n",
    "        if verbose and (epoch + 1) % 20 == 0:\n",
    "            j_in, j_out = trajectory[-1]\n",
    "            print(f\"  Epoch {epoch+1}: Loss={loss.item():.6f}, J_in={j_in:.4f}, J_out={j_out:.4f}\")\n",
    "    \n",
    "    final_j_in, final_j_out = get_trainable_params(model)\n",
    "    \n",
    "    return {\n",
    "        'losses': losses,\n",
    "        'trajectory': trajectory,\n",
    "        'final_j_in': final_j_in,\n",
    "        'final_j_out': final_j_out,\n",
    "        'model': model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Compare Optimizers\n",
    "\n",
    "Train the 2-parameter SOEN model with different optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer configurations\n",
    "OPTIMIZERS = {\n",
    "    'SGD (lr=0.1)': (torch.optim.SGD, {'lr': 0.1}),\n",
    "    'SGD (lr=0.5)': (torch.optim.SGD, {'lr': 0.5}),\n",
    "    'SGD + Momentum': (torch.optim.SGD, {'lr': 0.1, 'momentum': 0.9}),\n",
    "    'Adam (lr=0.05)': (torch.optim.Adam, {'lr': 0.05}),\n",
    "    'Adam (lr=0.01)': (torch.optim.Adam, {'lr': 0.01}),\n",
    "    'AdamW': (torch.optim.AdamW, {'lr': 0.05}),\n",
    "    'RMSprop': (torch.optim.RMSprop, {'lr': 0.05}),\n",
    "}\n",
    "\n",
    "# Common starting point (away from optimum)\n",
    "INIT_J_IN = 0.1\n",
    "INIT_J_OUT = 0.8\n",
    "N_EPOCHS = 100\n",
    "\n",
    "# Train with each optimizer\n",
    "results = {}\n",
    "for name, (opt_class, opt_kwargs) in OPTIMIZERS.items():\n",
    "    print(f\"Training with {name}...\")\n",
    "    results[name] = train_soen_model(\n",
    "        opt_class, opt_kwargs, X_data, y_data,\n",
    "        n_epochs=N_EPOCHS, init_j_in=INIT_J_IN, init_j_out=INIT_J_OUT, verbose=False\n",
    "    )\n",
    "    print(f\"  Final: J_in={results[name]['final_j_in']:.4f}, \"\n",
    "          f\"J_out={results[name]['final_j_out']:.4f}, \"\n",
    "          f\"Loss={results[name]['losses'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\nApproximate optimum: J_in={OPT_J_IN:.3f}, J_out={OPT_J_OUT:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Visualize Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(results)))\n",
    "\n",
    "# Linear scale\n",
    "ax1 = axes[0]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    ax1.plot(res['losses'], label=name, linewidth=2, color=color)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('MSE Loss')\n",
    "ax1.set_title('SOEN Training Loss (Linear Scale)')\n",
    "ax1.legend(loc='upper right', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log scale\n",
    "ax2 = axes[1]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    ax2.plot(res['losses'], label=name, linewidth=2, color=color)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MSE Loss (log scale)')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title('SOEN Training Loss (Log Scale)')\n",
    "ax2.legend(loc='upper right', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Visualize Optimization Trajectories\n",
    "\n",
    "Show how each optimizer navigates the SOEN loss landscape in (J_in, J_out) parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectories on contour\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Background contour\n",
    "contour = ax.contour(J_IN, J_OUT, loss_surface, levels=30, cmap='gray', alpha=0.5)\n",
    "ax.contourf(J_IN, J_OUT, loss_surface, levels=30, cmap='viridis', alpha=0.3)\n",
    "\n",
    "# Plot each trajectory\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    traj = np.array(res['trajectory'])\n",
    "    ax.plot(traj[:, 0], traj[:, 1], '-', color=color, linewidth=2, label=name, alpha=0.8)\n",
    "    ax.scatter(traj[0, 0], traj[0, 1], color=color, s=100, marker='o', edgecolor='black', zorder=5)\n",
    "    ax.scatter(traj[-1, 0], traj[-1, 1], color=color, s=100, marker='s', edgecolor='black', zorder=5)\n",
    "\n",
    "# Mark optimum and start\n",
    "ax.scatter([OPT_J_IN], [OPT_J_OUT], color='red', s=200, marker='*', \n",
    "           zorder=10, label=f'Optimum ({OPT_J_IN:.2f}, {OPT_J_OUT:.2f})')\n",
    "ax.scatter([INIT_J_IN], [INIT_J_OUT], color='black', s=150, marker='X', \n",
    "           zorder=10, label=f'Start ({INIT_J_IN}, {INIT_J_OUT})')\n",
    "\n",
    "ax.set_xlabel('J_input (input weight)', fontsize=12)\n",
    "ax.set_ylabel('J_output (output weight)', fontsize=12)\n",
    "ax.set_title('SOEN Optimization Trajectories in Parameter Space', fontsize=14)\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(J_IN_RANGE)\n",
    "ax.set_ylim(J_OUT_RANGE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. Zoomed Trajectory Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual trajectory plots\n",
    "n_opts = len(results)\n",
    "cols = 4\n",
    "rows = (n_opts + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 4*rows))\n",
    "axes = axes.flatten() if n_opts > 1 else [axes]\n",
    "\n",
    "for idx, ((name, res), color) in enumerate(zip(results.items(), colors)):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Background\n",
    "    ax.contourf(J_IN, J_OUT, loss_surface, levels=20, cmap='viridis', alpha=0.4)\n",
    "    ax.contour(J_IN, J_OUT, loss_surface, levels=20, cmap='gray', alpha=0.3)\n",
    "    \n",
    "    # Trajectory\n",
    "    traj = np.array(res['trajectory'])\n",
    "    ax.plot(traj[:, 0], traj[:, 1], 'o-', color=color, linewidth=2, markersize=3, alpha=0.8)\n",
    "    ax.scatter(traj[0, 0], traj[0, 1], color='black', s=80, marker='o', zorder=5)\n",
    "    ax.scatter(traj[-1, 0], traj[-1, 1], color=color, s=80, marker='s', edgecolor='black', zorder=5)\n",
    "    ax.scatter([OPT_J_IN], [OPT_J_OUT], color='red', s=100, marker='*', zorder=10)\n",
    "    \n",
    "    ax.set_title(f'{name}\\nFinal loss: {res[\"losses\"][-1]:.6f}', fontsize=10)\n",
    "    ax.set_xlabel('J_input')\n",
    "    ax.set_ylabel('J_output')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_opts, len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Individual Optimizer Trajectories', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 9. Parameter Evolution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# J_input evolution\n",
    "ax1 = axes[0]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    traj = np.array(res['trajectory'])\n",
    "    ax1.plot(traj[:, 0], label=name, color=color, linewidth=2)\n",
    "ax1.axhline(y=OPT_J_IN, color='red', linestyle='--', linewidth=2, label=f'Optimum={OPT_J_IN:.2f}')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('J_input')\n",
    "ax1.set_title('Input Weight Evolution')\n",
    "ax1.legend(loc='best', fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# J_output evolution\n",
    "ax2 = axes[1]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    traj = np.array(res['trajectory'])\n",
    "    ax2.plot(traj[:, 1], label=name, color=color, linewidth=2)\n",
    "ax2.axhline(y=OPT_J_OUT, color='red', linestyle='--', linewidth=2, label=f'Optimum={OPT_J_OUT:.2f}')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('J_output')\n",
    "ax2.set_title('Output Weight Evolution')\n",
    "ax2.legend(loc='best', fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for name, res in results.items():\n",
    "    j_in_error = abs(res['final_j_in'] - OPT_J_IN)\n",
    "    j_out_error = abs(res['final_j_out'] - OPT_J_OUT)\n",
    "    param_dist = np.sqrt(j_in_error**2 + j_out_error**2)\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Optimizer': name,\n",
    "        'Final Loss': f\"{res['losses'][-1]:.6f}\",\n",
    "        'Final J_in': f\"{res['final_j_in']:.4f}\",\n",
    "        'Final J_out': f\"{res['final_j_out']:.4f}\",\n",
    "        'J_in Error': f\"{j_in_error:.4f}\",\n",
    "        'J_out Error': f\"{j_out_error:.4f}\",\n",
    "        'Dist to Opt': f\"{param_dist:.4f}\",\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "print(\"=\" * 100)\n",
    "print(\"SOEN OPTIMIZER COMPARISON SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nModel: 1D → 1D (SingleDendrite) → 1D\")\n",
    "print(f\"Trainable parameters: 2 (J_input, J_output)\")\n",
    "print(f\"Task: Linear regression through SOEN dynamics\")\n",
    "print(f\"Approximate optimum: J_in={OPT_J_IN:.3f}, J_out={OPT_J_OUT:.3f}\")\n",
    "print(f\"Starting point: J_in={INIT_J_IN}, J_out={INIT_J_OUT}\")\n",
    "print(f\"Epochs: {N_EPOCHS}\\n\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 11. Convergence Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_to_threshold(losses, threshold):\n",
    "    \"\"\"Return number of epochs to reach loss threshold.\"\"\"\n",
    "    for i, loss in enumerate(losses):\n",
    "        if loss <= threshold:\n",
    "            return i + 1\n",
    "    return None\n",
    "\n",
    "# Find reasonable thresholds based on results\n",
    "min_final_loss = min(res['losses'][-1] for res in results.values())\n",
    "thresholds = [0.1, 0.05, 0.02, 0.01, min_final_loss * 2]\n",
    "\n",
    "print(\"Epochs to reach loss threshold:\")\n",
    "print(\"-\" * 90)\n",
    "header = f\"{'Optimizer':<20}\" + \"\".join([f\"Loss<{t:.4f}  \" for t in thresholds])\n",
    "print(header)\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for name, res in results.items():\n",
    "    row = f\"{name:<20}\"\n",
    "    for thresh in thresholds:\n",
    "        epochs = epochs_to_threshold(res['losses'], thresh)\n",
    "        row += f\"{str(epochs) if epochs else 'N/A':<14}\"\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 12. Visualize Best Model's Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best performing optimizer\n",
    "best_name = min(results, key=lambda x: results[x]['losses'][-1])\n",
    "best_model = results[best_name]['model']\n",
    "print(f\"Best optimizer: {best_name}\")\n",
    "print(f\"Final loss: {results[best_name]['losses'][-1]:.6f}\")\n",
    "\n",
    "# Get predictions\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    final_hist, all_hist = best_model(X_data)\n",
    "    predictions = final_hist[:, -1, :].squeeze().numpy()\n",
    "\n",
    "# Plot predictions vs targets\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Scatter plot\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_data.squeeze().numpy(), predictions, alpha=0.6)\n",
    "ax1.plot([y_data.min(), y_data.max()], [y_data.min(), y_data.max()], 'r--', linewidth=2)\n",
    "ax1.set_xlabel('True Target')\n",
    "ax1.set_ylabel('SOEN Prediction')\n",
    "ax1.set_title(f'Predictions vs Targets ({best_name})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Input vs output relationship\n",
    "ax2 = axes[1]\n",
    "x_means = X_data.mean(dim=1).squeeze().numpy()\n",
    "ax2.scatter(x_means, y_data.squeeze().numpy(), alpha=0.5, label='True targets')\n",
    "ax2.scatter(x_means, predictions, alpha=0.5, label='SOEN predictions')\n",
    "ax2.set_xlabel('Input flux (mean)')\n",
    "ax2.set_ylabel('Output')\n",
    "ax2.set_title('SOEN Model: Input-Output Relationship')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 13. Key Observations\n",
    "\n",
    "### Model Summary\n",
    "- **Architecture**: 1D → 1D (SingleDendrite) → 1D\n",
    "- **Trainable parameters**: Exactly 2 (J_input, J_output)\n",
    "- **Task**: Linear regression through SOEN neuron dynamics\n",
    "\n",
    "### SingleDendrite Dynamics\n",
    "The neuron evolves according to:\n",
    "$$\\frac{ds}{dt} = \\gamma^+ \\cdot g(\\phi_{eff}) - \\gamma^- \\cdot s$$\n",
    "\n",
    "where:\n",
    "- $\\phi_{eff} = J_{input} \\cdot x + \\phi_{offset}$ (effective input flux)\n",
    "- $g(\\cdot)$ is the source function (Heaviside fit)\n",
    "- Output = $J_{output} \\cdot s_{final}$\n",
    "\n",
    "### Optimizer Behavior on SOEN\n",
    "| Optimizer | Characteristics |\n",
    "|-----------|----------------|\n",
    "| **SGD** | Predictable path, may be slow |\n",
    "| **SGD + Momentum** | Faster convergence, smoother trajectory |\n",
    "| **Adam** | Adaptive learning, good for SOEN's varying gradients |\n",
    "| **AdamW** | Adam with weight decay regularization |\n",
    "| **RMSprop** | Good for non-stationary objectives |\n",
    "\n",
    "### Physical Mapping\n",
    "This 1-neuron model would map to **1 physical SingleDendrite neuron** on SOEN hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Notebook complete!\")\n",
    "print(f\"\\nBest optimizer: {best_name}\")\n",
    "print(f\"Final parameters: J_in={results[best_name]['final_j_in']:.4f}, J_out={results[best_name]['final_j_out']:.4f}\")\n",
    "print(f\"Final loss: {results[best_name]['losses'][-1]:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
