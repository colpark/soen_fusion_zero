{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST with Equilibrium Propagation (EP)\n",
    "\n",
    "**Equilibrium Propagation** as a remedy for vanishing gradients in long sequences.\n",
    "\n",
    "## Why EP?\n",
    "\n",
    "| Problem with BPTT | EP Solution |\n",
    "|-------------------|-------------|\n",
    "| Gradients through 112 steps → vanish | No backprop through time |\n",
    "| Gradient ≈ (W)^112 → exponential decay | State differences encode gradient |\n",
    "| Non-local, expensive | Local Hebbian-like updates |\n",
    "\n",
    "## Architecture (unchanged)\n",
    "\n",
    "```\n",
    "Input (7) → Hidden (28) → Output (10)\n",
    "               ↺ recurrent\n",
    "```\n",
    "\n",
    "## EP Algorithm\n",
    "\n",
    "```\n",
    "FREE PHASE:     Process input → Settle to equilibrium → Record states\n",
    "NUDGED PHASE:   Push output toward target → Re-settle → Record states  \n",
    "WEIGHT UPDATE:  ΔW ∝ (state_nudged - state_free) × pre_activation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data (112×7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "def load_mnist_112x7():\n",
    "    \"\"\"Load MNIST as (N, 112, 7) sequences.\"\"\"\n",
    "    train_img = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    train_lbl = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_img = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    test_lbl = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    # Reshape to 112 timesteps × 7 features\n",
    "    train_img = train_img.reshape(-1, 784).reshape(-1, 112, 7)\n",
    "    test_img = test_img.reshape(-1, 784).reshape(-1, 112, 7)\n",
    "    \n",
    "    # Train/val split\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(train_img))\n",
    "    n_val = 6000\n",
    "    \n",
    "    val_img, val_lbl = train_img[idx[:n_val]], train_lbl[idx[:n_val]]\n",
    "    train_img, train_lbl = train_img[idx[n_val:]], train_lbl[idx[n_val:]]\n",
    "    \n",
    "    print(f\"Train: {train_img.shape}, Val: {val_img.shape}, Test: {test_img.shape}\")\n",
    "    return (train_img, train_lbl), (val_img, val_lbl), (test_img, test_lbl)\n",
    "\n",
    "(train_data, train_labels), (val_data, val_labels), (test_data, test_labels) = load_mnist_112x7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SOEN-EP Model\n",
    "\n",
    "SingleDendrite dynamics:\n",
    "$$\\frac{ds}{dt} = \\gamma^+ g(\\phi) - \\gamma^- s$$\n",
    "\n",
    "where $\\phi = W_{in} x + W_{rec} s$ and $g$ is the source function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOEN_EP_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    SOEN model with Equilibrium Propagation training.\n",
    "    \n",
    "    Architecture: 7 → 28 → 10\n",
    "    \n",
    "    Key difference from standard training:\n",
    "    - Two-phase forward: free phase + nudged phase\n",
    "    - Weight updates from state differences (no BPTT)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=7, hidden_dim=28, output_dim=10, dt=0.1,\n",
    "                 gamma_plus=0.1, gamma_minus=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dt = dt\n",
    "        self.gamma_plus = gamma_plus\n",
    "        self.gamma_minus = gamma_minus\n",
    "        \n",
    "        # Weight matrices (same structure as baseline)\n",
    "        self.W_i2h = nn.Parameter(torch.empty(hidden_dim, input_dim))  # 28 × 7\n",
    "        self.W_h2h = nn.Parameter(torch.empty(hidden_dim, hidden_dim))  # 28 × 28\n",
    "        self.W_h2o = nn.Parameter(torch.empty(output_dim, hidden_dim))  # 10 × 28\n",
    "        \n",
    "        # Bias\n",
    "        self.bias_h = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.bias_o = nn.Parameter(torch.zeros(output_dim))\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        nn.init.uniform_(self.W_i2h, -0.3, 0.3)\n",
    "        nn.init.normal_(self.W_h2h, 0, 0.1)\n",
    "        nn.init.normal_(self.W_h2o, 0, 0.2)\n",
    "        # Remove self-connections in recurrent\n",
    "        with torch.no_grad():\n",
    "            self.W_h2h.fill_diagonal_(0)\n",
    "    \n",
    "    def source_function(self, phi):\n",
    "        \"\"\"Approximate Heaviside/sigmoid source function.\"\"\"\n",
    "        # Smooth approximation of SOEN source function\n",
    "        return torch.sigmoid(5 * phi)\n",
    "    \n",
    "    def hidden_dynamics(self, s, phi):\n",
    "        \"\"\"\n",
    "        SingleDendrite dynamics: ds/dt = γ⁺ g(φ) - γ⁻ s\n",
    "        \"\"\"\n",
    "        g = self.source_function(phi)\n",
    "        dsdt = self.gamma_plus * g - self.gamma_minus * s\n",
    "        return s + self.dt * dsdt\n",
    "    \n",
    "    def compute_phi(self, x, s, feedback=None):\n",
    "        \"\"\"\n",
    "        Compute total flux: φ = W_i2h @ x + W_h2h @ s + bias + feedback\n",
    "        \"\"\"\n",
    "        phi = F.linear(x, self.W_i2h, self.bias_h) + F.linear(s, self.W_h2h)\n",
    "        if feedback is not None:\n",
    "            phi = phi + feedback\n",
    "        return phi\n",
    "    \n",
    "    def compute_output(self, s):\n",
    "        \"\"\"Output layer: linear readout.\"\"\"\n",
    "        return F.linear(s, self.W_h2o, self.bias_o)\n",
    "    \n",
    "    def free_phase(self, x, settle_steps=20):\n",
    "        \"\"\"\n",
    "        FREE PHASE: Process input sequence and settle to equilibrium.\n",
    "        \n",
    "        Args:\n",
    "            x: Input sequence (batch, 112, 7)\n",
    "            settle_steps: Additional steps after input to reach equilibrium\n",
    "            \n",
    "        Returns:\n",
    "            s_free: Hidden state at equilibrium\n",
    "            o_free: Output at equilibrium\n",
    "            s_history: Hidden states during processing (for analysis)\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        s = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "        s_history = []\n",
    "        \n",
    "        # Process all 112 timesteps\n",
    "        for t in range(seq_len):\n",
    "            phi = self.compute_phi(x[:, t], s)\n",
    "            s = self.hidden_dynamics(s, phi)\n",
    "            if t % 10 == 0:  # Store every 10th for analysis\n",
    "                s_history.append(s.detach().clone())\n",
    "        \n",
    "        # Additional settling (no new input)\n",
    "        x_zero = torch.zeros(batch_size, self.input_dim, device=x.device)\n",
    "        for _ in range(settle_steps):\n",
    "            phi = self.compute_phi(x_zero, s)\n",
    "            s = self.hidden_dynamics(s, phi)\n",
    "        \n",
    "        s_free = s\n",
    "        o_free = self.compute_output(s_free)\n",
    "        \n",
    "        return s_free, o_free, s_history\n",
    "    \n",
    "    def nudged_phase(self, x, s_free, o_free, target, beta=0.5, settle_steps=20):\n",
    "        \"\"\"\n",
    "        NUDGED PHASE: Push output toward target and re-settle.\n",
    "        \n",
    "        The key insight: instead of backprop, we let the network\n",
    "        \"feel\" the error through symmetric feedback connections.\n",
    "        \n",
    "        Args:\n",
    "            x: Input sequence (for reference)\n",
    "            s_free: Hidden state from free phase\n",
    "            o_free: Output from free phase\n",
    "            target: One-hot target (batch, 10)\n",
    "            beta: Nudging strength\n",
    "            settle_steps: Steps to re-settle\n",
    "            \n",
    "        Returns:\n",
    "            s_nudged: Hidden state after nudging\n",
    "            o_nudged: Output after nudging\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Start from free phase state\n",
    "        s = s_free.clone()\n",
    "        \n",
    "        # Zero input during settling\n",
    "        x_zero = torch.zeros(batch_size, self.input_dim, device=x.device)\n",
    "        \n",
    "        # Settle with nudge feedback\n",
    "        for _ in range(settle_steps):\n",
    "            # Current output\n",
    "            o = self.compute_output(s)\n",
    "            \n",
    "            # Nudge: push output toward target\n",
    "            # Error signal: β × (target - output)\n",
    "            output_error = beta * (target - o)\n",
    "            \n",
    "            # Feedback to hidden layer via transpose of W_h2o\n",
    "            # This is the \"symmetric feedback\" that makes EP work\n",
    "            feedback = F.linear(output_error, self.W_h2o.t())\n",
    "            \n",
    "            # Update hidden state with feedback\n",
    "            phi = self.compute_phi(x_zero, s, feedback=feedback)\n",
    "            s = self.hidden_dynamics(s, phi)\n",
    "        \n",
    "        s_nudged = s\n",
    "        o_nudged = self.compute_output(s_nudged)\n",
    "        \n",
    "        return s_nudged, o_nudged\n",
    "    \n",
    "    def forward(self, x, target=None, beta=0.5, settle_steps=20):\n",
    "        \"\"\"\n",
    "        Full EP forward pass.\n",
    "        \n",
    "        If target is None: only free phase (inference)\n",
    "        If target provided: both phases (training)\n",
    "        \"\"\"\n",
    "        s_free, o_free, s_history = self.free_phase(x, settle_steps)\n",
    "        \n",
    "        if target is None:\n",
    "            return o_free, {'s_free': s_free, 's_history': s_history}\n",
    "        \n",
    "        s_nudged, o_nudged = self.nudged_phase(x, s_free, o_free, target, beta, settle_steps)\n",
    "        \n",
    "        return o_free, {\n",
    "            's_free': s_free,\n",
    "            'o_free': o_free,\n",
    "            's_nudged': s_nudged,\n",
    "            'o_nudged': o_nudged,\n",
    "            's_history': s_history,\n",
    "            'x_last': x[:, -1]  # Last input for weight update\n",
    "        }\n",
    "\n",
    "# Test model\n",
    "model = SOEN_EP_Model().to(device)\n",
    "print(f\"Model created: 7 → 28 → 10\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EP Trainer\n",
    "\n",
    "**Contrastive Hebbian Learning Rule:**\n",
    "\n",
    "$$\\Delta W = \\frac{1}{\\beta} \\left( s_{\\text{nudged}} \\otimes \\text{pre}_{\\text{nudged}} - s_{\\text{free}} \\otimes \\text{pre}_{\\text{free}} \\right)$$\n",
    "\n",
    "This is **local** — each synapse only needs its pre/post neuron states!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPTrainer:\n",
    "    \"\"\"\n",
    "    Equilibrium Propagation trainer.\n",
    "    \n",
    "    Key insight: Weight updates are computed from the DIFFERENCE\n",
    "    between free and nudged equilibrium states. No backprop through time!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, lr=0.01, beta=0.5, settle_steps=20,\n",
    "                 weight_decay=1e-4):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.beta = beta\n",
    "        self.settle_steps = settle_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "    def compute_ep_gradients(self, states):\n",
    "        \"\"\"\n",
    "        Compute weight updates using contrastive Hebbian rule.\n",
    "        \n",
    "        ΔW ∝ (1/β) × (post_nudged @ pre_nudged.T - post_free @ pre_free.T)\n",
    "        \n",
    "        This approximates the true gradient without backprop!\n",
    "        \"\"\"\n",
    "        s_free = states['s_free']      # (batch, 28)\n",
    "        s_nudged = states['s_nudged']  # (batch, 28)\n",
    "        o_free = states['o_free']      # (batch, 10)\n",
    "        o_nudged = states['o_nudged']  # (batch, 10)\n",
    "        x_last = states['x_last']      # (batch, 7)\n",
    "        \n",
    "        batch_size = s_free.shape[0]\n",
    "        scale = 1.0 / (self.beta * batch_size)\n",
    "        \n",
    "        # W_h2o gradient: output × hidden.T\n",
    "        # ΔW_h2o = (o_nudged @ s_nudged.T - o_free @ s_free.T) / β\n",
    "        grad_W_h2o = scale * (o_nudged.T @ s_nudged - o_free.T @ s_free)\n",
    "        \n",
    "        # W_h2h gradient: hidden × hidden.T (recurrent)\n",
    "        # ΔW_h2h = (s_nudged @ s_nudged.T - s_free @ s_free.T) / β\n",
    "        grad_W_h2h = scale * (s_nudged.T @ s_nudged - s_free.T @ s_free)\n",
    "        # Zero diagonal (no self-connections)\n",
    "        grad_W_h2h.fill_diagonal_(0)\n",
    "        \n",
    "        # W_i2h gradient: hidden × input.T\n",
    "        # Using last input as representative (could also average)\n",
    "        # ΔW_i2h = (s_nudged @ x.T - s_free @ x.T) / β\n",
    "        grad_W_i2h = scale * (s_nudged.T @ x_last - s_free.T @ x_last)\n",
    "        \n",
    "        # Bias gradients\n",
    "        grad_bias_h = scale * (s_nudged.sum(0) - s_free.sum(0))\n",
    "        grad_bias_o = scale * (o_nudged.sum(0) - o_free.sum(0))\n",
    "        \n",
    "        return {\n",
    "            'W_h2o': grad_W_h2o,\n",
    "            'W_h2h': grad_W_h2h,\n",
    "            'W_i2h': grad_W_i2h,\n",
    "            'bias_h': grad_bias_h,\n",
    "            'bias_o': grad_bias_o\n",
    "        }\n",
    "    \n",
    "    def update_weights(self, grads):\n",
    "        \"\"\"Apply weight updates with optional weight decay.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Update weights\n",
    "            self.model.W_h2o += self.lr * grads['W_h2o']\n",
    "            self.model.W_h2h += self.lr * grads['W_h2h']\n",
    "            self.model.W_i2h += self.lr * grads['W_i2h']\n",
    "            self.model.bias_h += self.lr * grads['bias_h']\n",
    "            self.model.bias_o += self.lr * grads['bias_o']\n",
    "            \n",
    "            # Weight decay\n",
    "            if self.weight_decay > 0:\n",
    "                self.model.W_h2o *= (1 - self.lr * self.weight_decay)\n",
    "                self.model.W_h2h *= (1 - self.lr * self.weight_decay)\n",
    "                self.model.W_i2h *= (1 - self.lr * self.weight_decay)\n",
    "            \n",
    "            # Enforce no self-connections\n",
    "            self.model.W_h2h.fill_diagonal_(0)\n",
    "            \n",
    "            # Clamp weights (stability)\n",
    "            self.model.W_h2o.clamp_(-1.0, 1.0)\n",
    "            self.model.W_h2h.clamp_(-0.5, 0.5)\n",
    "            self.model.W_i2h.clamp_(-1.0, 1.0)\n",
    "    \n",
    "    def train_step(self, x, labels):\n",
    "        \"\"\"\n",
    "        Single training step with EP.\n",
    "        \n",
    "        1. Free phase: process input, settle\n",
    "        2. Nudged phase: push toward target, re-settle\n",
    "        3. Compute EP gradients from state differences\n",
    "        4. Update weights\n",
    "        \"\"\"\n",
    "        # One-hot encode targets\n",
    "        target = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        # Forward pass (both phases)\n",
    "        output, states = self.model(x, target, self.beta, self.settle_steps)\n",
    "        \n",
    "        # Compute EP gradients (no backprop!)\n",
    "        grads = self.compute_ep_gradients(states)\n",
    "        \n",
    "        # Update weights\n",
    "        self.update_weights(grads)\n",
    "        \n",
    "        # Compute loss for monitoring (not used for gradients)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        pred = output.argmax(dim=1)\n",
    "        acc = (pred == labels).float().mean()\n",
    "        \n",
    "        return loss.item(), acc.item()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader):\n",
    "        \"\"\"Evaluate on dataset (free phase only).\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for x, labels in dataloader:\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            output, _ = self.model(x)  # Free phase only\n",
    "            \n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            pred = output.argmax(dim=1)\n",
    "            acc = (pred == labels).float().sum()\n",
    "            \n",
    "            total_loss += loss.item() * len(x)\n",
    "            total_acc += acc.item()\n",
    "            total_samples += len(x)\n",
    "        \n",
    "        self.model.train()\n",
    "        return total_loss / total_samples, total_acc / total_samples\n",
    "\n",
    "print(\"EPTrainer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train with EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ep(model, train_data, train_labels, val_data, val_labels,\n",
    "             epochs=30, batch_size=64, lr=0.05, beta=0.5, settle_steps=20):\n",
    "    \"\"\"\n",
    "    Train model using Equilibrium Propagation.\n",
    "    \"\"\"\n",
    "    # Create dataloaders\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_data, dtype=torch.float32),\n",
    "        torch.tensor(train_labels, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(val_data, dtype=torch.float32),\n",
    "        torch.tensor(val_labels, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = EPTrainer(model, lr=lr, beta=beta, settle_steps=settle_steps)\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"EQUILIBRIUM PROPAGATION TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Beta (nudge strength): {beta}\")\n",
    "    print(f\"Settle steps: {settle_steps}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for x, labels in pbar:\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            \n",
    "            loss, acc = trainer.train_step(x, labels)\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            epoch_acc += acc\n",
    "            n_batches += 1\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss:.4f}', 'acc': f'{acc:.3f}'})\n",
    "        \n",
    "        # Epoch averages\n",
    "        train_loss = epoch_loss / n_batches\n",
    "        train_acc = epoch_acc / n_batches\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc = trainer.evaluate(val_loader)\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Track best\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, \"\n",
    "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f} {'*' if val_acc == best_val_acc else ''}\")\n",
    "    \n",
    "    # Restore best model\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Initialize fresh model\n",
    "model = SOEN_EP_Model(\n",
    "    input_dim=7,\n",
    "    hidden_dim=28,\n",
    "    output_dim=10,\n",
    "    dt=0.1,\n",
    "    gamma_plus=0.1,\n",
    "    gamma_minus=0.01\n",
    ").to(device)\n",
    "\n",
    "# Train!\n",
    "history = train_ep(\n",
    "    model,\n",
    "    train_data, train_labels,\n",
    "    val_data, val_labels,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    lr=0.05,        # Higher LR for EP\n",
    "    beta=0.5,       # Nudge strength\n",
    "    settle_steps=20  # Steps to equilibrium\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss (EP Training)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy (EP Training)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_test(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_data, dtype=torch.float32),\n",
    "        torch.tensor(test_labels, dtype=torch.long)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for x, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        output, _ = model(x)\n",
    "        preds = output.argmax(dim=1).cpu()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY (Equilibrium Propagation): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return accuracy, all_preds.numpy(), all_labels.numpy()\n",
    "\n",
    "test_acc, test_preds, test_true = evaluate_test(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions_ep(model, test_data, test_labels, n=20):\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(len(test_data), n, replace=False)\n",
    "    samples = test_data[idx]\n",
    "    labels = test_labels[idx]\n",
    "    images = samples.reshape(n, 784).reshape(n, 28, 28)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(samples, dtype=torch.float32).to(device)\n",
    "        output, _ = model(x)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        preds = probs.argmax(dim=1).cpu().numpy()\n",
    "        conf = probs.max(dim=1)[0].cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle('Predictions (Equilibrium Propagation)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        ok = preds[i] == labels[i]\n",
    "        axes[i].set_title(f\"{'✓' if ok else '✗'} {preds[i]} ({conf[i]:.0%})\\nTrue: {labels[i]}\",\n",
    "                          color='green' if ok else 'red', fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions_ep(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze EP Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ep_dynamics(model, sample_data, sample_label, beta=0.5, settle_steps=20):\n",
    "    \"\"\"\n",
    "    Visualize how states evolve during free and nudged phases.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor(sample_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    target = F.one_hot(torch.tensor([sample_label]), num_classes=10).float().to(device)\n",
    "    \n",
    "    # Track states during free phase\n",
    "    s = torch.zeros(1, model.hidden_dim, device=device)\n",
    "    free_states = [s.clone()]\n",
    "    \n",
    "    # Process input\n",
    "    for t in range(112):\n",
    "        phi = model.compute_phi(x[:, t], s)\n",
    "        s = model.hidden_dynamics(s, phi)\n",
    "        if t % 5 == 0:\n",
    "            free_states.append(s.clone())\n",
    "    \n",
    "    # Settle\n",
    "    x_zero = torch.zeros(1, model.input_dim, device=device)\n",
    "    for _ in range(settle_steps):\n",
    "        phi = model.compute_phi(x_zero, s)\n",
    "        s = model.hidden_dynamics(s, phi)\n",
    "        free_states.append(s.clone())\n",
    "    \n",
    "    s_free = s.clone()\n",
    "    o_free = model.compute_output(s_free)\n",
    "    \n",
    "    # Nudged phase\n",
    "    nudged_states = [s.clone()]\n",
    "    for _ in range(settle_steps):\n",
    "        o = model.compute_output(s)\n",
    "        output_error = beta * (target - o)\n",
    "        feedback = F.linear(output_error, model.W_h2o.t())\n",
    "        phi = model.compute_phi(x_zero, s, feedback=feedback)\n",
    "        s = model.hidden_dynamics(s, phi)\n",
    "        nudged_states.append(s.clone())\n",
    "    \n",
    "    s_nudged = s\n",
    "    o_nudged = model.compute_output(s_nudged)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # State evolution during free phase\n",
    "    free_arr = torch.stack(free_states).squeeze().cpu().numpy()\n",
    "    axes[0, 0].imshow(free_arr.T, aspect='auto', cmap='viridis')\n",
    "    axes[0, 0].axvline(x=22, color='r', linestyle='--', label='Input ends')\n",
    "    axes[0, 0].set_xlabel('Time step')\n",
    "    axes[0, 0].set_ylabel('Hidden neuron')\n",
    "    axes[0, 0].set_title('Free Phase: Hidden State Evolution')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Nudged phase\n",
    "    nudged_arr = torch.stack(nudged_states).squeeze().cpu().numpy()\n",
    "    axes[0, 1].imshow(nudged_arr.T, aspect='auto', cmap='viridis')\n",
    "    axes[0, 1].set_xlabel('Settle step')\n",
    "    axes[0, 1].set_ylabel('Hidden neuron')\n",
    "    axes[0, 1].set_title('Nudged Phase: Hidden State Evolution')\n",
    "    \n",
    "    # State difference (this is what drives learning!)\n",
    "    diff = (s_nudged - s_free).squeeze().cpu().numpy()\n",
    "    axes[1, 0].bar(range(len(diff)), diff)\n",
    "    axes[1, 0].set_xlabel('Hidden neuron')\n",
    "    axes[1, 0].set_ylabel('Δs = s_nudged - s_free')\n",
    "    axes[1, 0].set_title('State Difference (drives weight updates)')\n",
    "    axes[1, 0].axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Output comparison\n",
    "    x_pos = np.arange(10)\n",
    "    width = 0.25\n",
    "    axes[1, 1].bar(x_pos - width, o_free.squeeze().cpu().numpy(), width, label='Free', alpha=0.7)\n",
    "    axes[1, 1].bar(x_pos, o_nudged.squeeze().cpu().numpy(), width, label='Nudged', alpha=0.7)\n",
    "    axes[1, 1].bar(x_pos + width, target.squeeze().cpu().numpy(), width, label='Target', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Class')\n",
    "    axes[1, 1].set_ylabel('Activation')\n",
    "    axes[1, 1].set_title(f'Output: Free vs Nudged vs Target (True: {sample_label})')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].set_xticks(x_pos)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFree phase prediction: {o_free.argmax().item()}\")\n",
    "    print(f\"Nudged phase prediction: {o_nudged.argmax().item()}\")\n",
    "    print(f\"True label: {sample_label}\")\n",
    "\n",
    "# Analyze a sample\n",
    "analyze_ep_dynamics(model, test_data[0], test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | BPTT | Equilibrium Propagation |\n",
    "|--------|------|-------------------------|\n",
    "| Gradient computation | Backprop through 112 steps | State differences |\n",
    "| Vanishing gradients | Yes (exponential decay) | **Avoided** |\n",
    "| Memory requirement | O(T × hidden) | O(hidden) |\n",
    "| Hardware compatibility | Requires external compute | **Local, Hebbian-like** |\n",
    "| Training phases | 1 (forward + backward) | 2 (free + nudged) |\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "EP computes gradients from the **difference** between free and nudged equilibrium states.\n",
    "This is fundamentally different from BPTT and avoids the vanishing gradient problem\n",
    "because we don't chain multiply through 112 timesteps.\n",
    "\n",
    "### Tuning Tips\n",
    "\n",
    "- **β (beta)**: Controls nudge strength. Too small → noisy gradients, too large → biased\n",
    "- **settle_steps**: More steps → better equilibrium, but slower\n",
    "- **Learning rate**: EP often needs higher LR than backprop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
