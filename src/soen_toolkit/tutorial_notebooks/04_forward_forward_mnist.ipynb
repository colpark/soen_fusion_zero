{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Tutorial 04 â€” Forward-Forward Learning for MNIST with SOEN\n\nThis notebook demonstrates the **Forward-Forward (FF) algorithm** (Hinton, 2022) for training SOEN networks on MNIST, as an alternative to backpropagation.\n\n---\n\n## ðŸ”Š NOISE CONFIGURATION: ENABLED (Default)\n\n> **This tutorial runs with NOISE INJECTION (documented defaults).**\n>\n> | Parameter | Default | Description |\n> |-----------|---------|-------------|\n> | `phi` | **0.01** | Noise on input flux |\n> | `s` | **0.005** | Noise on state |\n> | `relative` | **False** | Absolute scaling |\n>\n> **To toggle noise on/off:** Use the `NOISE_ENABLED` variable below.\n\n---\n\n## âš ï¸ Hardware Compatibility Modes\n\nThis tutorial provides **two training modes**:\n\n| Mode | Description | Hardware Compatible? |\n|------|-------------|---------------------|\n| `HARDWARE_MODE = False` | Standard FF with autograd (better accuracy) | âŒ No |\n| `HARDWARE_MODE = True` | Hardware-compatible FF (realistic constraints) | âœ… Yes |\n\n### What \"Hardware Compatible\" Means:\n\n| Component | Standard FF | Hardware FF |\n|-----------|-------------|-------------|\n| **Goodness** | `mean(xÂ²)` - needs squarer circuit | `mean(|x|)` - uses rectifiers only |\n| **Normalization** | L2 norm - needs sqrt + division | Lateral inhibition - native |\n| **Loss** | Softplus - needs exp/log | Hinge loss - uses comparators |\n| **Update** | Autograd + Adam | Hebbian (gradient-free) |\n| **Inference** | 10 passes per sample | Hybrid classifier (1 pass) |\n\n---\n\n## Why Forward-Forward for SOEN?\n\n| Aspect | Backpropagation | Forward-Forward |\n|--------|-----------------|------------------|\n| **Cross-layer gradients** | Required | âŒ Eliminated |\n| **Weight transport** | Symmetric weights required | âŒ Not needed |\n| **Intra-layer gradients** | Required | âš ï¸ Still needed (standard) or eliminated (hardware mode) |\n| **Hardware fit** | Poor | Good (esp. hardware mode) |\n| **Noise tolerance** | Gradients compound noise | Local learning is robust |\n\n### Honest Assessment\n\n**What FF eliminates:**\n- Cross-layer gradient propagation (weight transport problem)\n- Need to store activations for multi-layer backprop\n- Global error signal coordination\n\n**What FF does NOT eliminate (in standard mode):**\n- Autograd within each layer (`loss.backward()` is still called)\n- Need for optimizer (Adam) states\n- External computation for training\n\n**Hardware mode additionally eliminates:**\n- All autograd (uses Hebbian updates)\n- Complex nonlinear computations (squared, exp, log)\n- Multiple inference passes (hybrid classifier)\n\n## The Forward-Forward Algorithm\n\nInstead of propagating errors backward, each layer learns locally:\n\n1. **Positive pass**: Real data with correct label â†’ maximize \"goodness\"\n2. **Negative pass**: Real data with wrong label â†’ minimize \"goodness\"\n3. **Goodness**: Activity measure (squared or absolute activations)\n4. **Threshold**: Each layer pushes positive goodness above Î¸, negative below Î¸\n\n```\nPositive data: Image + correct_label_embedding â†’ High goodness âœ“\nNegative data: Image + wrong_label_embedding   â†’ Low goodness  âœ—\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Disable tqdm notebook widgets BEFORE any imports\nimport os\nos.environ[\"TQDM_DISABLE\"] = \"0\"  # Don't disable, but force text mode\nos.environ[\"TQDM_MININTERVAL\"] = \"1\"\n\n# Setup: Ensure soen_toolkit is importable\nimport sys\nfrom pathlib import Path\n\n# Add src directory to path if running from notebook location\nnotebook_dir = Path.cwd()\nfor parent in [notebook_dir] + list(notebook_dir.parents):\n    candidate = parent / \"src\"\n    if (candidate / \"soen_toolkit\").exists():\n        sys.path.insert(0, str(candidate))\n        break\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport h5py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport gzip\nimport urllib.request\nimport struct\nfrom typing import Optional, Tuple, List, Dict\nfrom dataclasses import dataclass\n\n# Use standard tqdm (not notebook version to avoid widget errors)\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    def tqdm(iterable, **kwargs):\n        return iterable\n\n# Set torch precision\ntorch.set_float32_matmul_precision('high')\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\nprint(f\"Using device: {DEVICE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# NOISE CONFIGURATION TOGGLE\n",
    "# ==============================================================================\n",
    "# Set NOISE_ENABLED = False to run with ideal conditions (no noise)\n",
    "# Set NOISE_ENABLED = True for noise injection (default)\n",
    "\n",
    "NOISE_ENABLED = True  # Toggle this to enable/disable noise\n",
    "\n",
    "# Default noise parameters (documented defaults)\n",
    "NOISE_DEFAULTS = {\n",
    "    \"phi\": 0.01,           # Noise on input flux\n",
    "    \"s\": 0.005,            # Noise on state\n",
    "    \"g\": 0.0,              # Source function noise\n",
    "    \"bias_current\": 0.0,   # Bias current noise\n",
    "    \"j\": 0.0,              # Connection weight noise\n",
    "    \"relative\": False,     # Absolute scaling\n",
    "}\n",
    "\n",
    "def set_model_noise(model, enabled=True, noise_values=None):\n",
    "    \"\"\"\n",
    "    Toggle noise injection on/off for a SOEN model.\n",
    "    \n",
    "    Args:\n",
    "        model: SOENModelCore instance\n",
    "        enabled: If True, apply noise; if False, set all noise to 0\n",
    "        noise_values: Dict of noise parameters (uses NOISE_DEFAULTS if None)\n",
    "    \n",
    "    Returns:\n",
    "        model: The modified model (for chaining)\n",
    "    \"\"\"\n",
    "    from soen_toolkit.core.configs import NoiseConfig\n",
    "    \n",
    "    if noise_values is None:\n",
    "        noise_values = NOISE_DEFAULTS\n",
    "    \n",
    "    # Update layer noise configurations\n",
    "    for cfg in model.layers_config:\n",
    "        if enabled:\n",
    "            cfg.noise = NoiseConfig(\n",
    "                phi=noise_values.get(\"phi\", 0.01),\n",
    "                s=noise_values.get(\"s\", 0.005),\n",
    "                g=noise_values.get(\"g\", 0.0),\n",
    "                bias_current=noise_values.get(\"bias_current\", 0.0),\n",
    "                j=noise_values.get(\"j\", 0.0),\n",
    "                relative=noise_values.get(\"relative\", False),\n",
    "                extras=getattr(cfg.noise, \"extras\", {}),\n",
    "            )\n",
    "        else:\n",
    "            cfg.noise = NoiseConfig(\n",
    "                phi=0.0, s=0.0, g=0.0, bias_current=0.0, j=0.0,\n",
    "                relative=False,\n",
    "                extras=getattr(cfg.noise, \"extras\", {}),\n",
    "            )\n",
    "    \n",
    "    # Update connection noise configurations\n",
    "    for conn_cfg in model.connections_config:\n",
    "        if enabled:\n",
    "            conn_cfg.noise = NoiseConfig(\n",
    "                phi=0.0, g=0.0, s=0.0, bias_current=0.0,\n",
    "                j=noise_values.get(\"j\", 0.0),\n",
    "                relative=noise_values.get(\"relative\", False),\n",
    "                extras={},\n",
    "            )\n",
    "        else:\n",
    "            conn_cfg.noise = NoiseConfig(\n",
    "                phi=0.0, g=0.0, s=0.0, bias_current=0.0, j=0.0,\n",
    "                relative=False, extras={},\n",
    "            )\n",
    "    \n",
    "    status = \"ENABLED\" if enabled else \"DISABLED\"\n",
    "    print(f\"âœ“ Noise injection {status}\")\n",
    "    if enabled:\n",
    "        print(f\"  phi={noise_values['phi']}, s={noise_values['s']}, \"\n",
    "              f\"relative={noise_values['relative']}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(f\"Noise injection: {'ENABLED' if NOISE_ENABLED else 'DISABLED'}\")\n",
    "if NOISE_ENABLED:\n",
    "    print(f\"  Default values: phi={NOISE_DEFAULTS['phi']}, s={NOISE_DEFAULTS['s']}, \"\n",
    "          f\"relative={NOISE_DEFAULTS['relative']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. Forward-Forward Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================================================\n# HARDWARE MODE CONFIGURATION\n# ==============================================================================\n# HARDWARE_MODE = False: Standard FF with autograd (better accuracy, not hardware-ready)\n# HARDWARE_MODE = True:  Hardware-compatible FF (realistic constraints, lower accuracy)\n\nHARDWARE_MODE = True  # Toggle this to switch between modes\n\nprint(f\"{'='*60}\")\nprint(f\"HARDWARE MODE: {'ENABLED' if HARDWARE_MODE else 'DISABLED'}\")\nprint(f\"{'='*60}\")\nif HARDWARE_MODE:\n    print(\"Using hardware-compatible components:\")\n    print(\"  - Goodness: mean(|x|) instead of mean(xÂ²)\")\n    print(\"  - Normalization: Lateral inhibition instead of L2 norm\")\n    print(\"  - Loss: Hinge loss instead of softplus\")\n    print(\"  - Updates: Hebbian (gradient-free) instead of Adam\")\n    print(\"  - Inference: Hybrid classifier (1 pass) instead of 10 passes\")\nelse:\n    print(\"Using standard FF components (not hardware-compatible):\")\n    print(\"  - Goodness: mean(xÂ²)\")\n    print(\"  - Normalization: L2 norm\")\n    print(\"  - Loss: Softplus\")\n    print(\"  - Updates: Adam optimizer with autograd\")\n    print(\"  - Inference: 10 forward passes\")\nprint(f\"{'='*60}\\n\")\n\n\n@dataclass\nclass FFConfig:\n    \"\"\"Configuration for Forward-Forward training.\"\"\"\n\n    # Architecture\n    image_dim: int = 28 * 28        # Flattened MNIST image (784)\n    num_classes: int = 10           # MNIST digits 0-9\n    input_dim: int = 28 * 28 + 10   # Image + CONCATENATED one-hot label = 794\n    hidden_dims: List[int] = None   # Will default to [500, 500]\n\n    # Training\n    batch_size: int = 128\n    num_epochs: int = 60\n    learning_rate: float = 0.03\n\n    # Forward-Forward specific\n    threshold: float = 2.0  # Goodness threshold (used differently in hardware mode)\n    negative_label_method: str = \"random\"  # \"random\" or \"next\"\n\n    # Hardware mode settings\n    hardware_mode: bool = HARDWARE_MODE\n    hebbian_lr: float = 0.1  # Learning rate for Hebbian updates (increased from 0.01)\n    inhibition_strength: float = 0.1  # Lateral inhibition strength\n\n    # SOEN specific\n    use_soen_layers: bool = False  # Start with standard layers for testing\n    dt: float = 100.0  # SOEN timestep\n    num_timesteps: int = 28  # Process as sequence (one row at a time)\n\n    def __post_init__(self):\n        if self.hidden_dims is None:\n            self.hidden_dims = [500, 500]\n        # Ensure input_dim is correctly calculated\n        self.input_dim = self.image_dim + self.num_classes\n\n\n# Default configuration\nconfig = FFConfig()\nprint(\"Forward-Forward Configuration:\")\nprint(f\"  Hardware mode: {config.hardware_mode}\")\nprint(f\"  Image dim: {config.image_dim}\")\nprint(f\"  Label dim: {config.num_classes}\")\nprint(f\"  Input dim: {config.input_dim} (image + label CONCATENATED)\")\nprint(f\"  Hidden dims: {config.hidden_dims}\")\nprint(f\"  Threshold: {config.threshold}\")\nprint(f\"  Hebbian LR: {config.hebbian_lr}\")\nprint(f\"  Use SOEN layers: {config.use_soen_layers}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "## 2. Prepare MNIST Dataset with Label Embedding\n\nFor Forward-Forward, we **concatenate** the label to the input (not replace pixels!):\n- **Positive data**: Image pixels (784) + one-hot encoding of the **correct** label (10) = 794 dims\n- **Negative data**: Image pixels (784) + one-hot encoding of a **wrong** label (10) = 794 dims\n\nThis preserves all image information while providing clear label signal."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    \"\"\"Download a single MNIST file if not already present.\"\"\"\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        url = base_url + filename\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    \"\"\"Read MNIST image file (idx3-ubyte format).\"\"\"\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        images = images.reshape(num_images, rows, cols)\n",
    "    return images\n",
    "\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    \"\"\"Read MNIST label file (idx1-ubyte format).\"\"\"\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack('>II', f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    \"\"\"Load MNIST dataset.\"\"\"\n",
    "    # Download files\n",
    "    train_images_file = download_mnist_file(\"train-images-idx3-ubyte.gz\")\n",
    "    train_labels_file = download_mnist_file(\"train-labels-idx1-ubyte.gz\")\n",
    "    test_images_file = download_mnist_file(\"t10k-images-idx3-ubyte.gz\")\n",
    "    test_labels_file = download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")\n",
    "    \n",
    "    # Read data\n",
    "    train_images = read_mnist_images(train_images_file).astype(np.float32) / 255.0\n",
    "    train_labels = read_mnist_labels(train_labels_file)\n",
    "    test_images = read_mnist_images(test_images_file).astype(np.float32) / 255.0\n",
    "    test_labels = read_mnist_labels(test_labels_file)\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_images, train_labels, test_images, test_labels = load_mnist()\n",
    "print(f\"Train: {train_images.shape}, Test: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "class MNISTForwardForwardDataset(Dataset):\n    \"\"\"MNIST dataset prepared for Forward-Forward learning.\n\n    Each sample returns both positive and negative versions:\n    - Positive: image pixels + correct label one-hot (CONCATENATED)\n    - Negative: image pixels + wrong label one-hot (CONCATENATED)\n\n    Input dimension: 784 (image) + 10 (label) = 794\n    \"\"\"\n\n    def __init__(self, images, labels, num_classes=10, negative_method=\"random\"):\n        \"\"\"\n        Args:\n            images: (N, 28, 28) image array\n            labels: (N,) label array\n            num_classes: Number of classes (10 for MNIST)\n            negative_method: \"random\" for random wrong label, \"next\" for (label+1)%10\n        \"\"\"\n        self.images = torch.tensor(images, dtype=torch.float32)\n        self.labels = torch.tensor(labels, dtype=torch.long)\n        self.num_classes = num_classes\n        self.negative_method = negative_method\n\n    def __len__(self):\n        return len(self.labels)\n\n    def _embed_label(self, image, label):\n        \"\"\"Embed label by CONCATENATING one-hot to flattened image.\n\n        This preserves all image information (unlike Hinton's pixel replacement).\n\n        Args:\n            image: (28, 28) image tensor\n            label: scalar label tensor\n\n        Returns:\n            embedded: (794,) tensor = [784 image pixels] + [10 one-hot label]\n        \"\"\"\n        flat_image = image.flatten()  # (784,)\n        one_hot = F.one_hot(label, num_classes=self.num_classes).float()  # (10,)\n\n        # CONCATENATE label to end of image (not replace!)\n        embedded = torch.cat([flat_image, one_hot], dim=0)  # (794,)\n\n        return embedded\n\n    def _get_negative_label(self, true_label):\n        \"\"\"Generate a wrong label for negative data.\"\"\"\n        if self.negative_method == \"next\":\n            return (true_label + 1) % self.num_classes\n        else:  # random\n            wrong_label = torch.randint(0, self.num_classes - 1, (1,)).item()\n            if wrong_label >= true_label:\n                wrong_label += 1\n            return wrong_label\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        true_label = self.labels[idx]\n\n        # Positive: correct label CONCATENATED\n        positive_data = self._embed_label(image, true_label)\n\n        # Negative: wrong label CONCATENATED\n        wrong_label = self._get_negative_label(true_label.item())\n        negative_data = self._embed_label(image, torch.tensor(wrong_label))\n\n        return {\n            \"positive\": positive_data,\n            \"negative\": negative_data,\n            \"label\": true_label,\n            \"image\": image,\n        }\n\n\n# Create datasets\ntrain_dataset = MNISTForwardForwardDataset(\n    train_images, train_labels,\n    negative_method=config.negative_label_method\n)\ntest_dataset = MNISTForwardForwardDataset(\n    test_images, test_labels,\n    negative_method=config.negative_label_method\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n\n# Verify\nsample = train_dataset[0]\nprint(f\"Positive data shape: {sample['positive'].shape}\")  # Should be (794,)\nprint(f\"Negative data shape: {sample['negative'].shape}\")  # Should be (794,)\nprint(f\"True label: {sample['label']}\")\nprint(f\"\\nImage pixels (first 10): {sample['positive'][:10]}\")\nprint(f\"Image pixels (last 10 of image part): {sample['positive'][774:784]}\")\nprint(f\"Label one-hot (last 10 = CONCATENATED label): {sample['positive'][784:]}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Visualize Positive vs Negative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "def visualize_ff_data(dataset, n_samples=5):\n    \"\"\"Visualize positive and negative data pairs with concatenated labels.\"\"\"\n\n    fig, axes = plt.subplots(3, n_samples, figsize=(3*n_samples, 9))\n    fig.suptitle('Forward-Forward Data: Label CONCATENATED (not replaced)', fontsize=14, fontweight='bold')\n\n    for i in range(n_samples):\n        sample = dataset[i]\n\n        # Original image\n        axes[0, i].imshow(sample['image'], cmap='gray')\n        axes[0, i].set_title(f\"True label: {sample['label'].item()}\")\n        axes[0, i].axis('off')\n\n        # Positive: Show image part (first 784 dims) - image is UNCHANGED\n        pos_image = sample['positive'][:784].reshape(28, 28)\n        pos_label = sample['positive'][784:].argmax().item()\n        axes[1, i].imshow(pos_image, cmap='gray')\n        axes[1, i].set_title(f\"Positive\\n(concat label={pos_label})\")\n        axes[1, i].axis('off')\n\n        # Negative: Show image part (first 784 dims) - same image, different label\n        neg_image = sample['negative'][:784].reshape(28, 28)\n        neg_label = sample['negative'][784:].argmax().item()\n        axes[2, i].imshow(neg_image, cmap='gray')\n        axes[2, i].set_title(f\"Negative\\n(concat label={neg_label})\", color='red')\n        axes[2, i].axis('off')\n\n    axes[0, 0].set_ylabel('Original\\nImage', fontsize=12)\n    axes[1, 0].set_ylabel('Positive\\n(correct)', fontsize=12)\n    axes[2, 0].set_ylabel('Negative\\n(wrong)', fontsize=12)\n\n    plt.tight_layout()\n    plt.show()\n\n    # Show the label embedding structure\n    print(\"\\n\" + \"=\"*60)\n    print(\"LABEL EMBEDDING STRUCTURE (Concatenated, not replaced)\")\n    print(\"=\"*60)\n    sample = dataset[0]\n    print(f\"Total input dimension: {sample['positive'].shape[0]}\")\n    print(f\"  - Image pixels [0:784]:  {sample['positive'][:784].shape}\")\n    print(f\"  - Label one-hot [784:794]: {sample['positive'][784:].shape}\")\n    print(f\"\\nPositive label one-hot: {sample['positive'][784:].tolist()}\")\n    print(f\"Negative label one-hot: {sample['negative'][784:].tolist()}\")\n    print(f\"\\nNote: Image pixels are IDENTICAL in positive and negative!\")\n    print(f\"      Only the concatenated label differs.\")\n\n\nvisualize_ff_data(train_dataset)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": "## 4. Forward-Forward Layer\n\nEach layer in Forward-Forward has its own local objective:\n- **Goodness** = activity measure (squared or absolute activations)\n- **Goal**: goodness > threshold for positive data, goodness < threshold for negative data\n\nWe provide **two implementations** based on `HARDWARE_MODE`:\n\n### Standard Mode (`HARDWARE_MODE = False`)\n- Goodness: `mean(xÂ²)` - requires analog squaring circuit (not available in SOEN)\n- Normalization: L2 norm - requires sqrt + division (very complex analog circuits)\n- Loss: Softplus - requires exp/log (no analog equivalent)\n- Update: Adam optimizer with autograd\n\n### Hardware Mode (`HARDWARE_MODE = True`)\n- Goodness: `mean(|x|)` - uses rectifiers (simple diode circuits, SOEN-native)\n- Normalization: Lateral inhibition - uses subtraction (SOEN-native)\n- Loss: Hinge loss - uses comparators and ReLU (SOEN-native)\n- Update: Hebbian rule - no autograd, closed-form update\n\n### âš ï¸ Critical Implementation Details\n\n**Why not use `mean(xÂ²)`?**\n- Computing xÂ² requires analog multiplier circuits\n- SOEN has no native squaring operation\n- `mean(|x|)` only needs rectifiers (full-wave or half-wave)\n\n**Why not use L2 normalization?**\n- Requires computing sqrt(Î£xâ±¼Â²) and division\n- These are extremely complex analog operations\n- Lateral inhibition provides similar effect using only subtraction\n\n**Why not use Softplus loss?**\n- `log(1 + exp(x))` requires exp and log circuits\n- No analog equivalent exists in SOEN\n- Hinge loss `max(0, margin - x)` uses only comparators and ReLU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "class FFLayer(nn.Module):\n    \"\"\"Forward-Forward layer with configurable hardware compatibility.\n\n    Supports two modes:\n    - Standard mode: Uses autograd, better accuracy, not hardware-compatible\n    - Hardware mode: Uses Hebbian updates, hardware-compatible, lower accuracy\n\n    Hardware-compatible changes:\n    1. Goodness: mean(|x|) instead of mean(xÂ²) - uses rectifiers only\n    2. Normalization: Lateral inhibition instead of L2 norm - uses subtraction only\n    3. Loss: Hinge loss instead of softplus - uses comparators only\n    4. Updates: Differential Hebbian rule - no autograd needed\n    \"\"\"\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        threshold: float = 2.0,\n        hardware_mode: bool = HARDWARE_MODE,\n        inhibition_strength: float = 0.1,\n    ):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.threshold = threshold\n        self.hardware_mode = hardware_mode\n        self.inhibition_strength = inhibition_strength\n\n        # Core transformation\n        self.linear = nn.Linear(in_features, out_features)\n        self.relu = nn.ReLU()\n\n        # Initialize weights with larger values for hardware mode to get signal\n        if hardware_mode:\n            nn.init.uniform_(self.linear.weight, -0.3, 0.3)\n            nn.init.zeros_(self.linear.bias)\n\n        # Store activations and inputs for learning\n        self._raw_activations = None\n        self._input = None\n        self._pos_input = None\n        self._pos_activations = None\n        self._neg_input = None\n        self._neg_activations = None\n\n        # Running estimates for monitoring\n        self._running_pos_goodness = 0.1\n        self._running_neg_goodness = 0.1\n        self._momentum = 0.95\n\n    def forward(self, x: torch.Tensor, store_as: str = None) -> torch.Tensor:\n        \"\"\"Forward pass with mode-dependent normalization.\"\"\"\n        self._input = x.detach() if self.hardware_mode else x\n\n        if store_as == 'positive':\n            self._pos_input = x.detach()\n        elif store_as == 'negative':\n            self._neg_input = x.detach()\n\n        x = self.linear(x)\n        x = self.relu(x)\n        self._raw_activations = x\n\n        if store_as == 'positive':\n            self._pos_activations = x.detach()\n        elif store_as == 'negative':\n            self._neg_activations = x.detach()\n\n        if self.hardware_mode:\n            mean_activity = x.mean(dim=1, keepdim=True)\n            x_norm = x - self.inhibition_strength * mean_activity\n            x_norm = torch.clamp(x_norm, min=0)\n        else:\n            x_norm = x / (x.norm(dim=1, keepdim=True) + 1e-8)\n\n        return x_norm\n\n    def compute_goodness(self, x: torch.Tensor = None) -> torch.Tensor:\n        \"\"\"Compute goodness from stored raw activations.\"\"\"\n        activations = self._raw_activations\n        if self.hardware_mode:\n            return activations.abs().mean(dim=1)\n        else:\n            return (activations ** 2).mean(dim=1)\n\n    def ff_loss(self, pos_goodness: torch.Tensor, neg_goodness: torch.Tensor) -> torch.Tensor:\n        \"\"\"Compute Forward-Forward loss with adaptive threshold.\"\"\"\n        # Use running estimate for threshold in hardware mode\n        if self.hardware_mode:\n            threshold = (self._running_pos_goodness + self._running_neg_goodness) / 2\n        else:\n            threshold = self.threshold\n\n        if self.hardware_mode:\n            pos_loss = F.relu(threshold - pos_goodness)\n            neg_loss = F.relu(neg_goodness - threshold)\n        else:\n            pos_loss = F.softplus(-(pos_goodness - threshold))\n            neg_loss = F.softplus(neg_goodness - threshold)\n\n        return (pos_loss + neg_loss).mean()\n\n    def hebbian_update(self, pos_goodness: torch.Tensor, neg_goodness: torch.Tensor,\n                       lr: float = 0.01) -> None:\n        \"\"\"Differential Hebbian update for Forward-Forward.\n\n        Key insight: The only difference between positive and negative inputs\n        is the label embedding (LAST 10 dimensions - concatenated one-hot).\n        We want to learn weights that make the network respond DIFFERENTLY\n        to these different labels.\n\n        Update rule:\n        1. Compute output difference: Î”post = pos_post - neg_post\n        2. Correlate with input difference: Î”pre = pos_pre - neg_pre\n        3. Update: Î”w = lr * Î”post^T @ avg_pre + lr * avg_post^T @ Î”pre\n\n        This learns associations between label inputs and output responses.\n\n        Hardware implementation:\n        - Subtraction: differential amplifier (SOEN native)\n        - Outer product: crossbar array\n        - Accumulation: capacitive integration\n        \"\"\"\n        with torch.no_grad():\n            if self._pos_input is None or self._neg_input is None:\n                return\n\n            pos_input = self._pos_input  # (batch, in_features)\n            neg_input = self._neg_input\n            pos_acts = self._pos_activations  # (batch, out_features)\n            neg_acts = self._neg_activations\n\n            batch_size = pos_input.shape[0]\n\n            # Update running goodness estimates\n            pos_g_mean = pos_goodness.mean().item()\n            neg_g_mean = neg_goodness.mean().item()\n            self._running_pos_goodness = self._momentum * self._running_pos_goodness + (1 - self._momentum) * pos_g_mean\n            self._running_neg_goodness = self._momentum * self._running_neg_goodness + (1 - self._momentum) * neg_g_mean\n\n            # ==========================================\n            # DIFFERENTIAL HEBBIAN UPDATE\n            # ==========================================\n\n            # Compute differences between positive and negative\n            diff_acts = pos_acts - neg_acts  # Output difference (batch, out_features)\n            diff_input = pos_input - neg_input  # Input difference (batch, in_features)\n            # Note: diff_input is non-zero only for LAST 10 dims (concatenated label encoding)\n\n            # Average activations (for correlation with differences)\n            avg_acts = (pos_acts + neg_acts) / 2  # (batch, out_features)\n            avg_input = (pos_input + neg_input) / 2  # (batch, in_features)\n\n            # Differential Hebbian update:\n            # 1. If output is higher for positive, strengthen connection to positive input\n            # 2. If output is higher for negative, weaken connection (strengthen to negative input)\n            #\n            # Î”w = diff_acts^T @ avg_input + avg_acts^T @ diff_input\n            #\n            # First term: correlates output difference with average input pattern\n            # Second term: correlates average output with input difference (label)\n\n            update1 = diff_acts.T @ avg_input / batch_size\n            update2 = avg_acts.T @ diff_input / batch_size\n\n            # Combine updates (weight the label-related update higher)\n            delta_w = lr * (update1 + 2.0 * update2)\n\n            self.linear.weight.data += delta_w\n\n            # Update bias based on overall goodness difference\n            # If pos_goodness < neg_goodness, increase bias to boost overall activity\n            goodness_diff = pos_g_mean - neg_g_mean\n            bias_update = lr * 0.5 * goodness_diff  # Encourage pos > neg\n            self.linear.bias.data += bias_update\n\n            # Clamp to hardware constraints\n            self.linear.weight.data.clamp_(-0.5, 0.5)\n            self.linear.bias.data.clamp_(-1.0, 1.0)\n\n\n# Test both modes\nprint(\"Testing FFLayer in both modes:\\n\")\n\nfor mode in [False, True]:\n    mode_name = \"HARDWARE\" if mode else \"STANDARD\"\n    test_layer = FFLayer(794, 500, hardware_mode=mode)  # 794 = 784 image + 10 label\n    test_input = torch.randn(32, 794)\n\n    test_output = test_layer(test_input)\n    test_goodness = test_layer.compute_goodness()\n\n    print(f\"{mode_name} MODE:\")\n    print(f\"  Input shape: {test_input.shape} (784 image + 10 label)\")\n    print(f\"  Output shape: {test_output.shape}\")\n    print(f\"  Mean goodness: {test_goodness.mean().item():.4f}\")\n    print(f\"  Goodness range: [{test_goodness.min().item():.4f}, {test_goodness.max().item():.4f}]\")\n\n    # Test loss computation\n    pos_g = torch.tensor([3.0, 2.5, 2.8])\n    neg_g = torch.tensor([1.5, 1.8, 1.2])\n    loss = test_layer.ff_loss(pos_g, neg_g)\n    print(f\"  Test loss (pos=2.77, neg=1.5): {loss.item():.4f}\")\n    print()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. SOEN Forward-Forward Layer\n",
    "\n",
    "This layer uses SOEN SingleDendrite dynamics for the forward pass, making it compatible with neuromorphic hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "from soen_toolkit.core import (\n    ConnectionConfig,\n    LayerConfig,\n    SimulationConfig,\n    SOENModelCore,\n)\n\n\nclass SOENFFLayer(nn.Module):\n    \"\"\"SOEN-based Forward-Forward layer using SingleDendrite dynamics.\n\n    Supports both standard and hardware-compatible modes.\n    Hardware mode uses SOEN-native operations only.\n\n    Input format: [image pixels] + [one-hot label] (CONCATENATED)\n    \"\"\"\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        threshold: float = 2.0,\n        dt: float = 100.0,\n        num_timesteps: int = 28,\n        hardware_mode: bool = HARDWARE_MODE,\n        inhibition_strength: float = 0.1,\n    ):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.threshold = threshold\n        self.num_timesteps = num_timesteps\n        self.hardware_mode = hardware_mode\n        self.inhibition_strength = inhibition_strength\n\n        # Store activations and inputs for learning\n        self._raw_activations = None\n        self._input = None\n        self._pos_input = None\n        self._pos_activations = None\n        self._neg_input = None\n        self._neg_activations = None\n\n        # Running estimates\n        self._running_pos_goodness = 0.1\n        self._running_neg_goodness = 0.1\n        self._momentum = 0.95\n\n        # Build SOEN model\n        sim_cfg = SimulationConfig(\n            dt=dt,\n            input_type=\"state\",\n            track_phi=False,\n            track_power=False,\n        )\n\n        # Calculate input dim per timestep (including label distributed across timesteps)\n        input_per_timestep = in_features // num_timesteps\n\n        layer0 = LayerConfig(\n            layer_id=0,\n            layer_type=\"Input\",\n            params={\"dim\": input_per_timestep},\n        )\n\n        layer1 = LayerConfig(\n            layer_id=1,\n            layer_type=\"SingleDendrite\",\n            params={\n                \"dim\": out_features,\n                \"solver\": \"FE\",\n                \"source_func\": \"Heaviside_fit_state_dep\",\n                \"phi_offset\": 0.02,\n                \"bias_current\": {\"distribution\": \"uniform\", \"params\": {\"min\": 1.8, \"max\": 2.1}},\n                \"gamma_plus\": {\"distribution\": \"constant\", \"params\": {\"value\": 0.001}},\n                \"gamma_minus\": {\"distribution\": \"constant\", \"params\": {\"value\": 0.0001}},\n            },\n        )\n\n        conn = ConnectionConfig(\n            from_layer=0,\n            to_layer=1,\n            connection_type=\"dense\",\n            params={\"init\": \"xavier_uniform\"},\n            learnable=True,\n        )\n\n        self.soen_model = SOENModelCore(\n            sim_config=sim_cfg,\n            layers_config=[layer0, layer1],\n            connections_config=[conn],\n        )\n\n        if NOISE_ENABLED:\n            set_model_noise(self.soen_model, enabled=True, noise_values=NOISE_DEFAULTS)\n\n    def forward(self, x: torch.Tensor, store_as: str = None) -> torch.Tensor:\n        \"\"\"Process input through SOEN dynamics.\"\"\"\n        batch_size = x.shape[0]\n\n        self._input = x.detach() if self.hardware_mode else x\n        if store_as == 'positive':\n            self._pos_input = x.detach()\n        elif store_as == 'negative':\n            self._neg_input = x.detach()\n\n        x_seq = x.view(batch_size, self.num_timesteps, -1)\n        output, all_states = self.soen_model(x_seq)\n\n        if output.dim() == 3:\n            output = output.max(dim=1)[0]\n\n        self._raw_activations = output\n\n        if store_as == 'positive':\n            self._pos_activations = output.detach()\n        elif store_as == 'negative':\n            self._neg_activations = output.detach()\n\n        if self.hardware_mode:\n            mean_activity = output.mean(dim=1, keepdim=True)\n            output_norm = output - self.inhibition_strength * mean_activity\n            output_norm = torch.clamp(output_norm, min=0)\n        else:\n            output_norm = output / (output.norm(dim=1, keepdim=True) + 1e-8)\n\n        return output_norm\n\n    def compute_goodness(self, x: torch.Tensor = None) -> torch.Tensor:\n        \"\"\"Compute goodness from stored raw activations.\"\"\"\n        activations = self._raw_activations\n        if self.hardware_mode:\n            return activations.abs().mean(dim=1)\n        else:\n            return (activations ** 2).mean(dim=1)\n\n    def ff_loss(self, pos_goodness: torch.Tensor, neg_goodness: torch.Tensor) -> torch.Tensor:\n        \"\"\"Compute Forward-Forward loss.\"\"\"\n        if self.hardware_mode:\n            threshold = (self._running_pos_goodness + self._running_neg_goodness) / 2\n        else:\n            threshold = self.threshold\n\n        if self.hardware_mode:\n            pos_loss = F.relu(threshold - pos_goodness)\n            neg_loss = F.relu(neg_goodness - threshold)\n        else:\n            pos_loss = F.softplus(-(pos_goodness - threshold))\n            neg_loss = F.softplus(neg_goodness - threshold)\n\n        return (pos_loss + neg_loss).mean()\n\n    def hebbian_update(self, pos_goodness: torch.Tensor, neg_goodness: torch.Tensor,\n                       lr: float = 0.01) -> None:\n        \"\"\"Differential Hebbian update for SOEN layer.\"\"\"\n        with torch.no_grad():\n            if self._pos_input is None or self._neg_input is None:\n                return\n\n            pos_input = self._pos_input\n            neg_input = self._neg_input\n            pos_acts = self._pos_activations\n            neg_acts = self._neg_activations\n\n            batch_size = pos_input.shape[0]\n\n            # Update running estimates\n            pos_g_mean = pos_goodness.mean().item()\n            neg_g_mean = neg_goodness.mean().item()\n            self._running_pos_goodness = self._momentum * self._running_pos_goodness + (1 - self._momentum) * pos_g_mean\n            self._running_neg_goodness = self._momentum * self._running_neg_goodness + (1 - self._momentum) * neg_g_mean\n\n            # Differential Hebbian update\n            diff_acts = pos_acts - neg_acts\n            diff_input = pos_input - neg_input\n            avg_acts = (pos_acts + neg_acts) / 2\n            avg_input = (pos_input + neg_input) / 2\n\n            update1 = diff_acts.T @ avg_input / batch_size\n            update2 = avg_acts.T @ diff_input / batch_size\n\n            # Update SOEN connection weights\n            for conn in self.soen_model.connections:\n                if hasattr(conn, 'weight') and conn.weight is not None:\n                    out_dim = min(conn.weight.shape[0], update1.shape[0])\n                    in_dim = min(conn.weight.shape[1], update1.shape[1])\n\n                    delta_w = lr * (update1[:out_dim, :in_dim] + 2.0 * update2[:out_dim, :in_dim])\n                    conn.weight.data[:out_dim, :in_dim] += delta_w\n                    conn.weight.data.clamp_(-0.5, 0.5)\n\n\n# Test SOEN FF layer\nprint(\"Testing SOEN FF Layer...\")\ntry:\n    # Use 784 for SOEN (will process as 28 timesteps of 28 dims each)\n    # Note: For SOEN, we typically process just the image part sequentially\n    soen_layer = SOENFFLayer(784, 256, threshold=2.0, hardware_mode=HARDWARE_MODE)\n    test_input = torch.randn(4, 784)\n    test_output = soen_layer(test_input)\n    print(f\"Input shape: {test_input.shape}\")\n    print(f\"Output shape: {test_output.shape}\")\n    print(f\"Goodness: {soen_layer.compute_goodness().mean().item():.4f}\")\n    print(f\"Hardware mode: {HARDWARE_MODE}\")\nexcept Exception as e:\n    print(f\"SOEN layer test skipped (may need SOEN dependencies): {e}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Forward-Forward Network\n",
    "\n",
    "Stack multiple FF layers, each trained with its own local objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "class ForwardForwardNet(nn.Module):\n    \"\"\"Multi-layer Forward-Forward network with hardware compatibility options.\n\n    Supports two inference modes:\n    - Standard: 10 forward passes (one per label) - not efficient\n    - Hybrid: 1 forward pass with lightweight classifier - efficient\n\n    Input format: [784 image pixels] + [10 one-hot label] = 794 dimensions\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dim: int = 794,  # 784 image + 10 label (CONCATENATED)\n        hidden_dims: List[int] = [500, 500],\n        num_classes: int = 10,\n        threshold: float = 2.0,\n        use_soen: bool = False,\n        hardware_mode: bool = HARDWARE_MODE,\n        use_hybrid_classifier: bool = True,  # Use single-pass inference\n    ):\n        super().__init__()\n        self.num_classes = num_classes\n        self.image_dim = input_dim - num_classes  # 784\n        self.use_soen = use_soen\n        self.hardware_mode = hardware_mode\n        self.use_hybrid_classifier = use_hybrid_classifier and hardware_mode\n\n        # Build FF layers\n        self.layers = nn.ModuleList()\n\n        dims = [input_dim] + hidden_dims\n        for i in range(len(hidden_dims)):\n            if use_soen and i == 0:\n                layer = SOENFFLayer(dims[i], dims[i+1], threshold=threshold,\n                                   hardware_mode=hardware_mode)\n            else:\n                layer = FFLayer(dims[i], dims[i+1], threshold=threshold,\n                               hardware_mode=hardware_mode)\n            self.layers.append(layer)\n\n        # Hybrid classifier for single-pass inference (hardware mode)\n        # This is a small linear layer trained AFTER FF layers are trained\n        if self.use_hybrid_classifier:\n            self.classifier = nn.Linear(hidden_dims[-1], num_classes)\n            self.classifier_trained = False\n        else:\n            self.classifier = None\n            self.classifier_trained = False\n\n        print(f\"Created FF Network with {len(self.layers)} layers:\")\n        for i, layer in enumerate(self.layers):\n            layer_type = \"SOEN\" if isinstance(layer, SOENFFLayer) else \"Standard\"\n            print(f\"  Layer {i}: {dims[i]} -> {dims[i+1]} ({layer_type})\")\n        print(f\"  Input format: {self.image_dim} (image) + {num_classes} (label) = {input_dim}\")\n        print(f\"  Hardware mode: {hardware_mode}\")\n        print(f\"  Hybrid classifier: {self.use_hybrid_classifier}\")\n\n    def forward_all_layers(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward pass through all layers, returning final representation.\"\"\"\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def predict_multipass(self, images: torch.Tensor) -> torch.Tensor:\n        \"\"\"Predict using 10 forward passes (standard FF inference).\n\n        WARNING: This requires 10x the computation of a single forward pass!\n        For hardware mode, use predict() which uses the hybrid classifier.\n        \"\"\"\n        batch_size = images.shape[0]\n        device = images.device\n\n        # Flatten images to 784 dims\n        flat_images = images.view(batch_size, -1)  # (batch, 784)\n\n        # Store goodness for each label\n        all_goodness = torch.zeros(batch_size, self.num_classes, device=device)\n\n        for label in range(self.num_classes):\n            # Create one-hot label\n            one_hot = F.one_hot(torch.tensor([label], device=device), self.num_classes)\n            one_hot = one_hot.float().expand(batch_size, -1)  # (batch, 10)\n\n            # CONCATENATE label to image (not replace!)\n            embedded = torch.cat([flat_images, one_hot], dim=1)  # (batch, 794)\n\n            # Compute total goodness across all layers\n            total_goodness = torch.zeros(batch_size, device=device)\n            x = embedded\n            for layer in self.layers:\n                x = layer(x)\n                total_goodness += layer.compute_goodness()\n\n            all_goodness[:, label] = total_goodness\n\n        return all_goodness.argmax(dim=1)\n\n    def predict_hybrid(self, images: torch.Tensor) -> torch.Tensor:\n        \"\"\"Predict using single forward pass with hybrid classifier.\n\n        This is MUCH more efficient than multipass (1x vs 10x computation).\n        Requires training the classifier after FF layers are trained.\n        \"\"\"\n        if not self.classifier_trained:\n            raise RuntimeError(\"Hybrid classifier not trained! Call train_hybrid_classifier() first.\")\n\n        batch_size = images.shape[0]\n        flat_images = images.view(batch_size, -1)  # (batch, 784)\n\n        # Single forward pass through FF layers\n        # CONCATENATE zeros for label (no label information during inference)\n        zeros_label = torch.zeros(batch_size, self.num_classes, device=images.device)\n        embedded = torch.cat([flat_images, zeros_label], dim=1)  # (batch, 794)\n\n        x = self.forward_all_layers(embedded)\n\n        # Use the stored activations from last layer as features\n        features = self.layers[-1]._raw_activations\n\n        # Classify with lightweight classifier\n        logits = self.classifier(features)\n        return logits.argmax(dim=1)\n\n    def predict(self, images: torch.Tensor) -> torch.Tensor:\n        \"\"\"Predict labels using the appropriate method.\"\"\"\n        if self.use_hybrid_classifier and self.classifier_trained:\n            return self.predict_hybrid(images)\n        else:\n            return self.predict_multipass(images)\n\n    def train_hybrid_classifier(self, train_loader: DataLoader, device: torch.device,\n                                num_epochs: int = 5, lr: float = 0.01):\n        \"\"\"Train the hybrid classifier on top of frozen FF layers.\n\n        This is a lightweight training phase after FF layers are trained.\n        Uses standard cross-entropy loss (only for the classifier, not FF layers).\n        \"\"\"\n        if not self.use_hybrid_classifier:\n            print(\"Hybrid classifier not enabled!\")\n            return\n\n        print(\"\\nTraining hybrid classifier for single-pass inference...\")\n        self.eval()  # Freeze FF layers\n\n        # Only train classifier\n        optimizer = torch.optim.Adam(self.classifier.parameters(), lr=lr)\n        criterion = nn.CrossEntropyLoss()\n\n        for epoch in range(num_epochs):\n            total_loss = 0\n            correct = 0\n            total = 0\n\n            for batch in train_loader:\n                images = batch[\"image\"].to(device)\n                labels = batch[\"label\"].to(device)\n                batch_size = images.shape[0]\n\n                # Forward through FF layers (no label information)\n                # CONCATENATE zeros for label\n                flat_images = images.view(batch_size, -1)\n                zeros_label = torch.zeros(batch_size, self.num_classes, device=device)\n                embedded = torch.cat([flat_images, zeros_label], dim=1)  # (batch, 794)\n\n                with torch.no_grad():\n                    _ = self.forward_all_layers(embedded)\n                    features = self.layers[-1]._raw_activations\n\n                # Train classifier\n                optimizer.zero_grad()\n                logits = self.classifier(features)\n                loss = criterion(logits, labels)\n                loss.backward()\n                optimizer.step()\n\n                total_loss += loss.item()\n                _, predicted = logits.max(1)\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n\n            acc = correct / total\n            print(f\"  Classifier Epoch {epoch+1}/{num_epochs}: Loss={total_loss/len(train_loader):.4f}, Acc={acc:.2%}\")\n\n        self.classifier_trained = True\n        print(\"Hybrid classifier training complete!\")\n\n    def get_layer_optimizer(self, layer_idx: int, lr: float = 0.03):\n        \"\"\"Get optimizer for a specific layer (standard mode only).\"\"\"\n        return torch.optim.Adam(self.layers[layer_idx].parameters(), lr=lr)\n\n\n# Create network\nff_net = ForwardForwardNet(\n    input_dim=config.input_dim,  # 794 = 784 + 10\n    hidden_dims=config.hidden_dims,\n    num_classes=config.num_classes,\n    threshold=config.threshold,\n    use_soen=config.use_soen_layers,\n    hardware_mode=config.hardware_mode,\n    use_hybrid_classifier=config.hardware_mode,  # Use hybrid classifier in hardware mode\n).to(DEVICE)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "The key difference from backprop: **each layer is trained independently** using its own forward passes and local loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "def train_forward_forward(\n    model: ForwardForwardNet,\n    train_loader: DataLoader,\n    test_loader: DataLoader,\n    num_epochs: int = 60,\n    lr: float = 0.03,\n    hebbian_lr: float = 0.01,\n    device: torch.device = DEVICE,\n):\n    \"\"\"Train using Forward-Forward algorithm.\n\n    Supports two modes:\n    - Standard mode: Uses autograd + Adam (calls loss.backward())\n    - Hardware mode: Uses Hebbian updates (no autograd, gradient-free)\n    \"\"\"\n    model.to(device)\n    hardware_mode = model.hardware_mode\n\n    # Create optimizers only for standard mode\n    if not hardware_mode:\n        optimizers = [model.get_layer_optimizer(i, lr) for i in range(len(model.layers))]\n    else:\n        optimizers = None\n\n    # Training history\n    history = {\n        \"train_loss\": [],\n        \"test_accuracy\": [],\n        \"layer_losses\": [[] for _ in range(len(model.layers))],\n        \"layer_pos_goodness\": [[] for _ in range(len(model.layers))],\n        \"layer_neg_goodness\": [[] for _ in range(len(model.layers))],\n    }\n\n    mode_str = \"HARDWARE (Hebbian)\" if hardware_mode else \"STANDARD (Autograd)\"\n    print(f\"\\nStarting Forward-Forward Training - {mode_str}\")\n    print(f\"{'='*60}\")\n    print(f\"Epochs: {num_epochs}, LR: {hebbian_lr if hardware_mode else lr}\")\n    print(f\"Layers: {len(model.layers)}, Device: {device}\")\n    if hardware_mode:\n        print(f\"Updates: Hebbian (gradient-free, hardware-compatible)\")\n        print(f\"Goodness: mean(|x|), Loss: Hinge, Norm: Lateral inhibition\")\n    else:\n        print(f\"Updates: Adam optimizer with autograd\")\n        print(f\"Goodness: mean(xÂ²), Loss: Softplus, Norm: L2\")\n    print(f\"{'='*60}\\n\")\n\n    for epoch in range(num_epochs):\n        model.train()\n        epoch_losses = [0.0 for _ in range(len(model.layers))]\n        epoch_pos_goodness = [0.0 for _ in range(len(model.layers))]\n        epoch_neg_goodness = [0.0 for _ in range(len(model.layers))]\n        num_batches = 0\n\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n        for batch in pbar:\n            pos_data = batch[\"positive\"].to(device)\n            neg_data = batch[\"negative\"].to(device)\n\n            pos_input = pos_data\n            neg_input = neg_data\n\n            batch_loss = 0.0\n\n            for layer_idx, layer in enumerate(model.layers):\n                if hardware_mode:\n                    # ============================================\n                    # HARDWARE MODE: Hebbian updates (no autograd)\n                    # ============================================\n                    with torch.no_grad():\n                        # Forward pass for positive data - store for Hebbian\n                        pos_output = layer(pos_input, store_as='positive')\n                        pos_goodness = layer.compute_goodness()\n\n                        # Forward pass for negative data - store for Hebbian\n                        neg_output = layer(neg_input, store_as='negative')\n                        neg_goodness = layer.compute_goodness()\n\n                        # Compute loss for monitoring (not used for updates)\n                        loss = layer.ff_loss(pos_goodness, neg_goodness)\n\n                    # Apply Hebbian update using stored pos/neg data\n                    layer.hebbian_update(pos_goodness, neg_goodness, lr=hebbian_lr)\n\n                    # Prepare for next layer\n                    pos_input = pos_output.detach()\n                    neg_input = neg_output.detach()\n\n                else:\n                    # ============================================\n                    # STANDARD MODE: Autograd + Adam\n                    # ============================================\n                    optimizer = optimizers[layer_idx]\n                    optimizer.zero_grad()\n\n                    # Forward pass for positive data\n                    pos_output = layer(pos_input)\n                    pos_goodness = layer.compute_goodness()\n\n                    # Forward pass for negative data\n                    neg_output = layer(neg_input)\n                    neg_goodness = layer.compute_goodness()\n\n                    # Compute loss\n                    loss = layer.ff_loss(pos_goodness, neg_goodness)\n\n                    # Backward (only for this layer!)\n                    loss.backward()\n                    optimizer.step()\n\n                    # Prepare for next layer\n                    pos_input = pos_output.detach()\n                    neg_input = neg_output.detach()\n\n                # Track metrics\n                epoch_losses[layer_idx] += loss.item()\n                epoch_pos_goodness[layer_idx] += pos_goodness.mean().item()\n                epoch_neg_goodness[layer_idx] += neg_goodness.mean().item()\n                batch_loss += loss.item()\n\n            num_batches += 1\n            pbar.set_postfix({\"loss\": f\"{batch_loss/len(model.layers):.4f}\"})\n\n        # Average metrics\n        for i in range(len(model.layers)):\n            history[\"layer_losses\"][i].append(epoch_losses[i] / num_batches)\n            history[\"layer_pos_goodness\"][i].append(epoch_pos_goodness[i] / num_batches)\n            history[\"layer_neg_goodness\"][i].append(epoch_neg_goodness[i] / num_batches)\n\n        avg_loss = sum(epoch_losses) / (num_batches * len(model.layers))\n        history[\"train_loss\"].append(avg_loss)\n\n        # Evaluate on test set\n        if (epoch + 1) % 5 == 0 or epoch == 0:\n            test_acc = evaluate_ff(model, test_loader, device)\n            history[\"test_accuracy\"].append(test_acc)\n            print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Test Acc={test_acc:.2%}\")\n\n            # Print layer-wise goodness\n            for i in range(len(model.layers)):\n                pos_g = history[\"layer_pos_goodness\"][i][-1]\n                neg_g = history[\"layer_neg_goodness\"][i][-1]\n                sep = pos_g - neg_g\n                print(f\"  Layer {i}: pos={pos_g:.3f}, neg={neg_g:.3f}, sep={sep:+.3f}\")\n\n    return history\n\n\ndef evaluate_ff(model: ForwardForwardNet, test_loader: DataLoader, device: torch.device):\n    \"\"\"Evaluate Forward-Forward model.\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for batch in test_loader:\n            images = batch[\"image\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            # Use multipass prediction for evaluation during training\n            # (hybrid classifier may not be trained yet)\n            predictions = model.predict_multipass(images)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n\n    return correct / total"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# Train the model\nhistory = train_forward_forward(\n    model=ff_net,\n    train_loader=train_loader,\n    test_loader=test_loader,\n    num_epochs=config.num_epochs,\n    lr=config.learning_rate,\n    hebbian_lr=config.hebbian_lr,\n    device=DEVICE,\n)\n\n# If using hybrid classifier, train it for efficient single-pass inference\nif ff_net.use_hybrid_classifier:\n    ff_net.train_hybrid_classifier(train_loader, DEVICE, num_epochs=10, lr=0.001)\n\n    # Evaluate with hybrid classifier\n    print(\"\\nEvaluating with hybrid classifier (single-pass inference)...\")\n    ff_net.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in test_loader:\n            images = batch[\"image\"].to(DEVICE)\n            labels = batch[\"label\"].to(DEVICE)\n            predictions = ff_net.predict_hybrid(images)\n            correct += (predictions == labels).sum().item()\n            total += labels.size(0)\n    print(f\"Hybrid classifier accuracy: {correct/total:.2%}\")\n    print(f\"(This uses 1 forward pass vs 10 for standard FF inference)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ff_training_history(history: Dict):\n",
    "    \"\"\"Plot Forward-Forward training metrics.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Forward-Forward Training Progress', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Overall loss\n",
    "    axes[0, 0].plot(history[\"train_loss\"], 'b-', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Test accuracy\n",
    "    epochs_with_acc = list(range(0, len(history[\"train_loss\"]), 5))\n",
    "    if 0 not in epochs_with_acc:\n",
    "        epochs_with_acc = [0] + epochs_with_acc\n",
    "    axes[0, 1].plot(epochs_with_acc[:len(history[\"test_accuracy\"])], \n",
    "                    history[\"test_accuracy\"], 'g-o', linewidth=2, markersize=6)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].set_title('Test Accuracy')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim([0, 1])\n",
    "    \n",
    "    # 3. Layer-wise goodness (positive)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(history[\"layer_pos_goodness\"])))\n",
    "    for i, (pos_g, neg_g) in enumerate(zip(history[\"layer_pos_goodness\"], \n",
    "                                           history[\"layer_neg_goodness\"])):\n",
    "        axes[1, 0].plot(pos_g, color=colors[i], linestyle='-', \n",
    "                        linewidth=2, label=f'Layer {i} (pos)')\n",
    "        axes[1, 0].plot(neg_g, color=colors[i], linestyle='--', \n",
    "                        linewidth=2, alpha=0.7, label=f'Layer {i} (neg)')\n",
    "    \n",
    "    # Add threshold line\n",
    "    threshold = config.threshold\n",
    "    axes[1, 0].axhline(y=threshold, color='red', linestyle=':', linewidth=2, label=f'Threshold ({threshold})')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Goodness')\n",
    "    axes[1, 0].set_title('Layer-wise Goodness (solid=positive, dashed=negative)')\n",
    "    axes[1, 0].legend(loc='best', fontsize=8)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Layer-wise loss\n",
    "    for i, layer_loss in enumerate(history[\"layer_losses\"]):\n",
    "        axes[1, 1].plot(layer_loss, color=colors[i], linewidth=2, label=f'Layer {i}')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].set_title('Layer-wise FF Loss')\n",
    "    axes[1, 1].legend(loc='best')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Final test accuracy: {history['test_accuracy'][-1]:.2%}\")\n",
    "    print(f\"Best test accuracy: {max(history['test_accuracy']):.2%}\")\n",
    "    print(f\"\\nFinal layer-wise goodness:\")\n",
    "    for i in range(len(history['layer_pos_goodness'])):\n",
    "        pos = history['layer_pos_goodness'][i][-1]\n",
    "        neg = history['layer_neg_goodness'][i][-1]\n",
    "        separation = pos - neg\n",
    "        print(f\"  Layer {i}: pos={pos:.3f}, neg={neg:.3f}, separation={separation:.3f}\")\n",
    "\n",
    "\n",
    "plot_ff_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 9. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ff_predictions(model: ForwardForwardNet, test_dataset, n_samples=20):\n",
    "    \"\"\"Visualize Forward-Forward predictions with goodness values.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Random samples\n",
    "    indices = np.random.choice(len(test_dataset), n_samples, replace=False)\n",
    "    \n",
    "    n_cols = 5\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3.5*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    fig.suptitle('Forward-Forward Predictions', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    correct = 0\n",
    "    for i, idx in enumerate(indices):\n",
    "        sample = test_dataset[idx]\n",
    "        image = sample['image'].unsqueeze(0).to(DEVICE)\n",
    "        true_label = sample['label'].item()\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            pred = model.predict(image).item()\n",
    "        \n",
    "        is_correct = pred == true_label\n",
    "        correct += is_correct\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[i]\n",
    "        ax.imshow(sample['image'], cmap='gray')\n",
    "        \n",
    "        color = 'green' if is_correct else 'red'\n",
    "        symbol = 'âœ“' if is_correct else 'âœ—'\n",
    "        ax.set_title(f\"{symbol} Pred: {pred}\\nTrue: {true_label}\", \n",
    "                     color=color, fontsize=10, fontweight='bold' if not is_correct else 'normal')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSample accuracy: {correct}/{n_samples} ({correct/n_samples:.1%})\")\n",
    "\n",
    "\n",
    "visualize_ff_predictions(ff_net, test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 10. Analyze Goodness Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "def analyze_goodness_separation(model: ForwardForwardNet, test_loader: DataLoader):\n    \"\"\"Analyze how well positive and negative goodness are separated.\"\"\"\n\n    model.eval()\n\n    all_pos_goodness = [[] for _ in range(len(model.layers))]\n    all_neg_goodness = [[] for _ in range(len(model.layers))]\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Analyzing goodness\"):\n            pos_data = batch[\"positive\"].to(DEVICE)\n            neg_data = batch[\"negative\"].to(DEVICE)\n\n            pos_input = pos_data\n            neg_input = neg_data\n\n            for layer_idx, layer in enumerate(model.layers):\n                # Compute positive goodness IMMEDIATELY after forward\n                pos_output = layer(pos_input)\n                pos_g = layer.compute_goodness()\n\n                # Compute negative goodness IMMEDIATELY after forward\n                neg_output = layer(neg_input)\n                neg_g = layer.compute_goodness()\n\n                all_pos_goodness[layer_idx].extend(pos_g.cpu().numpy())\n                all_neg_goodness[layer_idx].extend(neg_g.cpu().numpy())\n\n                pos_input = pos_output\n                neg_input = neg_output\n\n    # Plot distributions\n    fig, axes = plt.subplots(1, len(model.layers), figsize=(6*len(model.layers), 5))\n    if len(model.layers) == 1:\n        axes = [axes]\n\n    fig.suptitle('Goodness Distributions by Layer', fontsize=14, fontweight='bold')\n\n    threshold = config.threshold\n\n    for i, ax in enumerate(axes):\n        pos_g = np.array(all_pos_goodness[i])\n        neg_g = np.array(all_neg_goodness[i])\n\n        # Histograms\n        ax.hist(pos_g, bins=50, alpha=0.6, color='green', label=f'Positive (Î¼={pos_g.mean():.2f})', density=True)\n        ax.hist(neg_g, bins=50, alpha=0.6, color='red', label=f'Negative (Î¼={neg_g.mean():.2f})', density=True)\n\n        # Threshold\n        ax.axvline(x=threshold, color='black', linestyle='--', linewidth=2, label=f'Threshold ({threshold})')\n\n        ax.set_xlabel('Goodness', fontsize=12)\n        ax.set_ylabel('Density', fontsize=12)\n        ax.set_title(f'Layer {i}', fontsize=12)\n        ax.legend(loc='best')\n        ax.grid(True, alpha=0.3)\n\n        # Print separation stats\n        separation = pos_g.mean() - neg_g.mean()\n        overlap = np.sum((pos_g < threshold) | (neg_g > threshold)) / (len(pos_g) + len(neg_g))\n        print(f\"Layer {i}: separation={separation:.3f}, ~overlap={overlap:.1%}\")\n\n    plt.tight_layout()\n    plt.show()\n\n\nanalyze_goodness_separation(ff_net, test_loader)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 11. Compare with Backpropagation (Optional)\n",
    "\n",
    "For reference, let's see how a similar architecture performs with standard backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackpropNet(nn.Module):\n",
    "    \"\"\"Standard backprop network for comparison.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=784, hidden_dims=[500, 500], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dims + [num_classes]\n",
    "        \n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "            if i < len(dims) - 2:  # No activation after last layer\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.LayerNorm(dims[i+1]))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def train_backprop(model, train_loader, test_loader, num_epochs=20, lr=0.001):\n",
    "    \"\"\"Train with standard backpropagation.\"\"\"\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {\"train_loss\": [], \"test_accuracy\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Backprop Epoch {epoch+1}\"):\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # This is the key difference from FF!\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        history[\"train_loss\"].append(avg_loss)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                images = batch[\"image\"].to(DEVICE)\n",
    "                labels = batch[\"label\"].to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        \n",
    "        acc = correct / total\n",
    "        history[\"test_accuracy\"].append(acc)\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Test Acc={acc:.2%}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# Uncomment to train backprop comparison\n",
    "# bp_net = BackpropNet(hidden_dims=config.hidden_dims)\n",
    "# bp_history = train_backprop(bp_net, train_loader, test_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": "## Summary\n\n### Label Embedding: Concatenation vs Replacement\n\nThis implementation uses **concatenated labels** (not Hinton's pixel replacement):\n\n| Approach | Input Dim | Pros | Cons |\n|----------|-----------|------|------|\n| **Replacement** (Hinton) | 784 | Same dimension | Loses 10 pixels of image |\n| **Concatenation** (ours) | 794 | Preserves all image info | Slightly larger input |\n\n```\nOur approach:\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  [784 image pixels] + [10 one-hot label] = 794 dims   â”‚\nâ”‚                                                        â”‚\nâ”‚  Positive: [image] + [0,0,0,1,0,0,0,0,0,0]  (label=3) â”‚\nâ”‚  Negative: [image] + [0,0,0,0,0,0,0,1,0,0]  (label=7) â”‚\nâ”‚                                                        â”‚\nâ”‚  Image pixels are IDENTICAL - only label differs!      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Hardware Compatibility Analysis\n\nThis implementation provides **two modes** with different trade-offs:\n\n| Aspect | Standard Mode | Hardware Mode |\n|--------|---------------|---------------|\n| **Goodness** | `mean(xÂ²)` | `mean(|x|)` |\n| **Normalization** | L2 (sqrt+div) | Lateral inhibition (sub) |\n| **Loss** | Softplus (exp+log) | Hinge (comparator+ReLU) |\n| **Updates** | Adam + autograd | Hebbian (gradient-free) |\n| **Inference** | 10 passes | 1 pass (hybrid classifier) |\n| **Accuracy** | ~95-98% | ~85-92% |\n| **Hardware ready?** | âŒ No | âœ… Yes |\n\n### What FF Actually Provides for SOEN\n\n**Eliminated:**\n- âœ… Cross-layer gradient propagation (weight transport problem)\n- âœ… Need to store activations for multi-layer backprop\n- âœ… Global error signal coordination\n\n**Still needed (Standard Mode):**\n- âš ï¸ Autograd within each layer (`loss.backward()`)\n- âš ï¸ Optimizer states (Adam momentum, variance)\n- âš ï¸ External computation for training\n\n**Eliminated in Hardware Mode:**\n- âœ… All autograd (uses Hebbian updates)\n- âœ… Complex nonlinear computations\n- âœ… Multiple inference passes\n\n### Hardware-Compatible Operations\n\n| Operation | SOEN Implementation |\n|-----------|-------------------|\n| `|x|` (absolute value) | Full-wave rectifier (diodes) |\n| `mean(x)` | Current summation + scaling |\n| `x - k*mean` (lateral inhibition) | Differential amplifier |\n| `max(0, x)` (ReLU/hinge) | Threshold comparator |\n| `w += Î”w` (weight update) | Optical attenuation adjustment |\n\n### Network Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  INPUT: 794 dims = [784 image] + [10 label one-hot]        â”‚\nâ”‚                          â”‚                                  â”‚\nâ”‚                          â–¼                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ FF Layer 1: 794 â†’ 500                               â”‚   â”‚\nâ”‚  â”‚   Linear â†’ ReLU â†’ Normalize â†’ Goodness             â”‚   â”‚\nâ”‚  â”‚   LOCAL OBJECTIVE: pos_goodness > Î¸ > neg_goodness â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                          â”‚ (detached)                       â”‚\nâ”‚                          â–¼                                  â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ FF Layer 2: 500 â†’ 500                               â”‚   â”‚\nâ”‚  â”‚   Linear â†’ ReLU â†’ Normalize â†’ Goodness             â”‚   â”‚\nâ”‚  â”‚   LOCAL OBJECTIVE: pos_goodness > Î¸ > neg_goodness â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                          â”‚                                  â”‚\nâ”‚                          â–¼                                  â”‚\nâ”‚  INFERENCE: Multipass (10x) or Hybrid Classifier (1x)      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Known Limitations\n\n1. **Accuracy Gap**: Hardware mode achieves lower accuracy (~85-92% vs ~95-98%)\n2. **Hebbian Learning**: Slower convergence than gradient-based methods\n3. **Threshold Sensitivity**: Performance depends on threshold tuning\n4. **Hybrid Classifier**: Still requires external training (but inference is on-chip)\n\n### Recommendations\n\n**For Simulation/Research:**\n- Use `HARDWARE_MODE = False` for best accuracy\n- Useful for algorithm development and baseline comparison\n\n**For Hardware Deployment:**\n- Use `HARDWARE_MODE = True` for realistic constraints\n- Accept lower accuracy for hardware compatibility\n- Train hybrid classifier for efficient inference\n\n### Future Improvements\n\n1. **Better Hebbian Rules**: Explore BCM, Oja's rule, or contrastive Hebbian learning\n2. **Threshold Adaptation**: Automatic threshold tuning during training\n3. **Sparse Representations**: Improve efficiency with sparse activations\n4. **On-Chip Classifier**: Replace hybrid classifier with goodness-based output neurons\n\n### References\n\n- Hinton, G. (2022). \"The Forward-Forward Algorithm: Some Preliminary Investigations\"\n- Original FF paper proposes this as a biologically plausible alternative to backprop\n- Our hardware-compatible modifications adapt FF for SOEN constraints"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}