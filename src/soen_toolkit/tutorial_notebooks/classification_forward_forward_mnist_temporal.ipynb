{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Forward-Forward MNIST Classification (Row-by-Row Temporal)\n\n10-class MNIST classification using Forward-Forward algorithm with **temporal row scanning**.\n\n## Architecture\n\n```\nInput: 28 pixels (one row) + 10 (one-hot label) = 38 per timestep\nTimesteps: 28 (one per row, scanning top to bottom)\nHidden: ≤24 SingleDendrite neurons\nOutput: Goodness (sum of squared activations at final timestep)\n```\n\n## Key Innovation: Temporal Image Scanning\n\nInstead of feeding all 784 pixels at once:\n- Feed image **row by row** (28 pixels per timestep)\n- Network accumulates information over 28 timesteps\n- Final state captures full image representation\n- Temporal dynamics become meaningful!\n\n## Inference (10 forward passes)\n\n```\nFor each class c ∈ {0, 1, ..., 9}:\n    For t in 0..27:\n        X_t = [row_t_pixels, one_hot(c)]  # 38 dims\n    goodness_c = compute_goodness(final_state)\nPredict: argmax(goodness_0, ..., goodness_9)\n```\n\n## Hardware Compatibility\n\n- Goodness = mean(I²) = power measurement\n- Label embedding = optical input modulation\n- Temporal scanning = natural sequential processing\n- No backward pass needed for inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport gzip\nimport urllib.request\n\nfrom soen_toolkit.core import (\n    ConnectionConfig,\n    LayerConfig,\n    SimulationConfig,\n    SOENModelCore,\n)\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nprint(f\"PyTorch version: {torch.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Direct MNIST download without torchvision\ndef download_mnist(data_dir='./data/mnist'):\n    \"\"\"Download MNIST dataset without torchvision.\"\"\"\n    os.makedirs(data_dir, exist_ok=True)\n    \n    base_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/'\n    files = {\n        'train_images': 'train-images-idx3-ubyte.gz',\n        'train_labels': 'train-labels-idx1-ubyte.gz',\n        'test_images': 't10k-images-idx3-ubyte.gz',\n        'test_labels': 't10k-labels-idx1-ubyte.gz',\n    }\n    \n    paths = {}\n    for key, filename in files.items():\n        filepath = os.path.join(data_dir, filename)\n        if not os.path.exists(filepath):\n            print(f\"Downloading {filename}...\")\n            urllib.request.urlretrieve(base_url + filename, filepath)\n        paths[key] = filepath\n    \n    return paths\n\n\ndef load_mnist_images(filepath):\n    \"\"\"Load MNIST images from gzipped IDX file - keep as 28x28.\"\"\"\n    with gzip.open(filepath, 'rb') as f:\n        magic = int.from_bytes(f.read(4), 'big')\n        n_images = int.from_bytes(f.read(4), 'big')\n        n_rows = int.from_bytes(f.read(4), 'big')\n        n_cols = int.from_bytes(f.read(4), 'big')\n        data = np.frombuffer(f.read(), dtype=np.uint8)\n        # Keep as [N, 28, 28] for row-by-row processing\n        return data.reshape(n_images, n_rows, n_cols).astype(np.float32) / 255.0\n\n\ndef load_mnist_labels(filepath):\n    \"\"\"Load MNIST labels from gzipped IDX file.\"\"\"\n    with gzip.open(filepath, 'rb') as f:\n        magic = int.from_bytes(f.read(4), 'big')\n        n_labels = int.from_bytes(f.read(4), 'big')\n        return np.frombuffer(f.read(), dtype=np.uint8)\n\n\n# Download and load MNIST\npaths = download_mnist()\nX_train_full = torch.from_numpy(load_mnist_images(paths['train_images']))\ny_train_full = torch.from_numpy(load_mnist_labels(paths['train_labels'])).long()\nX_test_full = torch.from_numpy(load_mnist_images(paths['test_images']))\ny_test_full = torch.from_numpy(load_mnist_labels(paths['test_labels'])).long()\n\nprint(f\"Full dataset: Train={X_train_full.shape}, Test={X_test_full.shape}\")\nprint(f\"Image shape: {X_train_full.shape[1:]} (28 rows × 28 cols)\")\n\n# Use training data subset\nN_TRAIN = 20000\nN_TEST = 2000\n\ntorch.manual_seed(42)\ntrain_idx = torch.randperm(len(X_train_full))[:N_TRAIN]\ntest_idx = torch.randperm(len(X_test_full))[:N_TEST]\n\nX_train = X_train_full[train_idx]\ny_train = y_train_full[train_idx]\nX_test = X_test_full[test_idx]\ny_test = y_test_full[test_idx]\n\n# Scale to SOEN operating range [0.025, 0.275]\nX_train = X_train * 0.25 + 0.025\nX_test = X_test * 0.25 + 0.025\n\nprint(f\"\\nUsing subset:\")\nprint(f\"  Training set: {X_train.shape} (N × rows × cols)\")\nprint(f\"  Test set: {X_test.shape}\")\nprint(f\"  X range: [{X_train.min():.3f}, {X_train.max():.3f}]\")\nprint(f\"  Class distribution (train): {torch.bincount(y_train)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize samples and row-by-row scanning concept\nfig, axes = plt.subplots(2, 5, figsize=(12, 5))\nfor i, ax in enumerate(axes.flat):\n    img = X_train[i].numpy()\n    ax.imshow(img, cmap='gray')\n    ax.set_title(f'Label: {y_train[i].item()}')\n    ax.axis('off')\nplt.suptitle('MNIST Samples (will be scanned row-by-row: 28 timesteps)')\nplt.tight_layout()\nplt.show()\n\n# Show row-by-row concept\nfig, axes = plt.subplots(1, 4, figsize=(14, 3))\nsample_img = X_train[0].numpy()\n\naxes[0].imshow(sample_img, cmap='gray')\naxes[0].set_title('Full Image')\naxes[0].axis('off')\n\nfor i, t in enumerate([0, 13, 27]):\n    axes[i+1].bar(range(28), sample_img[t], color='steelblue')\n    axes[i+1].set_ylim(0, 0.3)\n    axes[i+1].set_xlabel('Pixel')\n    axes[i+1].set_ylabel('Value')\n    axes[i+1].set_title(f't={t} (row {t})')\n\nplt.suptitle('Row-by-Row Temporal Input: Each row = one timestep', fontsize=12)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Forward-Forward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "N_CLASSES = 10\nN_ROWS = 28      # Number of timesteps (rows in image)\nN_COLS = 28      # Pixels per row\nLABEL_SCALE = 0.25\n\n# Input dimension: 28 pixels + 10 label = 38 per timestep\nINPUT_DIM_PER_ROW = N_COLS + N_CLASSES\n\ndef embed_label_temporal(X, y, n_classes=N_CLASSES, label_scale=LABEL_SCALE):\n    \"\"\"\n    Embed one-hot label into each row of the temporal sequence.\n    \n    Args:\n        X: [N, 28, 28] images (N samples, 28 rows, 28 cols)\n        y: [N] class labels (0-9)\n    \n    Returns:\n        X_embedded: [N, 28, 38] - each row has 28 pixels + 10 label dims\n    \"\"\"\n    N = X.shape[0]\n    \n    # Create one-hot labels [N, 10]\n    one_hot = torch.zeros(N, n_classes)\n    one_hot.scatter_(1, y.unsqueeze(1), label_scale)\n    \n    # Expand to [N, 28, 10] - same label at each timestep\n    one_hot_expanded = one_hot.unsqueeze(1).expand(-1, N_ROWS, -1)\n    \n    # Concatenate: [N, 28, 28] + [N, 28, 10] = [N, 28, 38]\n    return torch.cat([X, one_hot_expanded], dim=2)\n\n\ndef create_positive_negative_pairs_temporal(X, y, n_classes=N_CLASSES, label_scale=LABEL_SCALE):\n    \"\"\"\n    Create positive and negative temporal sequences for Forward-Forward.\n    \n    Positive: image rows with correct label at each timestep\n    Negative: image rows with random wrong label at each timestep\n    \"\"\"\n    N = X.shape[0]\n    \n    # Positive: correct labels\n    X_pos = embed_label_temporal(X, y, n_classes, label_scale)\n    \n    # Negative: random wrong labels\n    y_wrong = (y + torch.randint(1, n_classes, (N,))) % n_classes\n    X_neg = embed_label_temporal(X, y_wrong, n_classes, label_scale)\n    \n    return X_pos, X_neg\n\n\n# Test embedding\nX_pos, X_neg = create_positive_negative_pairs_temporal(X_train[:5], y_train[:5])\nprint(f\"Input shape: {X_train[:5].shape} (N × rows × cols)\")\nprint(f\"Embedded shape: {X_pos.shape} (N × timesteps × features)\")\nprint(f\"Features per timestep: {N_COLS} pixels + {N_CLASSES} label = {INPUT_DIM_PER_ROW}\")\nprint(f\"Timesteps: {N_ROWS} (one per row)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "def compute_goodness(activations):\n    \"\"\"\n    Compute goodness as mean of squared activations.\n    Hardware-compatible: measures mean power in the layer.\n    \"\"\"\n    return (activations ** 2).mean(dim=1)\n\n\ndef forward_forward_loss(goodness_pos, goodness_neg, margin=0.01):\n    \"\"\"\n    Contrastive Forward-Forward loss.\n    \n    Push G_pos to be greater than G_neg by at least margin.\n    Small margin (0.01) works well when separation is ~0.1.\n    \"\"\"\n    return F.softplus(margin - (goodness_pos - goodness_neg)).mean()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Build SOEN Model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "def build_ff_temporal_model(hidden_dims, input_dim=INPUT_DIM_PER_ROW, dt=1.0, gamma_minus=1e-6):\n    \"\"\"\n    Build a SOEN model for Forward-Forward with temporal row scanning.\n    \n    Args:\n        hidden_dims: List of hidden layer dimensions (e.g., [24] or [12, 12])\n        input_dim: 28 pixels + 10 label = 38 per timestep\n        gamma_minus: Decay rate. Use 1e-6 for pure accumulation (recommended)\n                     Higher values cause information loss over 28 timesteps.\n    \n    Key difference from flat input:\n    - Much smaller input dimension (38 vs 794)\n    - Temporal dynamics accumulate information over 28 timesteps\n    - Network \"scans\" image row by row\n    \n    IMPORTANT: gamma_minus=0.05 causes 77% information loss over 28 steps!\n    With gamma_minus=1e-6, the network acts as a pure accumulator.\n    \"\"\"\n    sim_cfg = SimulationConfig(\n        dt=dt,\n        input_type=\"state\",\n        track_phi=False,\n        track_power=False,\n    )\n    \n    layers = []\n    connections = []\n    \n    # Input layer - 38 dims per timestep\n    layers.append(LayerConfig(\n        layer_id=0,\n        layer_type=\"Input\",\n        params={\"dim\": input_dim},\n    ))\n    \n    # Hidden layers\n    for i, hidden_dim in enumerate(hidden_dims):\n        layer_id = i + 1\n        \n        layers.append(LayerConfig(\n            layer_id=layer_id,\n            layer_type=\"SingleDendrite\",\n            params={\n                \"dim\": hidden_dim,\n                \"solver\": \"FE\",\n                \"source_func\": \"Heaviside_fit_state_dep\",\n                \"phi_offset\": 0.02,\n                \"bias_current\": 1.98,\n                \"gamma_plus\": 1.0,\n                \"gamma_minus\": gamma_minus,  # 1e-6 = pure accumulator (no forgetting)\n                \"learnable_params\": {\n                    \"phi_offset\": False,\n                    \"bias_current\": False,\n                    \"gamma_plus\": False,\n                    \"gamma_minus\": False,\n                },\n            },\n        ))\n        \n        connections.append(ConnectionConfig(\n            from_layer=layer_id - 1,\n            to_layer=layer_id,\n            connection_type=\"all_to_all\",\n            learnable=True,\n            params={\"init\": \"xavier_uniform\"},\n        ))\n    \n    model = SOENModelCore(\n        sim_config=sim_cfg,\n        layers_config=layers,\n        connections_config=connections,\n    )\n    \n    return model\n\n\n# Test model with pure accumulation (gamma_minus=1e-6)\nHIDDEN_DIMS = [24]\ntest_model = build_ff_temporal_model(HIDDEN_DIMS, gamma_minus=1e-6)\nn_params = sum(p.numel() for p in test_model.parameters() if p.requires_grad)\nprint(f\"Model architecture: {INPUT_DIM_PER_ROW} → {HIDDEN_DIMS} → goodness\")\nprint(f\"Input: {INPUT_DIM_PER_ROW} = {N_COLS} pixels + {N_CLASSES} label (per timestep)\")\nprint(f\"Timesteps: {N_ROWS} (rows)\")\nprint(f\"Parameters: {n_params}\")\nprint(f\"gamma_minus=1e-6 (pure accumulator - NO information loss over 28 steps)\")\nprint(f\"\\nWhy pure accumulator?\")\nprint(f\"  With gamma_minus=0.05: decay^28 = 0.95^28 = {0.95**28:.2%} retention\")\nprint(f\"  With gamma_minus=1e-6: decay^28 ≈ 100% retention\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_ff_temporal_fast(model, X, y, batch_size=100, goodness_mode='final'):\n    \"\"\"\n    Fast evaluation for temporal row-by-row processing.\n    \n    Args:\n        goodness_mode: 'final' = only last timestep, 'all' = sum all timesteps\n    \"\"\"\n    model.eval()\n    N = X.shape[0]\n    all_predictions = []\n    \n    with torch.no_grad():\n        for start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n            X_batch = X[start:end]  # [B, 28, 28]\n            B = X_batch.shape[0]\n            \n            # Repeat each sample N_CLASSES times\n            X_repeated = X_batch.unsqueeze(1).expand(-1, N_CLASSES, -1, -1).reshape(B * N_CLASSES, N_ROWS, N_COLS)\n            y_hypotheses = torch.arange(N_CLASSES).unsqueeze(0).expand(B, -1).reshape(B * N_CLASSES)\n            \n            X_embedded = embed_label_temporal(X_repeated, y_hypotheses)\n            _, layer_states = model(X_embedded)\n            \n            # Compute goodness based on mode\n            total_goodness = torch.zeros(B * N_CLASSES)\n            for layer_idx in range(1, len(model.layers)):\n                if goodness_mode == 'final':\n                    act = layer_states[layer_idx][:, -1, :]  # Final timestep only\n                    total_goodness += compute_goodness(act)\n                elif goodness_mode == 'all':\n                    # Sum goodness over all timesteps (better gradient signal)\n                    for t in range(layer_states[layer_idx].shape[1]):\n                        act = layer_states[layer_idx][:, t, :]\n                        total_goodness += compute_goodness(act)\n            \n            goodness_matrix = total_goodness.reshape(B, N_CLASSES)\n            predictions = goodness_matrix.argmax(dim=1)\n            all_predictions.append(predictions)\n    \n    all_predictions = torch.cat(all_predictions)\n    accuracy = (all_predictions == y).float().mean().item()\n    model.train()\n    return accuracy\n\n\ndef train_forward_forward_temporal(model, X_train, y_train, X_test, y_test,\n                                    n_epochs=100, lr=0.01, margin=0.01,\n                                    batch_size=64, eval_subset=1000, verbose=True,\n                                    weight_decay=1e-4, lr_decay=0.98,\n                                    goodness_mode='all'):\n    \"\"\"\n    Train SOEN model with Forward-Forward using temporal row scanning.\n    \n    Args:\n        goodness_mode: 'final' = only last timestep (weak gradient for early rows)\n                       'all' = sum all timesteps (better gradient signal)\n    \n    For multi-layer networks, we accumulate losses from all layers and do\n    a single backward pass to avoid gradient computation issues.\n    \"\"\"\n    model.train()\n    \n    # Single optimizer for all parameters (avoids gradient computation issues)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n    \n    # Track which layers are hidden\n    hidden_layer_indices = [i for i, l in enumerate(model.layers) if l.layer_type != 'Input']\n    \n    history = {\n        'loss': [],\n        'train_acc': [],\n        'test_acc': [],\n        'goodness_pos': [],\n        'goodness_neg': [],\n        'lr': [],\n    }\n    \n    N = X_train.shape[0]\n    n_batches = (N + batch_size - 1) // batch_size\n    \n    # Subset for fast evaluation\n    eval_idx = torch.randperm(N)[:min(eval_subset, N)]\n    X_train_eval = X_train[eval_idx]\n    y_train_eval = y_train[eval_idx]\n    \n    best_test_acc = 0\n    \n    for epoch in range(n_epochs):\n        epoch_loss = 0\n        epoch_g_pos = []\n        epoch_g_neg = []\n        \n        # Shuffle data\n        perm = torch.randperm(N)\n        X_shuffled = X_train[perm]\n        y_shuffled = y_train[perm]\n        \n        for batch_idx in range(n_batches):\n            start = batch_idx * batch_size\n            end = min(start + batch_size, N)\n            \n            X_batch = X_shuffled[start:end]  # [B, 28, 28]\n            y_batch = y_shuffled[start:end]\n            \n            # Create pos/neg pairs with temporal embedding\n            X_pos, X_neg = create_positive_negative_pairs_temporal(X_batch, y_batch)\n            \n            optimizer.zero_grad()\n            \n            # Forward pass through all 28 timesteps\n            _, layer_states_pos = model(X_pos)\n            _, layer_states_neg = model(X_neg)\n            \n            # Accumulate loss from all hidden layers\n            total_loss = 0\n            batch_g_pos_list = []\n            batch_g_neg_list = []\n            \n            for layer_idx in hidden_layer_indices:\n                if goodness_mode == 'final':\n                    # Only final timestep (weak gradient for early rows)\n                    act_pos = layer_states_pos[layer_idx][:, -1, :]\n                    act_neg = layer_states_neg[layer_idx][:, -1, :]\n                    g_pos = compute_goodness(act_pos)\n                    g_neg = compute_goodness(act_neg)\n                elif goodness_mode == 'all':\n                    # Sum goodness over ALL timesteps (better gradient signal)\n                    n_timesteps = layer_states_pos[layer_idx].shape[1]\n                    g_pos = torch.zeros(X_batch.shape[0])\n                    g_neg = torch.zeros(X_batch.shape[0])\n                    for t in range(n_timesteps):\n                        act_pos = layer_states_pos[layer_idx][:, t, :]\n                        act_neg = layer_states_neg[layer_idx][:, t, :]\n                        g_pos = g_pos + compute_goodness(act_pos)\n                        g_neg = g_neg + compute_goodness(act_neg)\n                \n                batch_g_pos_list.append(g_pos.mean().item())\n                batch_g_neg_list.append(g_neg.mean().item())\n                \n                layer_loss = forward_forward_loss(g_pos, g_neg, margin)\n                total_loss = total_loss + layer_loss\n            \n            # Single backward pass for accumulated loss\n            total_loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            batch_loss = total_loss.item()\n            batch_g_pos = np.mean(batch_g_pos_list)\n            batch_g_neg = np.mean(batch_g_neg_list)\n            \n            epoch_loss += batch_loss\n            epoch_g_pos.append(batch_g_pos)\n            epoch_g_neg.append(batch_g_neg)\n            \n            if verbose and batch_idx % 50 == 0:\n                print(f\"\\rEpoch {epoch+1}/{n_epochs} | Batch {batch_idx+1}/{n_batches} | \"\n                      f\"Loss: {batch_loss:.4f} | G+: {batch_g_pos:.4f} | G-: {batch_g_neg:.4f}\", end=\"\")\n        \n        # Step LR scheduler\n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        # Evaluate\n        train_acc = evaluate_ff_temporal_fast(model, X_train_eval, y_train_eval, goodness_mode=goodness_mode)\n        test_acc = evaluate_ff_temporal_fast(model, X_test, y_test, goodness_mode=goodness_mode)\n        \n        if test_acc > best_test_acc:\n            best_test_acc = test_acc\n        \n        history['loss'].append(epoch_loss / n_batches)\n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)\n        history['goodness_pos'].append(np.mean(epoch_g_pos))\n        history['goodness_neg'].append(np.mean(epoch_g_neg))\n        history['lr'].append(current_lr)\n        \n        if verbose:\n            sep = np.mean(epoch_g_pos) - np.mean(epoch_g_neg)\n            print(f\"\\rEpoch {epoch+1}/{n_epochs} | Loss: {epoch_loss/n_batches:.4f} | \"\n                  f\"Train: {train_acc:.4f} | Test: {test_acc:.4f} | \"\n                  f\"Best: {best_test_acc:.4f} | Sep: {sep:.4f}    \")\n    \n    return history"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# Build temporal model with 24 hidden neurons\nHIDDEN_DIMS = [24]\nMARGIN = 0.01\nN_EPOCHS = 100\nLR = 0.01\nBATCH_SIZE = 64\nWEIGHT_DECAY = 1e-4\nLR_DECAY = 0.98\nGAMMA_MINUS = 1e-6  # Pure accumulator - critical for temporal processing!\nGOODNESS_MODE = 'all'  # Sum all timesteps for better gradient signal\n\nprint(f\"Training Forward-Forward MNIST with TEMPORAL ROW SCANNING...\")\nprint(f\"Architecture: {INPUT_DIM_PER_ROW} → {HIDDEN_DIMS} → goodness\")\nprint(f\"Input per timestep: {N_COLS} pixels + {N_CLASSES} label = {INPUT_DIM_PER_ROW}\")\nprint(f\"Timesteps: {N_ROWS} (one per row)\")\nprint(f\"Total neurons: {sum(HIDDEN_DIMS)} (constraint: <26)\")\nprint(f\"Margin: {MARGIN}, Initial LR: {LR}\")\nprint(f\"Training samples: {N_TRAIN}, Test samples: {N_TEST}\")\nprint(f\"\\nKEY SETTINGS:\")\nprint(f\"  gamma_minus = {GAMMA_MINUS} (pure accumulator, no information loss)\")\nprint(f\"  goodness_mode = '{GOODNESS_MODE}' (all timesteps → better gradient)\")\nprint(\"=\" * 80)\n\ntorch.manual_seed(42)\nmodel = build_ff_temporal_model(HIDDEN_DIMS, gamma_minus=GAMMA_MINUS)\nn_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Parameters: {n_params} (much smaller than flat: {INPUT_DIM_PER_ROW}*{HIDDEN_DIMS[0]} vs 794*24)\")\n\nhistory = train_forward_forward_temporal(\n    model, X_train, y_train, X_test, y_test,\n    n_epochs=N_EPOCHS, lr=LR, margin=MARGIN,\n    batch_size=BATCH_SIZE, verbose=True,\n    weight_decay=WEIGHT_DECAY, lr_decay=LR_DECAY,\n    goodness_mode=GOODNESS_MODE\n)\n\nprint(\"=\" * 80)\nprint(f\"Final train accuracy: {history['train_acc'][-1]:.4f}\")\nprint(f\"Final test accuracy: {history['test_acc'][-1]:.4f}\")\nprint(f\"Best test accuracy: {max(history['test_acc']):.4f}\")\nprint(f\"Random baseline: 10%\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Loss\nax1 = axes[0, 0]\nax1.plot(history['loss'], color='steelblue', lw=2)\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Contrastive Loss')\nax1.set_title('Training Loss')\nax1.grid(True, alpha=0.3)\n\n# Goodness\nax2 = axes[0, 1]\nax2.plot(history['goodness_pos'], label='Positive (G+)', color='green', lw=2)\nax2.plot(history['goodness_neg'], label='Negative (G-)', color='red', lw=2)\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Mean Goodness')\nax2.set_title('Goodness Values')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# Learning rate\nax3 = axes[0, 2]\nax3.plot(history['lr'], color='orange', lw=2)\nax3.set_xlabel('Epoch')\nax3.set_ylabel('Learning Rate')\nax3.set_title('Learning Rate Decay')\nax3.grid(True, alpha=0.3)\n\n# Accuracy\nax4 = axes[1, 0]\nax4.plot(history['train_acc'], label='Train', color='coral', lw=2)\nax4.plot(history['test_acc'], label='Test', color='steelblue', lw=2)\nax4.axhline(y=0.1, color='gray', linestyle='--', alpha=0.5, label='Random (10%)')\nbest_epoch = np.argmax(history['test_acc'])\nax4.axvline(x=best_epoch, color='green', linestyle=':', alpha=0.7, label=f'Best ({max(history[\"test_acc\"]):.2%})')\nax4.set_xlabel('Epoch')\nax4.set_ylabel('Accuracy')\nax4.set_title('Classification Accuracy')\nax4.legend()\nax4.grid(True, alpha=0.3)\nax4.set_ylim(0, 1.0)\n\n# Separation\nax5 = axes[1, 1]\nseparation = [p - n for p, n in zip(history['goodness_pos'], history['goodness_neg'])]\nax5.plot(separation, color='purple', lw=2)\nax5.axhline(y=0, color='black', linestyle='--', alpha=0.5)\nax5.set_xlabel('Epoch')\nax5.set_ylabel('G+ - G-')\nax5.set_title('Goodness Separation')\nax5.grid(True, alpha=0.3)\n\n# Train vs Test gap\nax6 = axes[1, 2]\ngap = [t - v for t, v in zip(history['train_acc'], history['test_acc'])]\nax6.plot(gap, color='brown', lw=2)\nax6.axhline(y=0, color='black', linestyle='--', alpha=0.5)\nax6.set_xlabel('Epoch')\nax6.set_ylabel('Train - Test')\nax6.set_title('Generalization Gap')\nax6.grid(True, alpha=0.3)\n\nplt.suptitle(f'Forward-Forward MNIST ({sum(HIDDEN_DIMS)} neurons, 10 classes)', fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "def get_predictions_temporal(model, X, batch_size=100, goodness_mode='all'):\n    \"\"\"Get predictions and goodness for temporal model.\"\"\"\n    model.eval()\n    N = X.shape[0]\n    all_predictions = []\n    all_goodness = []\n    \n    with torch.no_grad():\n        for start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n            X_batch = X[start:end]  # [B, 28, 28]\n            B = X_batch.shape[0]\n            \n            X_repeated = X_batch.unsqueeze(1).expand(-1, N_CLASSES, -1, -1).reshape(B * N_CLASSES, N_ROWS, N_COLS)\n            y_hypotheses = torch.arange(N_CLASSES).unsqueeze(0).expand(B, -1).reshape(B * N_CLASSES)\n            \n            X_embedded = embed_label_temporal(X_repeated, y_hypotheses)\n            _, layer_states = model(X_embedded)\n            \n            total_goodness = torch.zeros(B * N_CLASSES)\n            for layer_idx in range(1, len(model.layers)):\n                if goodness_mode == 'final':\n                    act = layer_states[layer_idx][:, -1, :]\n                    total_goodness += compute_goodness(act)\n                elif goodness_mode == 'all':\n                    for t in range(layer_states[layer_idx].shape[1]):\n                        act = layer_states[layer_idx][:, t, :]\n                        total_goodness += compute_goodness(act)\n            \n            goodness_matrix = total_goodness.reshape(B, N_CLASSES)\n            all_goodness.append(goodness_matrix)\n            all_predictions.append(goodness_matrix.argmax(dim=1))\n    \n    return torch.cat(all_predictions), torch.cat(all_goodness)\n\n\ndef compute_confusion_matrix(y_true, y_pred, n_classes=N_CLASSES):\n    \"\"\"Compute confusion matrix.\"\"\"\n    cm = np.zeros((n_classes, n_classes), dtype=np.int32)\n    for true, pred in zip(y_true, y_pred):\n        cm[true, pred] += 1\n    return cm\n\n\n# Get test predictions\ntest_preds, test_goodness = get_predictions_temporal(model, X_test, goodness_mode=GOODNESS_MODE)\n\n# Confusion matrix\ncm = compute_confusion_matrix(y_test.numpy(), test_preds.numpy())\n\nfig, ax = plt.subplots(figsize=(10, 8))\nim = ax.imshow(cm, cmap='Blues')\nax.set_xticks(range(N_CLASSES))\nax.set_yticks(range(N_CLASSES))\nax.set_xlabel('Predicted')\nax.set_ylabel('True')\nax.set_title(f'Confusion Matrix - Temporal Model (Test Acc: {history[\"test_acc\"][-1]:.2%})')\n\nfor i in range(N_CLASSES):\n    for j in range(N_CLASSES):\n        text = ax.text(j, i, cm[i, j], ha='center', va='center', fontsize=10,\n                       color='white' if cm[i, j] > cm.max()/2 else 'black')\n\nplt.colorbar(im)\nplt.tight_layout()\nplt.show()\n\n# Per-class accuracy\nprint(\"\\nPer-class accuracy:\")\nfor digit in range(N_CLASSES):\n    mask = y_test == digit\n    if mask.sum() > 0:\n        digit_acc = (test_preds[mask] == digit).float().mean().item()\n        print(f\"  Digit {digit}: {digit_acc:.2%}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# Show some predictions with temporal scanning visualization\nn_show = 20\nfig, axes = plt.subplots(4, 5, figsize=(15, 12))\n\nfor i, ax in enumerate(axes.flat):\n    if i >= n_show:\n        break\n    \n    img = X_test[i].numpy()  # [28, 28]\n    true_label = y_test[i].item()\n    pred_label = test_preds[i].item()\n    \n    ax.imshow(img, cmap='gray')\n    color = 'green' if pred_label == true_label else 'red'\n    ax.set_title(f'True: {true_label}, Pred: {pred_label}', color=color)\n    ax.axis('off')\n\nplt.suptitle('Temporal Forward-Forward Predictions (28 timesteps per image)', fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# Show goodness distribution and temporal dynamics\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\n\nfor i, ax in enumerate(axes.flat):\n    goodness_vals = test_goodness[i].numpy()\n    true_label = y_test[i].item()\n    pred_label = test_preds[i].item()\n    \n    colors = ['green' if d == true_label else 'lightgray' for d in range(N_CLASSES)]\n    colors[pred_label] = 'red' if pred_label != true_label else 'green'\n    \n    ax.bar(range(N_CLASSES), goodness_vals, color=colors)\n    ax.set_xticks(range(N_CLASSES))\n    ax.set_xlabel('Digit')\n    ax.set_ylabel('Goodness')\n    status = '✓' if pred_label == true_label else '✗'\n    ax.set_title(f'True: {true_label}, Pred: {pred_label} {status}')\n\nplt.suptitle('Goodness Distribution (accumulated over 28 timesteps)', fontsize=14)\nplt.tight_layout()\nplt.show()\n\n# Visualize temporal activation dynamics for one sample\nprint(\"\\nVisualizing temporal dynamics for sample 0...\")\nsample_idx = 0\nsample_img = X_test[sample_idx:sample_idx+1]  # [1, 28, 28]\ntrue_label = y_test[sample_idx].item()\n\n# Get activations over time for correct label\nX_embedded = embed_label_temporal(sample_img, torch.tensor([true_label]))\nmodel.eval()\nwith torch.no_grad():\n    _, layer_states = model(X_embedded)\n    hidden_states = layer_states[1]  # [1, 28, 24] - hidden layer over time\n\n# Plot activation evolution\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\n\n# Left: image with scan line indication\nax1 = axes[0]\nax1.imshow(sample_img[0].numpy(), cmap='gray')\nax1.set_title(f'Sample (label={true_label})')\nax1.set_xlabel('Column (pixels per timestep)')\nax1.set_ylabel('Row (timestep)')\n\n# Right: hidden neuron activations over time\nax2 = axes[1]\nactivations = hidden_states[0].numpy()  # [28, 24]\nim = ax2.imshow(activations.T, aspect='auto', cmap='viridis')\nax2.set_xlabel('Timestep (row)')\nax2.set_ylabel('Neuron')\nax2.set_title('Hidden Layer Activation Over Time')\nplt.colorbar(im, ax=ax2, label='Activation')\n\nplt.suptitle('Temporal Dynamics: Network \"Scans\" Image Row by Row', fontsize=12)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 9. Compare with Different Hidden Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# Compare different temporal architectures (all <26 neurons)\nhidden_configs = [\n    [8],       # 8 neurons\n    [12],      # 12 neurons  \n    [16],      # 16 neurons\n    [20],      # 20 neurons\n    [24],      # 24 neurons\n    [12, 12],  # Two-layer: 24 total\n]\n\ncomparison_results = []\n\nprint(\"Comparing TEMPORAL architectures (all <26 neurons)...\")\nprint(f\"Input: {INPUT_DIM_PER_ROW} features × {N_ROWS} timesteps\")\nprint(f\"gamma_minus = {GAMMA_MINUS} (pure accumulator)\")\nprint(f\"goodness_mode = '{GOODNESS_MODE}'\")\nprint(\"=\" * 80)\n\nfor hidden_dims in hidden_configs:\n    torch.manual_seed(42)\n    model = build_ff_temporal_model(hidden_dims, gamma_minus=GAMMA_MINUS)\n    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_neurons = sum(hidden_dims)\n    \n    history = train_forward_forward_temporal(\n        model, X_train, y_train, X_test, y_test,\n        n_epochs=50, lr=0.01, margin=0.01,\n        batch_size=64, verbose=False,\n        weight_decay=1e-4, lr_decay=0.98,\n        goodness_mode=GOODNESS_MODE\n    )\n    \n    best_test = max(history['test_acc'])\n    comparison_results.append({\n        'hidden_dims': str(hidden_dims),\n        'total_neurons': total_neurons,\n        'n_params': n_params,\n        'train_acc': history['train_acc'][-1],\n        'test_acc': history['test_acc'][-1],\n        'best_test': best_test,\n    })\n    \n    print(f\"Hidden={str(hidden_dims):12s} | Neurons={total_neurons:2d} | Params={n_params:5d} | \"\n          f\"Final: {history['test_acc'][-1]:.4f} | Best: {best_test:.4f}\")\n\nprint(\"=\" * 80)\n\n# Find best architecture\nbest_result = max(comparison_results, key=lambda x: x['best_test'])\nprint(f\"\\nBest temporal architecture: {best_result['hidden_dims']} with {best_result['best_test']:.2%} test accuracy\")\nprint(f\"Note: Parameters much smaller due to {INPUT_DIM_PER_ROW} input vs 794 (flat)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 10. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"CONCLUSIONS: TEMPORAL FORWARD-FORWARD MNIST\")\nprint(\"=\" * 70)\n\nprint(f\"\\n1. ARCHITECTURE (Temporal Row Scanning):\")\nprint(f\"   Input per timestep: {N_COLS} pixels + {N_CLASSES} label = {INPUT_DIM_PER_ROW}\")\nprint(f\"   Timesteps: {N_ROWS} (one per image row)\")\nprint(f\"   Hidden: {sum(HIDDEN_DIMS)} SingleDendrite neurons\")\nprint(f\"   Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n\nprint(f\"\\n2. CRITICAL PARAMETERS:\")\nprint(f\"   gamma_minus = {GAMMA_MINUS} (pure accumulator)\")\nprint(f\"   goodness_mode = '{GOODNESS_MODE}' (all timesteps)\")\nprint(f\"\")\nprint(f\"   WHY THESE MATTER:\")\nprint(f\"   - gamma_minus=0.05 causes 77% info loss (0.95^28 = {0.95**28:.1%})\")\nprint(f\"   - gamma_minus=1e-6 gives ~100% retention\")\nprint(f\"   - goodness_mode='all' provides gradient to ALL rows\")\nprint(f\"   - goodness_mode='final' only trains last few rows\")\n\nprint(f\"\\n3. PARAMETER EFFICIENCY:\")\nprint(f\"   Flat input:     794 dims × 1 timestep  = 794 input features\")\nprint(f\"   Temporal input: 38 dims × 28 timesteps = 1064 total features\")\nprint(f\"   But parameters: {INPUT_DIM_PER_ROW}×{sum(HIDDEN_DIMS)} = {INPUT_DIM_PER_ROW*sum(HIDDEN_DIMS)} vs 794×24 = 19056\")\nprint(f\"   → {19056 // (INPUT_DIM_PER_ROW*sum(HIDDEN_DIMS))}× fewer parameters!\")\n\nprint(f\"\\n4. PERFORMANCE:\")\nprint(f\"   Train accuracy: {history['train_acc'][-1]:.2%}\")\nprint(f\"   Test accuracy:  {history['test_acc'][-1]:.2%}\")\nprint(f\"   Best test:      {max(history['test_acc']):.2%}\")\nprint(f\"   Random baseline: 10%\")\n\nprint(f\"\\n5. HARDWARE ADVANTAGES:\")\nprint(f\"   ✓ Smaller input fanout ({INPUT_DIM_PER_ROW} vs 794)\")\nprint(f\"   ✓ Temporal dynamics meaningful (scanning)\")\nprint(f\"   ✓ Sequential processing = natural for hardware\")\nprint(f\"   ✓ Memory through state accumulation\")\nprint(f\"   ✓ Only {sum(HIDDEN_DIMS)} physical neurons needed!\")\n\nprint(f\"\\n6. INFERENCE PIPELINE:\")\nprint(f\"   For each digit hypothesis (10 total):\")\nprint(f\"     - Present image row-by-row (28 timesteps)\")\nprint(f\"     - Each timestep: 28 pixels + 10-dim label = 38 inputs\")\nprint(f\"     - Measure goodness (power) at each timestep, sum all\")\nprint(f\"   Total: 10 × 28 = 280 timesteps per classification\")\n\nprint(\"\\n\" + \"=\" * 70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}