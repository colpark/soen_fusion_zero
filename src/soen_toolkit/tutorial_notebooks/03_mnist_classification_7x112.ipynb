{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 03b â€” MNIST Classification with SOEN (7Ã—112 Format)\n",
        "\n",
        "This notebook demonstrates training a SOEN (Superconducting Optoelectronic Network) model on the MNIST digit classification task using a **7Ã—112 input format** designed for neurons with **8 maximum dendrites**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”Š NOISE CONFIGURATION: ENABLED (Default)\n",
        "\n",
        "> **This tutorial runs with NOISE INJECTION by default (documented values).**\n",
        ">\n",
        "> | Parameter | Default | Description |\n",
        "> |-----------|---------|-------------|\n",
        "> | `phi` | **0.01** | Noise on input flux |\n",
        "> | `s` | **0.005** | Noise on state |\n",
        "> | `relative` | **false** | Absolute scaling |\n",
        ">\n",
        "> **To toggle noise on/off**, use the `NOISE_ENABLED` setting in the Configuration cell below.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Differences from Standard Tutorial 03\n",
        "\n",
        "| Aspect | Standard (28Ã—28) | This Version (7Ã—112) |\n",
        "|--------|------------------|----------------------|\n",
        "| **Input Shape** | 28 timesteps Ã— 28 features | 7 timesteps Ã— 112 features |\n",
        "| **Row Grouping** | 1 row per timestep | 4 rows per timestep |\n",
        "| **Dendrite Compatibility** | N/A | 112 / 8 = 14 inputs per dendrite |\n",
        "| **Temporal Steps** | 28 | 7 |\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "Input (112D) â†’ SingleDendrite (128D) â†’ Output (10D)\n",
        "     â†“               â†“ â†º                    â†“\n",
        "  4 rowsÃ—28px    Recurrent SOEN       10 digit classes\n",
        "  (7 timesteps)  (8 dendrite ready)\n",
        "```\n",
        "\n",
        "## Why 7Ã—112?\n",
        "\n",
        "- **8 Dendrite Compatibility**: 112 features / 8 dendrites = 14 inputs per dendrite\n",
        "- **Shorter Sequences**: 7 timesteps vs 28 timesteps (4Ã— faster processing)\n",
        "- **Spatial Context**: Each timestep sees 4 rows at once (more spatial context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Disable tqdm notebook widgets BEFORE any imports\n",
        "import os\n",
        "os.environ[\"TQDM_DISABLE\"] = \"0\"  # Don't disable, but force text mode\n",
        "os.environ[\"TQDM_MININTERVAL\"] = \"1\"\n",
        "\n",
        "# Setup: Ensure soen_toolkit is importable\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path if running from notebook location\n",
        "notebook_dir = Path.cwd()\n",
        "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
        "    candidate = parent / \"src\"\n",
        "    if (candidate / \"soen_toolkit\").exists():\n",
        "        sys.path.insert(0, str(candidate))\n",
        "        break\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "import gzip\n",
        "import urllib.request\n",
        "import struct\n",
        "\n",
        "# Use standard tqdm (not notebook version to avoid widget errors)\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    # Simple fallback if tqdm not available\n",
        "    def tqdm(iterable, **kwargs):\n",
        "        return iterable\n",
        "\n",
        "# Set torch precision for H100 tensor cores\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# NOISE CONFIGURATION TOGGLE\n",
        "# ============================================================================\n",
        "# Set NOISE_ENABLED to control noise injection:\n",
        "#   True  = Noise enabled (default) - adds stochastic noise per timestep\n",
        "#   False = Ideal conditions - no noise, deterministic behavior\n",
        "# ============================================================================\n",
        "\n",
        "NOISE_ENABLED = True  # Toggle this to enable/disable noise\n",
        "\n",
        "# Default noise values from documentation (used when NOISE_ENABLED = True)\n",
        "NOISE_DEFAULTS = {\n",
        "    \"phi\": 0.01,           # Noise on input flux\n",
        "    \"s\": 0.005,            # Noise on state\n",
        "    \"g\": 0.0,              # Source function noise\n",
        "    \"bias_current\": 0.0,   # Bias current noise\n",
        "    \"j\": 0.0,              # Connection weight noise\n",
        "    \"relative\": False,     # Absolute scaling\n",
        "}\n",
        "\n",
        "def set_model_noise(model, enabled=True, noise_values=None):\n",
        "    \"\"\"\n",
        "    Toggle noise injection on/off for a SOEN model.\n",
        "    \n",
        "    Args:\n",
        "        model: SOENModelCore instance\n",
        "        enabled: True to enable noise, False to disable\n",
        "        noise_values: Optional dict of noise values (uses NOISE_DEFAULTS if None)\n",
        "    \n",
        "    Returns:\n",
        "        model: The modified model (in-place modification)\n",
        "    \"\"\"\n",
        "    from soen_toolkit.core.configs import NoiseConfig\n",
        "    \n",
        "    if noise_values is None:\n",
        "        noise_values = NOISE_DEFAULTS\n",
        "    \n",
        "    for cfg in model.layers_config:\n",
        "        if enabled:\n",
        "            # Apply noise values\n",
        "            cfg.noise = NoiseConfig(\n",
        "                phi=noise_values.get(\"phi\", 0.01),\n",
        "                s=noise_values.get(\"s\", 0.005),\n",
        "                g=noise_values.get(\"g\", 0.0),\n",
        "                bias_current=noise_values.get(\"bias_current\", 0.0),\n",
        "                j=noise_values.get(\"j\", 0.0),\n",
        "                relative=noise_values.get(\"relative\", False),\n",
        "                extras=getattr(cfg.noise, \"extras\", {}),\n",
        "            )\n",
        "        else:\n",
        "            # Disable noise (all zeros)\n",
        "            cfg.noise = NoiseConfig(\n",
        "                phi=0.0, s=0.0, g=0.0, bias_current=0.0, j=0.0,\n",
        "                relative=False,\n",
        "                extras=getattr(cfg.noise, \"extras\", {}),\n",
        "            )\n",
        "    \n",
        "    # Also update connection noise\n",
        "    for conn_cfg in model.connections_config:\n",
        "        if enabled:\n",
        "            conn_cfg.noise = NoiseConfig(\n",
        "                phi=0.0, g=0.0, s=0.0, bias_current=0.0,\n",
        "                j=noise_values.get(\"j\", 0.0),\n",
        "                relative=noise_values.get(\"relative\", False),\n",
        "                extras={},\n",
        "            )\n",
        "        else:\n",
        "            conn_cfg.noise = NoiseConfig(\n",
        "                phi=0.0, g=0.0, s=0.0, bias_current=0.0, j=0.0,\n",
        "                relative=False, extras={},\n",
        "            )\n",
        "    \n",
        "    status = \"ENABLED\" if enabled else \"DISABLED\"\n",
        "    print(f\"âœ“ Noise injection {status}\")\n",
        "    if enabled:\n",
        "        print(f\"  phi={noise_values['phi']}, s={noise_values['s']}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "print(f\"Noise configuration: {'ENABLED' if NOISE_ENABLED else 'DISABLED'}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prepare MNIST Dataset (7Ã—112 Format)\n",
        "\n",
        "We'll download MNIST and convert it to HDF5 format with the **7Ã—112 reshaping**:\n",
        "\n",
        "**Data format**: Images are reshaped from (28, 28) to (7, 112) where:\n",
        "- Time dimension = 7 (groups of 4 rows)\n",
        "- Feature dimension = 112 (4 rows Ã— 28 pixels per row)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
        "    \"\"\"Download a single MNIST file if not already present.\"\"\"\n",
        "    data_dir = Path(\"./data/mnist\")\n",
        "    data_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    filepath = data_dir / filename\n",
        "    if not filepath.exists():\n",
        "        url = base_url + filename\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        urllib.request.urlretrieve(url, filepath)\n",
        "    return filepath\n",
        "\n",
        "def read_mnist_images(filepath):\n",
        "    \"\"\"Read MNIST image file (idx3-ubyte format).\"\"\"\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        # Read magic number and dimensions\n",
        "        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
        "        # Read image data\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        images = images.reshape(num_images, rows, cols)\n",
        "    return images\n",
        "\n",
        "def read_mnist_labels(filepath):\n",
        "    \"\"\"Read MNIST label file (idx1-ubyte format).\"\"\"\n",
        "    with gzip.open(filepath, 'rb') as f:\n",
        "        # Read magic number and count\n",
        "        magic, num_labels = struct.unpack('>II', f.read(8))\n",
        "        # Read labels\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "    return labels\n",
        "\n",
        "def reshape_to_7x112(images):\n",
        "    \"\"\"\n",
        "    Reshape MNIST images from (N, 28, 28) to (N, 7, 112).\n",
        "    \n",
        "    Groups 4 consecutive rows into each timestep:\n",
        "    - Timestep 0: rows 0-3 (4 Ã— 28 = 112 features)\n",
        "    - Timestep 1: rows 4-7 (4 Ã— 28 = 112 features)\n",
        "    - ...\n",
        "    - Timestep 6: rows 24-27 (4 Ã— 28 = 112 features)\n",
        "    \n",
        "    This format is designed for 8 dendrites: 112 / 8 = 14 inputs per dendrite\n",
        "    \"\"\"\n",
        "    n_samples = images.shape[0]\n",
        "    # Reshape: (N, 28, 28) -> (N, 7, 4, 28) -> (N, 7, 112)\n",
        "    reshaped = images.reshape(n_samples, 7, 4, 28)\n",
        "    reshaped = reshaped.reshape(n_samples, 7, 112)\n",
        "    return reshaped\n",
        "\n",
        "def prepare_mnist_hdf5_7x112(output_path=\"training/datasets/mnist_seq7x112.hdf5\", \n",
        "                             normalize=True,\n",
        "                             val_split=0.1):\n",
        "    \"\"\"\n",
        "    Download MNIST and save as HDF5 for SOEN training with 7Ã—112 format.\n",
        "    \n",
        "    Args:\n",
        "        output_path: Where to save the HDF5 file\n",
        "        normalize: Whether to normalize pixel values to [0, 1]\n",
        "        val_split: Fraction of training data to use for validation\n",
        "    \"\"\"\n",
        "    output_path = Path(output_path)\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Check if already exists\n",
        "    if output_path.exists():\n",
        "        print(f\"Dataset already exists at {output_path}\")\n",
        "        with h5py.File(output_path, 'r') as f:\n",
        "            print(f\"  Train samples: {len(f['train']['labels'])}\")\n",
        "            print(f\"  Val samples: {len(f['val']['labels'])}\")\n",
        "            print(f\"  Test samples: {len(f['test']['labels'])}\")\n",
        "            print(f\"  Data shape: {f['train']['data'].shape}\")\n",
        "        return output_path\n",
        "    \n",
        "    print(\"Downloading MNIST (without torchvision)...\")\n",
        "    \n",
        "    # Download MNIST files\n",
        "    train_images_file = download_mnist_file(\"train-images-idx3-ubyte.gz\")\n",
        "    train_labels_file = download_mnist_file(\"train-labels-idx1-ubyte.gz\")\n",
        "    test_images_file = download_mnist_file(\"t10k-images-idx3-ubyte.gz\")\n",
        "    test_labels_file = download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")\n",
        "    \n",
        "    # Read the data\n",
        "    train_images = read_mnist_images(train_images_file).astype(np.float32)\n",
        "    train_labels = read_mnist_labels(train_labels_file).astype(np.int64)\n",
        "    test_images = read_mnist_images(test_images_file).astype(np.float32)\n",
        "    test_labels = read_mnist_labels(test_labels_file).astype(np.int64)\n",
        "    \n",
        "    # Normalize to [0, 1]\n",
        "    if normalize:\n",
        "        train_images = train_images / 255.0\n",
        "        test_images = test_images / 255.0\n",
        "    \n",
        "    # Reshape to 7Ã—112 format\n",
        "    print(\"\\nReshaping images from (28, 28) to (7, 112)...\")\n",
        "    print(\"  - 7 timesteps (groups of 4 rows)\")\n",
        "    print(\"  - 112 features per timestep (4 rows Ã— 28 pixels)\")\n",
        "    print(\"  - 8 dendrite compatible: 112 / 8 = 14 inputs per dendrite\")\n",
        "    \n",
        "    train_images = reshape_to_7x112(train_images)\n",
        "    test_images = reshape_to_7x112(test_images)\n",
        "    \n",
        "    # Split training into train/val\n",
        "    n_train = len(train_images)\n",
        "    n_val = int(n_train * val_split)\n",
        "    \n",
        "    # Shuffle before splitting\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.permutation(n_train)\n",
        "    val_indices = indices[:n_val]\n",
        "    train_indices = indices[n_val:]\n",
        "    \n",
        "    val_images = train_images[val_indices]\n",
        "    val_labels = train_labels[val_indices]\n",
        "    train_images = train_images[train_indices]\n",
        "    train_labels = train_labels[train_indices]\n",
        "    \n",
        "    print(f\"\\nFinal shapes:\")\n",
        "    print(f\"  Train: {train_images.shape} (N, T=7 timesteps, D=112 features)\")\n",
        "    print(f\"  Val: {val_images.shape}\")\n",
        "    print(f\"  Test: {test_images.shape}\")\n",
        "    \n",
        "    # Save to HDF5 (no compression for speed - file is only ~170MB)\n",
        "    print(f\"\\nSaving to {output_path}...\")\n",
        "    with h5py.File(output_path, 'w') as f:\n",
        "        # Training set\n",
        "        train_grp = f.create_group('train')\n",
        "        train_grp.create_dataset('data', data=train_images)\n",
        "        train_grp.create_dataset('labels', data=train_labels)\n",
        "        \n",
        "        # Validation set\n",
        "        val_grp = f.create_group('val')\n",
        "        val_grp.create_dataset('data', data=val_images)\n",
        "        val_grp.create_dataset('labels', data=val_labels)\n",
        "        \n",
        "        # Test set\n",
        "        test_grp = f.create_group('test')\n",
        "        test_grp.create_dataset('data', data=test_images)\n",
        "        test_grp.create_dataset('labels', data=test_labels)\n",
        "        \n",
        "        # Metadata\n",
        "        f.attrs['description'] = 'MNIST as sequences (7 timesteps x 112 features) for 8 dendrite neurons'\n",
        "        f.attrs['num_classes'] = 10\n",
        "        f.attrs['seq_len'] = 7\n",
        "        f.attrs['feature_dim'] = 112\n",
        "        f.attrs['rows_per_timestep'] = 4\n",
        "        f.attrs['dendrite_inputs'] = 14  # 112 / 8 dendrites\n",
        "    \n",
        "    print(\"Done!\")\n",
        "    print(f\"  Train: {len(train_labels)} samples\")\n",
        "    print(f\"  Val: {len(val_labels)} samples\")\n",
        "    print(f\"  Test: {len(test_labels)} samples\")\n",
        "    \n",
        "    return output_path\n",
        "\n",
        "# Prepare the dataset\n",
        "data_path = prepare_mnist_hdf5_7x112()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Visualize the 7Ã—112 Dataset\n",
        "\n",
        "Let's see how MNIST looks when reshaped to 7 timesteps Ã— 112 features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_mnist_7x112_samples(data_path, n_samples=5):\n",
        "    \"\"\"\n",
        "    Visualize MNIST samples in both original 28Ã—28 and reshaped 7Ã—112 formats.\n",
        "    \"\"\"\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "        images_7x112 = np.array(f['train']['data'][:n_samples])\n",
        "        labels = np.array(f['train']['labels'][:n_samples])\n",
        "    \n",
        "    # Reconstruct 28Ã—28 from 7Ã—112 for comparison\n",
        "    images_28x28 = images_7x112.reshape(n_samples, 7, 4, 28).reshape(n_samples, 28, 28)\n",
        "    \n",
        "    fig, axes = plt.subplots(3, n_samples, figsize=(3*n_samples, 9))\n",
        "    fig.suptitle('MNIST: Original vs 7Ã—112 Reshaping', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        # Top row: Original 28Ã—28 image\n",
        "        axes[0, i].imshow(images_28x28[i], cmap='gray')\n",
        "        axes[0, i].set_title(f'Label: {labels[i]}', fontsize=10)\n",
        "        axes[0, i].axis('off')\n",
        "        \n",
        "        # Middle row: 7Ã—112 sequential view (heatmap)\n",
        "        im = axes[1, i].imshow(images_7x112[i], cmap='viridis', aspect='auto')\n",
        "        axes[1, i].set_xlabel('Feature (0-111)', fontsize=8)\n",
        "        if i == 0:\n",
        "            axes[1, i].set_ylabel('Timestep (0-6)', fontsize=8)\n",
        "        axes[1, i].set_yticks(range(7))\n",
        "        \n",
        "        # Bottom row: Show 7Ã—112 as 7 groups of 4 rows\n",
        "        img_grouped = images_7x112[i].reshape(7, 4, 28)\n",
        "        # Stack horizontally to show all 7 timesteps\n",
        "        stacked = np.hstack([img_grouped[t] for t in range(7)])\n",
        "        axes[2, i].imshow(stacked, cmap='gray', aspect='auto')\n",
        "        axes[2, i].set_xlabel('Timestep blocks (0-6)', fontsize=8)\n",
        "        if i == 0:\n",
        "            axes[2, i].set_ylabel('4 rows per block', fontsize=8)\n",
        "        # Add vertical lines to separate timesteps\n",
        "        for t in range(1, 7):\n",
        "            axes[2, i].axvline(x=t*28-0.5, color='red', linewidth=0.5, alpha=0.5)\n",
        "    \n",
        "    axes[0, 0].set_ylabel('Original\\n28Ã—28', fontsize=10)\n",
        "    axes[1, 0].set_ylabel('7Ã—112\\nSequence', fontsize=10)\n",
        "    axes[2, 0].set_ylabel('4 rows per\\ntimestep', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"7Ã—112 Format Summary\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"â€¢ Original shape: 28Ã—28 = 784 pixels\")\n",
        "    print(f\"â€¢ Reshaped: 7 timesteps Ã— 112 features = 784 pixels\")\n",
        "    print(f\"â€¢ Each timestep: 4 rows Ã— 28 pixels = 112 features\")\n",
        "    print(f\"â€¢ 8 dendrite compatibility: 112 / 8 = 14 inputs per dendrite\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "visualize_mnist_7x112_samples(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_dendrite_mapping(n_dendrites=8, features_per_timestep=112):\n",
        "    \"\"\"\n",
        "    Visualize how the 112 input features map to 8 dendrites.\n",
        "    \"\"\"\n",
        "    inputs_per_dendrite = features_per_timestep // n_dendrites\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(14, 4))\n",
        "    \n",
        "    # Create a color map for dendrites\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, n_dendrites))\n",
        "    \n",
        "    # Draw the feature mapping\n",
        "    for d in range(n_dendrites):\n",
        "        start = d * inputs_per_dendrite\n",
        "        end = start + inputs_per_dendrite\n",
        "        ax.barh(0, inputs_per_dendrite, left=start, height=0.8, \n",
        "                color=colors[d], edgecolor='black', linewidth=1)\n",
        "        ax.text(start + inputs_per_dendrite/2, 0, f'D{d}\\n({start}-{end-1})',\n",
        "                ha='center', va='center', fontsize=9, fontweight='bold')\n",
        "    \n",
        "    ax.set_xlim(0, 112)\n",
        "    ax.set_ylim(-0.5, 0.5)\n",
        "    ax.set_xlabel('Feature Index (0-111)', fontsize=12)\n",
        "    ax.set_title(f'8 Dendrite Mapping: 112 features â†’ 14 inputs per dendrite', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.set_yticks([])\n",
        "    \n",
        "    # Add pixel mapping annotation\n",
        "    ax.text(56, -0.35, 'Each timestep: 4 rows Ã— 28 pixels = 112 features', \n",
        "            ha='center', fontsize=10, style='italic')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Show detailed mapping\n",
        "    print(\"\\nDendrite â†’ Pixel Mapping:\")\n",
        "    print(\"-\" * 50)\n",
        "    for d in range(n_dendrites):\n",
        "        start = d * inputs_per_dendrite\n",
        "        end = start + inputs_per_dendrite\n",
        "        row_start = start // 28\n",
        "        col_start = start % 28\n",
        "        row_end = (end - 1) // 28\n",
        "        col_end = (end - 1) % 28\n",
        "        print(f\"  Dendrite {d}: features [{start:3d}-{end-1:3d}] â†’ \"\n",
        "              f\"row {row_start}, col {col_start:2d} to row {row_end}, col {col_end:2d}\")\n",
        "\n",
        "visualize_dendrite_mapping()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Examine the Model Architecture\n",
        "\n",
        "Let's look at the SOEN model configured for 7Ã—112 input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from soen_toolkit.core.model_yaml import build_model_from_yaml\n",
        "\n",
        "# Load and inspect the model\n",
        "model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec_7x112.yaml\")\n",
        "model = build_model_from_yaml(model_path)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"MNIST SOEN MODEL ARCHITECTURE (7Ã—112 Format)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "print(\"\\nLayer dimensions:\")\n",
        "for layer_id, dim in model.layer_nodes.items():\n",
        "    if layer_id == 0:\n",
        "        print(f\"  Layer {layer_id}: {dim} neurons (112 = 4 rows Ã— 28 pixels)\")\n",
        "    else:\n",
        "        print(f\"  Layer {layer_id}: {dim} neurons\")\n",
        "\n",
        "print(\"\\nConnections:\")\n",
        "for name, param in model.connections.items():\n",
        "    print(f\"  {name}: {param.shape} (learnable: {param.requires_grad})\")\n",
        "\n",
        "# Test forward pass\n",
        "print(\"\\nTesting forward pass...\")\n",
        "x_test = torch.randn(2, 7, 112)  # [batch=2, seq_len=7, features=112]\n",
        "with torch.no_grad():\n",
        "    output, states = model(x_test)\n",
        "print(f\"  Input shape: {x_test.shape} (batch, 7 timesteps, 112 features)\")\n",
        "print(f\"  Output shape: {output.shape}\")\n",
        "print(\"  Forward pass successful!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"8 DENDRITE COMPATIBILITY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Input features: 112\")\n",
        "print(f\"  Number of dendrites: 8\")\n",
        "print(f\"  Inputs per dendrite: 112 / 8 = 14\")\n",
        "print(\"=\" * 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train the Model\n",
        "\n",
        "Now let's train the SOEN model on MNIST using the 7Ã—112 training configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Disable progress bar to avoid widget errors in notebooks\n",
        "import os\n",
        "os.environ[\"SOEN_NO_PROGRESS_BAR\"] = \"1\"\n",
        "\n",
        "from soen_toolkit.training.trainers.experiment import run_from_config\n",
        "\n",
        "# Run training\n",
        "print(\"Starting MNIST SOEN training (7Ã—112 format)...\")\n",
        "print(\"This may take a while depending on your hardware.\")\n",
        "print(\"=\"*60)\n",
        "print(\"Input format: 7 timesteps Ã— 112 features\")\n",
        "print(\"8 dendrite compatible: 112 / 8 = 14 inputs per dendrite\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "run_from_config(\"training/training_configs/mnist_soen_7x112.yaml\", script_dir=Path.cwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate the Trained Model\n",
        "\n",
        "Let's load the best checkpoint and evaluate on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def load_best_checkpoint_7x112():\n",
        "    \"\"\"Find and load the best checkpoint from training.\"\"\"\n",
        "    \n",
        "    # Find checkpoints\n",
        "    ckpt_patterns = [\n",
        "        \"training/temp/**/checkpoints/**/*.ckpt\",\n",
        "        \"training/temp/**/*.ckpt\",\n",
        "    ]\n",
        "    \n",
        "    all_ckpts = []\n",
        "    for pattern in ckpt_patterns:\n",
        "        all_ckpts.extend(glob.glob(pattern, recursive=True))\n",
        "    \n",
        "    # Filter for 7x112 checkpoints\n",
        "    ckpts_7x112 = [c for c in all_ckpts if '7x112' in c or 'MNIST_SOEN_7x112' in c]\n",
        "    \n",
        "    if not ckpts_7x112:\n",
        "        # Fall back to all checkpoints if no specific 7x112 found\n",
        "        ckpts_7x112 = all_ckpts\n",
        "    \n",
        "    if not ckpts_7x112:\n",
        "        print(\"No checkpoint found. Run training first.\")\n",
        "        return None, None\n",
        "    \n",
        "    # Get the most recent checkpoint\n",
        "    latest_ckpt = max(ckpts_7x112, key=lambda x: Path(x).stat().st_mtime)\n",
        "    print(f\"Loading checkpoint: {latest_ckpt}\")\n",
        "    \n",
        "    # Load model\n",
        "    model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec_7x112.yaml\")\n",
        "    model = build_model_from_yaml(model_path)\n",
        "    \n",
        "    # Load weights\n",
        "    ckpt = torch.load(latest_ckpt, map_location='cpu')\n",
        "    state_dict = ckpt.get('state_dict', ckpt)\n",
        "    \n",
        "    # Remove 'model.' prefix if present\n",
        "    clean_state_dict = {}\n",
        "    for k, v in state_dict.items():\n",
        "        if k.startswith('model.'):\n",
        "            clean_state_dict[k[6:]] = v\n",
        "        else:\n",
        "            clean_state_dict[k] = v\n",
        "    \n",
        "    model.load_state_dict(clean_state_dict, strict=False)\n",
        "    model.eval()\n",
        "    \n",
        "    return model, latest_ckpt\n",
        "\n",
        "trained_model, ckpt_path = load_best_checkpoint_7x112()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_on_test_set(model, data_path, batch_size=128):\n",
        "    \"\"\"Evaluate model on the test set.\"\"\"\n",
        "    \n",
        "    if model is None:\n",
        "        print(\"No model loaded.\")\n",
        "        return\n",
        "    \n",
        "    # Load test data\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "        test_data = np.array(f['test']['data'])\n",
        "        test_labels = np.array(f['test']['labels'])\n",
        "    \n",
        "    print(f\"Evaluating on {len(test_labels)} test samples...\")\n",
        "    print(f\"Input shape: {test_data.shape} (N, 7 timesteps, 112 features)\")\n",
        "    \n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    \n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(test_data), batch_size)):\n",
        "            batch_data = test_data[i:i+batch_size]\n",
        "            x = torch.tensor(batch_data, dtype=torch.float32).to(device)\n",
        "            \n",
        "            output, _ = model(x)\n",
        "            \n",
        "            # Apply max pooling over time\n",
        "            if output.dim() == 3:\n",
        "                pooled = output.max(dim=1)[0]\n",
        "            else:\n",
        "                pooled = output\n",
        "            \n",
        "            probs = torch.softmax(pooled, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "            \n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "    \n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = (all_preds == test_labels).mean()\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"TEST SET RESULTS (7Ã—112 Format)\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Correct: {(all_preds == test_labels).sum()}/{len(test_labels)}\")\n",
        "    \n",
        "    return all_preds, all_probs, accuracy\n",
        "\n",
        "if trained_model is not None:\n",
        "    predictions, probabilities, test_accuracy = evaluate_on_test_set(trained_model, data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_predictions_7x112(model, data_path, n_samples=20):\n",
        "    \"\"\"Visualize model predictions on random test samples.\"\"\"\n",
        "    \n",
        "    if model is None:\n",
        "        print(\"No model loaded.\")\n",
        "        return\n",
        "    \n",
        "    # Load test data\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "        test_data = np.array(f['test']['data'])\n",
        "        test_labels = np.array(f['test']['labels'])\n",
        "    \n",
        "    # Random sample\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.choice(len(test_data), n_samples, replace=False)\n",
        "    \n",
        "    samples = test_data[indices]  # Shape: (n_samples, 7, 112)\n",
        "    labels = test_labels[indices]\n",
        "    \n",
        "    # Reconstruct 28Ã—28 for visualization\n",
        "    samples_28x28 = samples.reshape(n_samples, 7, 4, 28).reshape(n_samples, 28, 28)\n",
        "    \n",
        "    # Get predictions\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.tensor(samples, dtype=torch.float32)\n",
        "        output, _ = model(x)\n",
        "        \n",
        "        if output.dim() == 3:\n",
        "            pooled = output.max(dim=1)[0]\n",
        "        else:\n",
        "            pooled = output\n",
        "        \n",
        "        probs = torch.softmax(pooled, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).numpy()\n",
        "        confidence = probs.max(dim=1)[0].numpy()\n",
        "    \n",
        "    # Plot\n",
        "    n_cols = 5\n",
        "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(2.5*n_cols, 3*n_rows))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    fig.suptitle('MNIST Predictions (SOEN 7Ã—112 Model)', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    for i in range(n_samples):\n",
        "        ax = axes[i]\n",
        "        ax.imshow(samples_28x28[i], cmap='gray')\n",
        "        \n",
        "        is_correct = preds[i] == labels[i]\n",
        "        color = 'green' if is_correct else 'red'\n",
        "        symbol = 'âœ“' if is_correct else 'âœ—'\n",
        "        \n",
        "        ax.set_title(\n",
        "            f\"{symbol} Pred: {preds[i]} ({confidence[i]:.0%})\\nTrue: {labels[i]}\",\n",
        "            fontsize=9,\n",
        "            color=color,\n",
        "            fontweight='bold' if not is_correct else 'normal'\n",
        "        )\n",
        "        ax.axis('off')\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for i in range(n_samples, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Summary\n",
        "    accuracy = (preds == labels).mean()\n",
        "    print(f\"\\nSample accuracy: {accuracy:.1%} ({(preds == labels).sum()}/{n_samples})\")\n",
        "\n",
        "if trained_model is not None:\n",
        "    visualize_predictions_7x112(trained_model, data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_confusion_matrix(predictions, true_labels):\n",
        "    \"\"\"Plot confusion matrix for predictions.\"\"\"\n",
        "    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "    \n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=range(10), yticklabels=range(10))\n",
        "    ax.set_xlabel('Predicted', fontsize=12)\n",
        "    ax.set_ylabel('True', fontsize=12)\n",
        "    ax.set_title('Confusion Matrix (7Ã—112 Format)', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Per-class accuracy\n",
        "    print(\"\\nPer-class accuracy:\")\n",
        "    for digit in range(10):\n",
        "        mask = true_labels == digit\n",
        "        class_acc = (predictions[mask] == digit).mean()\n",
        "        print(f\"  Digit {digit}: {class_acc:.1%}\")\n",
        "\n",
        "if trained_model is not None:\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "        test_labels = np.array(f['test']['labels'])\n",
        "    plot_confusion_matrix(predictions, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Analyze SOEN Dynamics (7 Timesteps)\n",
        "\n",
        "Let's visualize how the SingleDendrite layer processes the input over the 7 timesteps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def visualize_soen_dynamics_7x112(model, data_path, sample_idx=0):\n",
        "    \"\"\"Visualize the temporal dynamics of the SOEN hidden layer with 7Ã—112 input.\"\"\"\n",
        "    \n",
        "    if model is None:\n",
        "        print(\"No model loaded.\")\n",
        "        return\n",
        "    \n",
        "    # Load a sample\n",
        "    with h5py.File(data_path, 'r') as f:\n",
        "        sample = np.array(f['test']['data'][sample_idx:sample_idx+1])  # (1, 7, 112)\n",
        "        label = np.array(f['test']['labels'][sample_idx])\n",
        "    \n",
        "    # Reconstruct 28Ã—28 for visualization\n",
        "    sample_28x28 = sample.reshape(1, 7, 4, 28).reshape(28, 28)\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        x = torch.tensor(sample, dtype=torch.float32)\n",
        "        output, all_states = model(x)\n",
        "        \n",
        "        # Get hidden layer states (Layer 1)\n",
        "        hidden_states = all_states[1]  # [batch, seq_len+1, hidden_dim]\n",
        "        hidden_states = hidden_states[0, 1:, :].numpy()  # Remove batch and initial state\n",
        "        \n",
        "        # Get output\n",
        "        if output.dim() == 3:\n",
        "            output_over_time = output[0].numpy()\n",
        "        else:\n",
        "            output_over_time = output[0].numpy()\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle(f'SOEN Dynamics for Digit {label} (7Ã—112 Input)', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # 1. Input image with timestep boundaries\n",
        "    ax = axes[0, 0]\n",
        "    ax.imshow(sample_28x28, cmap='gray')\n",
        "    # Draw horizontal lines to show 7 timestep boundaries\n",
        "    for t in range(1, 7):\n",
        "        ax.axhline(y=t*4-0.5, color='red', linewidth=1, alpha=0.7)\n",
        "    ax.set_title('Input Image (red lines = timestep boundaries)', fontsize=12)\n",
        "    ax.set_ylabel('Rows (4 per timestep)')\n",
        "    \n",
        "    # 2. Hidden layer activity over time (only 7 timesteps)\n",
        "    im = axes[0, 1].imshow(hidden_states.T, aspect='auto', cmap='viridis')\n",
        "    axes[0, 1].set_xlabel('Timestep (0-6)', fontsize=10)\n",
        "    axes[0, 1].set_ylabel('Hidden Neuron', fontsize=10)\n",
        "    axes[0, 1].set_title('Hidden Layer Activity (128 neurons Ã— 7 timesteps)', fontsize=12)\n",
        "    axes[0, 1].set_xticks(range(7))\n",
        "    plt.colorbar(im, ax=axes[0, 1], label='Activation')\n",
        "    \n",
        "    # 3. Mean hidden activity over time\n",
        "    mean_activity = hidden_states.mean(axis=1)\n",
        "    std_activity = hidden_states.std(axis=1)\n",
        "    time_steps = np.arange(len(mean_activity))\n",
        "    axes[1, 0].plot(time_steps, mean_activity, 'b-', linewidth=2, marker='o', label='Mean')\n",
        "    axes[1, 0].fill_between(time_steps, \n",
        "                            mean_activity - std_activity,\n",
        "                            mean_activity + std_activity,\n",
        "                            alpha=0.3, label='Â±1 std')\n",
        "    axes[1, 0].set_xlabel('Timestep', fontsize=10)\n",
        "    axes[1, 0].set_ylabel('Activation', fontsize=10)\n",
        "    axes[1, 0].set_title('Mean Hidden Layer Activity (7 timesteps)', fontsize=12)\n",
        "    axes[1, 0].set_xticks(range(7))\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Output class probabilities at final timestep\n",
        "    if output_over_time.ndim == 2:\n",
        "        final_output = output_over_time[-1]\n",
        "    else:\n",
        "        final_output = output_over_time\n",
        "    probs = np.exp(final_output) / np.exp(final_output).sum()  # Softmax\n",
        "    \n",
        "    bars = axes[1, 1].bar(range(10), probs, color='steelblue', edgecolor='black')\n",
        "    bars[label].set_color('green')  # Highlight true class\n",
        "    axes[1, 1].set_xlabel('Digit Class', fontsize=10)\n",
        "    axes[1, 1].set_ylabel('Probability', fontsize=10)\n",
        "    axes[1, 1].set_title(f'Output Probabilities (True: {label})', fontsize=12)\n",
        "    axes[1, 1].set_xticks(range(10))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if trained_model is not None:\n",
        "    # Visualize dynamics for a few samples\n",
        "    for idx in [0, 5, 10]:\n",
        "        visualize_soen_dynamics_7x112(trained_model, data_path, sample_idx=idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we:\n",
        "\n",
        "1. **Prepared MNIST** with 7Ã—112 reshaping:\n",
        "   - 7 timesteps (groups of 4 rows)\n",
        "   - 112 features per timestep (4 rows Ã— 28 pixels)\n",
        "   - Compatible with 8 dendrite neurons (112 / 8 = 14 inputs per dendrite)\n",
        "\n",
        "2. **Built a SOEN model** with:\n",
        "   - Input layer (112D)\n",
        "   - SingleDendrite hidden layer (128D) with recurrent connections\n",
        "   - Linear output layer (10D) with **learnable** connections\n",
        "\n",
        "3. **Trained and evaluated** the model on MNIST\n",
        "\n",
        "### Key Differences from Standard 28Ã—28 Format\n",
        "\n",
        "| Aspect | 28Ã—28 | 7Ã—112 |\n",
        "|--------|-------|-------|\n",
        "| Timesteps | 28 | 7 |\n",
        "| Features/timestep | 28 | 112 |\n",
        "| Rows per timestep | 1 | 4 |\n",
        "| Dendrite compatible | N/A | 8 dendrites (14 inputs each) |\n",
        "| Processing speed | Slower | 4Ã— faster |\n",
        "| Spatial context | Single row | 4 rows at once |\n",
        "\n",
        "### Benefits of 7Ã—112 Format\n",
        "\n",
        "- **8 Dendrite Compatibility**: Perfect fit for 8-dendrite neuron models\n",
        "- **Shorter Sequences**: 7 vs 28 timesteps means faster processing\n",
        "- **Richer Spatial Context**: Each timestep sees 4 rows at once\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Compare accuracy between 28Ã—28 and 7Ã—112 formats\n",
        "- Experiment with different dendrite configurations\n",
        "- Try other reshaping strategies (e.g., 4Ã—196 for 7 dendrites)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}