{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST with Parallel Input (One Row per Neuron)\n",
    "\n",
    "**Different approach**: Instead of sequential row-by-row input, each neuron receives a different row simultaneously.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Image (28×28)\n",
    "     ↓\n",
    "28 Hidden Neurons (each gets one row = 28 pixels)\n",
    "     ↓ ↺ recurrent\n",
    "10 Output Neurons\n",
    "```\n",
    "\n",
    "## Timeline\n",
    "\n",
    "```\n",
    "t=1  t=2  t=3  t=4  t=5  │  t=6  t=7  t=8  t=9  t=10\n",
    "─────────────────────────┼─────────────────────────────\n",
    "    INPUT PHASE          │       SETTLE PHASE\n",
    "  (same input ×5)        │      (no input)\n",
    "                         │         ↑\n",
    "                         │     Take output here\n",
    "```\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `n_input_steps` | 5 | Times to present the same input |\n",
    "| `n_settle_steps` | 5 | Times to run without input |\n",
    "| `output_step` | 6 | Which timestep to read output from |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KEY HYPERPARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "N_INPUT_STEPS = 5      # Present same input for this many timesteps\n",
    "N_SETTLE_STEPS = 5     # Run without input for this many timesteps\n",
    "OUTPUT_STEP = 6        # Which timestep to read output (1-indexed)\n",
    "                       # 6 = first timestep after input phase ends\n",
    "\n",
    "# Network dimensions\n",
    "HIDDEN_DIM = 28        # One neuron per row\n",
    "INPUT_DIM = 28         # Each neuron gets 28 pixels (one row)\n",
    "OUTPUT_DIM = 10        # 10 digit classes\n",
    "\n",
    "# SOEN dynamics\n",
    "DT = 0.1\n",
    "GAMMA_PLUS = 0.1       # Integration rate\n",
    "GAMMA_MINUS = 0.01     # Leak rate\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LR = 0.01\n",
    "\n",
    "print(f\"Timeline: {N_INPUT_STEPS} input steps + {N_SETTLE_STEPS} settle steps = {N_INPUT_STEPS + N_SETTLE_STEPS} total\")\n",
    "print(f\"Output taken at step {OUTPUT_STEP}\")\n",
    "print(f\"Architecture: {INPUT_DIM} (per neuron) → {HIDDEN_DIM} hidden → {OUTPUT_DIM} output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "def load_mnist():\n",
    "    \"\"\"Load MNIST as (N, 28, 28) - each row goes to a different neuron.\"\"\"\n",
    "    train_img = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    train_lbl = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_img = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    test_lbl = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    # Train/val split\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(train_img))\n",
    "    n_val = 6000\n",
    "    \n",
    "    val_img, val_lbl = train_img[idx[:n_val]], train_lbl[idx[:n_val]]\n",
    "    train_img, train_lbl = train_img[idx[n_val:]], train_lbl[idx[n_val:]]\n",
    "    \n",
    "    print(f\"Train: {train_img.shape}, Val: {val_img.shape}, Test: {test_img.shape}\")\n",
    "    return (train_img, train_lbl), (val_img, val_lbl), (test_img, test_lbl)\n",
    "\n",
    "(train_data, train_labels), (val_data, val_labels), (test_data, test_labels) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Parallel Input Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_parallel_input(image, label):\n",
    "    \"\"\"Show how each neuron receives a different row.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title(f'Original Image (Label: {label})', fontsize=12)\n",
    "    axes[0].set_xlabel('28 columns')\n",
    "    axes[0].set_ylabel('28 rows')\n",
    "    \n",
    "    # Row assignment\n",
    "    row_colors = np.arange(28).reshape(28, 1) * np.ones((1, 28))\n",
    "    axes[1].imshow(row_colors, cmap='tab20', aspect='auto')\n",
    "    for i in range(0, 28, 4):\n",
    "        axes[1].axhline(y=i-0.5, color='white', linewidth=0.5)\n",
    "        axes[1].text(29, i, f'Neuron {i}', va='center', fontsize=8)\n",
    "    axes[1].set_title('Row → Neuron Assignment', fontsize=12)\n",
    "    axes[1].set_xlabel('28 pixels (input to that neuron)')\n",
    "    axes[1].set_ylabel('Neuron index')\n",
    "    \n",
    "    # Timeline\n",
    "    ax = axes[2]\n",
    "    total_steps = N_INPUT_STEPS + N_SETTLE_STEPS\n",
    "    \n",
    "    # Input phase\n",
    "    ax.barh(0, N_INPUT_STEPS, left=0, height=0.5, color='blue', alpha=0.7, label='Input phase')\n",
    "    ax.text(N_INPUT_STEPS/2, 0, f'Same input ×{N_INPUT_STEPS}', ha='center', va='center', color='white', fontweight='bold')\n",
    "    \n",
    "    # Settle phase\n",
    "    ax.barh(0, N_SETTLE_STEPS, left=N_INPUT_STEPS, height=0.5, color='orange', alpha=0.7, label='Settle phase')\n",
    "    ax.text(N_INPUT_STEPS + N_SETTLE_STEPS/2, 0, f'No input ×{N_SETTLE_STEPS}', ha='center', va='center', color='white', fontweight='bold')\n",
    "    \n",
    "    # Output marker\n",
    "    ax.axvline(x=OUTPUT_STEP - 0.5, color='red', linewidth=2, linestyle='--', label=f'Output (step {OUTPUT_STEP})')\n",
    "    ax.scatter([OUTPUT_STEP - 0.5], [0], color='red', s=100, zorder=5, marker='v')\n",
    "    \n",
    "    ax.set_xlim(-0.5, total_steps + 0.5)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_title('Timeline', fontsize=12)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xticks(range(total_steps + 1))\n",
    "    ax.set_xticklabels([str(i+1) for i in range(total_steps + 1)])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nKey insight:\")\n",
    "    print(f\"  • Each of 28 neurons receives a different row (28 pixels)\")\n",
    "    print(f\"  • Same input presented {N_INPUT_STEPS} times for integration\")\n",
    "    print(f\"  • Network settles for {N_SETTLE_STEPS} steps without input\")\n",
    "    print(f\"  • Output read at step {OUTPUT_STEP} (first settle step)\")\n",
    "\n",
    "visualize_parallel_input(train_data[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parallel SOEN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelSOEN(nn.Module):\n",
    "    \"\"\"\n",
    "    SOEN model with parallel input: each neuron receives a different row.\n",
    "    \n",
    "    Architecture:\n",
    "        - 28 hidden neurons\n",
    "        - Each neuron i receives row i of the image (28 pixels)\n",
    "        - Recurrent connections between hidden neurons\n",
    "        - 28 → 10 output layer\n",
    "    \n",
    "    Input connection is DIAGONAL: W_i2h[i, :] only receives from row i.\n",
    "    This is the key difference from the standard all-to-all connection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=28, input_dim=28, output_dim=10,\n",
    "                 n_input_steps=5, n_settle_steps=5, output_step=6,\n",
    "                 dt=0.1, gamma_plus=0.1, gamma_minus=0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_input_steps = n_input_steps\n",
    "        self.n_settle_steps = n_settle_steps\n",
    "        self.output_step = output_step\n",
    "        self.dt = dt\n",
    "        self.gamma_plus = gamma_plus\n",
    "        self.gamma_minus = gamma_minus\n",
    "        \n",
    "        # Input weights: each neuron gets its own row\n",
    "        # W_i2h[neuron_i, pixel_j] = weight from pixel j of row i to neuron i\n",
    "        # This is 28 separate (28,) weight vectors, implemented as (28, 28)\n",
    "        self.W_i2h = nn.Parameter(torch.empty(hidden_dim, input_dim))\n",
    "        \n",
    "        # Recurrent weights: all-to-all between hidden neurons\n",
    "        self.W_h2h = nn.Parameter(torch.empty(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # Output weights: 28 → 10\n",
    "        self.W_h2o = nn.Parameter(torch.empty(output_dim, hidden_dim))\n",
    "        \n",
    "        # Biases\n",
    "        self.bias_h = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.bias_o = nn.Parameter(torch.zeros(output_dim))\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        nn.init.uniform_(self.W_i2h, -0.2, 0.2)\n",
    "        nn.init.normal_(self.W_h2h, 0, 0.1)\n",
    "        nn.init.normal_(self.W_h2o, 0, 0.2)\n",
    "        # No self-connections in recurrent\n",
    "        with torch.no_grad():\n",
    "            self.W_h2h.fill_diagonal_(0)\n",
    "    \n",
    "    def source_function(self, phi):\n",
    "        \"\"\"Smooth approximation of Heaviside source function.\"\"\"\n",
    "        return torch.sigmoid(5 * phi)\n",
    "    \n",
    "    def step(self, s, x=None):\n",
    "        \"\"\"\n",
    "        Single timestep update.\n",
    "        \n",
    "        Args:\n",
    "            s: Hidden state (batch, 28)\n",
    "            x: Input image (batch, 28, 28) or None for settle phase\n",
    "        \n",
    "        Returns:\n",
    "            s_new: Updated hidden state\n",
    "        \"\"\"\n",
    "        batch_size = s.shape[0]\n",
    "        \n",
    "        # Compute input contribution\n",
    "        # Each neuron i receives row i of the image\n",
    "        # input_to_neuron[b, i] = sum_j(W_i2h[i, j] * x[b, i, j])\n",
    "        if x is not None:\n",
    "            # Element-wise multiply then sum along pixel dimension\n",
    "            # x: (batch, 28, 28) - 28 rows, 28 pixels per row\n",
    "            # W_i2h: (28, 28) - 28 neurons, 28 input weights per neuron\n",
    "            # For neuron i, we want: sum_j(W_i2h[i,j] * x[b,i,j])\n",
    "            input_contrib = (x * self.W_i2h.unsqueeze(0)).sum(dim=2)  # (batch, 28)\n",
    "        else:\n",
    "            input_contrib = 0\n",
    "        \n",
    "        # Recurrent contribution\n",
    "        recurrent_contrib = F.linear(s, self.W_h2h)  # (batch, 28)\n",
    "        \n",
    "        # Total flux\n",
    "        phi = input_contrib + recurrent_contrib + self.bias_h\n",
    "        \n",
    "        # SingleDendrite dynamics: ds/dt = γ⁺g(φ) - γ⁻s\n",
    "        g = self.source_function(phi)\n",
    "        dsdt = self.gamma_plus * g - self.gamma_minus * s\n",
    "        s_new = s + self.dt * dsdt\n",
    "        \n",
    "        return s_new\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass with parallel input.\n",
    "        \n",
    "        Args:\n",
    "            x: Images (batch, 28, 28)\n",
    "        \n",
    "        Returns:\n",
    "            output: Class logits (batch, 10)\n",
    "            states: Dictionary with intermediate states\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        s = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "        \n",
    "        # Store states for analysis\n",
    "        all_states = [s.clone()]\n",
    "        all_outputs = []\n",
    "        \n",
    "        # INPUT PHASE: Present same input for n_input_steps\n",
    "        for t in range(self.n_input_steps):\n",
    "            s = self.step(s, x)\n",
    "            all_states.append(s.clone())\n",
    "            all_outputs.append(F.linear(s, self.W_h2o, self.bias_o))\n",
    "        \n",
    "        # SETTLE PHASE: Run without input for n_settle_steps\n",
    "        for t in range(self.n_settle_steps):\n",
    "            s = self.step(s, x=None)\n",
    "            all_states.append(s.clone())\n",
    "            all_outputs.append(F.linear(s, self.W_h2o, self.bias_o))\n",
    "        \n",
    "        # Get output at specified step (1-indexed)\n",
    "        output = all_outputs[self.output_step - 1]\n",
    "        \n",
    "        return output, {\n",
    "            'all_states': all_states,\n",
    "            'all_outputs': all_outputs,\n",
    "            'final_state': s\n",
    "        }\n",
    "\n",
    "# Create model\n",
    "model = ParallelSOEN(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    input_dim=INPUT_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    n_input_steps=N_INPUT_STEPS,\n",
    "    n_settle_steps=N_SETTLE_STEPS,\n",
    "    output_step=OUTPUT_STEP,\n",
    "    dt=DT,\n",
    "    gamma_plus=GAMMA_PLUS,\n",
    "    gamma_minus=GAMMA_MINUS\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model: {HIDDEN_DIM} hidden neurons, each receiving {INPUT_DIM} pixels\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"W_i2h: {model.W_i2h.shape} (each row is one neuron's input weights)\")\n",
    "print(f\"W_h2h: {model.W_h2h.shape} (recurrent)\")\n",
    "print(f\"W_h2o: {model.W_h2o.shape} (output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                epochs=30, batch_size=128, lr=0.01):\n",
    "    \"\"\"\n",
    "    Train the parallel SOEN model.\n",
    "    \"\"\"\n",
    "    # Create dataloaders\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(train_data, dtype=torch.float32),\n",
    "        torch.tensor(train_labels, dtype=torch.long)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.tensor(val_data, dtype=torch.float32),\n",
    "        torch.tensor(val_labels, dtype=torch.long)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_val_acc = 0\n",
    "    best_state = None\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PARALLEL SOEN TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Each neuron receives a different row of the image\")\n",
    "    print(f\"Input steps: {model.n_input_steps}, Settle steps: {model.n_settle_steps}\")\n",
    "    print(f\"Output at step: {model.output_step}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for x, labels in pbar:\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output, _ = model(x)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Enforce no self-connections\n",
    "            with torch.no_grad():\n",
    "                model.W_h2h.fill_diagonal_(0)\n",
    "            \n",
    "            # Metrics\n",
    "            pred = output.argmax(dim=1)\n",
    "            epoch_correct += (pred == labels).sum().item()\n",
    "            epoch_total += len(labels)\n",
    "            epoch_loss += loss.item() * len(labels)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{epoch_correct/epoch_total:.3f}'})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Epoch metrics\n",
    "        train_loss = epoch_loss / epoch_total\n",
    "        train_acc = epoch_correct / epoch_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, labels in val_loader:\n",
    "                x, labels = x.to(device), labels.to(device)\n",
    "                output, _ = model(x)\n",
    "                loss = F.cross_entropy(output, labels)\n",
    "                \n",
    "                val_loss += loss.item() * len(labels)\n",
    "                val_correct += (output.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += len(labels)\n",
    "        \n",
    "        val_loss /= val_total\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Track best\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, train_acc={train_acc:.3f}, \"\n",
    "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f} {'*' if val_acc == best_val_acc else ''}\")\n",
    "    \n",
    "    # Restore best\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    print(f\"\\nBest validation accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_model(model, train_data, train_labels, val_data, val_labels,\n",
    "                      epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss (Parallel SOEN)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy (Parallel SOEN)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_data, test_labels):\n",
    "    model.eval()\n",
    "    \n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(test_data, dtype=torch.float32),\n",
    "        torch.tensor(test_labels, dtype=torch.long)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for x, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x = x.to(device)\n",
    "        output, _ = model(x)\n",
    "        preds = output.argmax(dim=1).cpu()\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TEST ACCURACY (Parallel SOEN): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "test_acc = evaluate(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dynamics(model, image, label):\n",
    "    \"\"\"Visualize how states evolve during input and settle phases.\"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output, states = model(x)\n",
    "    \n",
    "    # Stack states: (n_steps+1, 28)\n",
    "    all_states = torch.stack(states['all_states']).squeeze().cpu().numpy()\n",
    "    all_outputs = torch.stack(states['all_outputs']).squeeze().cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(image, cmap='gray')\n",
    "    axes[0, 0].set_title(f'Input Image (Label: {label})')\n",
    "    axes[0, 0].set_xlabel('Pixel')\n",
    "    axes[0, 0].set_ylabel('Row (= Neuron)')\n",
    "    \n",
    "    # Hidden state evolution\n",
    "    im = axes[0, 1].imshow(all_states.T, aspect='auto', cmap='viridis')\n",
    "    axes[0, 1].axvline(x=model.n_input_steps + 0.5, color='red', linestyle='--', label='Input ends')\n",
    "    axes[0, 1].axvline(x=model.output_step, color='green', linestyle='--', label=f'Output step {model.output_step}')\n",
    "    axes[0, 1].set_xlabel('Timestep')\n",
    "    axes[0, 1].set_ylabel('Neuron')\n",
    "    axes[0, 1].set_title('Hidden State Evolution')\n",
    "    axes[0, 1].legend()\n",
    "    plt.colorbar(im, ax=axes[0, 1])\n",
    "    \n",
    "    # Output evolution\n",
    "    for i in range(10):\n",
    "        axes[1, 0].plot(all_outputs[:, i], label=f'{i}', alpha=0.7)\n",
    "    axes[1, 0].axvline(x=model.n_input_steps - 0.5, color='red', linestyle='--')\n",
    "    axes[1, 0].axvline(x=model.output_step - 1, color='green', linestyle='--')\n",
    "    axes[1, 0].set_xlabel('Timestep')\n",
    "    axes[1, 0].set_ylabel('Logit')\n",
    "    axes[1, 0].set_title('Output Logits Over Time')\n",
    "    axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Final prediction\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    probs = F.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "    colors = ['green' if i == label else 'blue' for i in range(10)]\n",
    "    colors[pred] = 'red' if pred != label else 'green'\n",
    "    axes[1, 1].bar(range(10), probs, color=colors)\n",
    "    axes[1, 1].set_xlabel('Class')\n",
    "    axes[1, 1].set_ylabel('Probability')\n",
    "    axes[1, 1].set_title(f'Prediction: {pred} (True: {label}) {\"✓\" if pred == label else \"✗\"}')\n",
    "    axes[1, 1].set_xticks(range(10))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a few samples\n",
    "for i in [0, 1, 2]:\n",
    "    visualize_dynamics(model, test_data[i], test_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_output_steps(model, test_data, test_labels, max_samples=1000):\n",
    "    \"\"\"\n",
    "    Compare accuracy at different output steps.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Sample subset for speed\n",
    "    x = torch.tensor(test_data[:max_samples], dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(test_labels[:max_samples], dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, states = model(x)\n",
    "    \n",
    "    all_outputs = states['all_outputs']  # List of (batch, 10)\n",
    "    \n",
    "    results = []\n",
    "    for step, output in enumerate(all_outputs, 1):\n",
    "        pred = output.argmax(dim=1).cpu()\n",
    "        acc = (pred == labels).float().mean().item()\n",
    "        phase = 'input' if step <= model.n_input_steps else 'settle'\n",
    "        results.append((step, acc, phase))\n",
    "        print(f\"Step {step:2d} ({phase:6s}): {acc:.4f}\")\n",
    "    \n",
    "    # Plot\n",
    "    steps = [r[0] for r in results]\n",
    "    accs = [r[1] for r in results]\n",
    "    colors = ['blue' if r[2] == 'input' else 'orange' for r in results]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(steps, accs, color=colors)\n",
    "    plt.axvline(x=model.n_input_steps + 0.5, color='red', linestyle='--', label='Input phase ends')\n",
    "    plt.xlabel('Output Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs Output Step')\n",
    "    plt.legend()\n",
    "    plt.xticks(steps)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    best_step = steps[np.argmax(accs)]\n",
    "    print(f\"\\nBest output step: {best_step} (accuracy: {max(accs):.4f})\")\n",
    "\n",
    "explore_output_steps(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | Sequential (28 steps) | Parallel (5+5 steps) |\n",
    "|--------|----------------------|----------------------|\n",
    "| Input format | 28 timesteps, 1 row each | 1 image, 28 parallel neurons |\n",
    "| Total timesteps | 28 | 10 (5 input + 5 settle) |\n",
    "| Each neuron sees | All rows over time | Only its assigned row |\n",
    "| Gradient path | Through 28 steps | Through 10 steps |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Parallel input reduces temporal depth**: 10 steps vs 28 steps\n",
    "2. **Each neuron specializes**: Neuron i becomes expert at row i\n",
    "3. **Recurrence integrates across rows**: Hidden→Hidden connections combine information\n",
    "4. **Settle phase matters**: Network needs time to integrate after input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
