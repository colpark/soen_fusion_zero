{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST Classification with SOEN\n",
    "\n",
    "This notebook demonstrates training a SOEN (Superconducting Optoelectronic Network) model on the MNIST digit classification task.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Sequential Processing**: MNIST images (28×28) are treated as 28-timestep sequences, where each timestep is a row of 28 pixels\n",
    "2. **Temporal Dynamics**: The SingleDendrite layer integrates information over time, leveraging SOEN's natural temporal processing\n",
    "3. **Learnable Readout**: The output connection is learnable (lesson from Tutorial 02)\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Input (28D) → SingleDendrite (128D) → Output (10D)\n",
    "     ↓              ↓ ↺                   ↓\n",
    "  Row pixels    Recurrent SOEN      10 digit classes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup: Ensure soen_toolkit is importable\nimport sys\nfrom pathlib import Path\n\n# Add src directory to path if running from notebook location\nnotebook_dir = Path.cwd()\nfor parent in [notebook_dir] + list(notebook_dir.parents):\n    candidate = parent / \"src\"\n    if (candidate / \"soen_toolkit\").exists():\n        sys.path.insert(0, str(candidate))\n        break\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport h5py\nimport torch\nimport torch.nn as nn\nimport glob\nimport gzip\nimport urllib.request\nimport struct\n\n# Use standard tqdm (not notebook version to avoid widget errors)\ntry:\n    from tqdm import tqdm\nexcept ImportError:\n    # Simple fallback if tqdm not available\n    def tqdm(iterable, **kwargs):\n        return iterable\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare MNIST Dataset\n",
    "\n",
    "We'll download MNIST and convert it to HDF5 format compatible with the SOEN training pipeline.\n",
    "\n",
    "**Data format**: Images are reshaped from (28, 28) to (28, 28) sequences where:\n",
    "- Time dimension = 28 (rows)\n",
    "- Feature dimension = 28 (columns/pixels per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n    \"\"\"Download a single MNIST file if not already present.\"\"\"\n    data_dir = Path(\"./data/mnist\")\n    data_dir.mkdir(parents=True, exist_ok=True)\n    \n    filepath = data_dir / filename\n    if not filepath.exists():\n        url = base_url + filename\n        print(f\"Downloading {filename}...\")\n        urllib.request.urlretrieve(url, filepath)\n    return filepath\n\ndef read_mnist_images(filepath):\n    \"\"\"Read MNIST image file (idx3-ubyte format).\"\"\"\n    with gzip.open(filepath, 'rb') as f:\n        # Read magic number and dimensions\n        magic, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n        # Read image data\n        images = np.frombuffer(f.read(), dtype=np.uint8)\n        images = images.reshape(num_images, rows, cols)\n    return images\n\ndef read_mnist_labels(filepath):\n    \"\"\"Read MNIST label file (idx1-ubyte format).\"\"\"\n    with gzip.open(filepath, 'rb') as f:\n        # Read magic number and count\n        magic, num_labels = struct.unpack('>II', f.read(8))\n        # Read labels\n        labels = np.frombuffer(f.read(), dtype=np.uint8)\n    return labels\n\ndef prepare_mnist_hdf5(output_path=\"training/datasets/mnist_seq28.hdf5\", \n                       normalize=True,\n                       val_split=0.1):\n    \"\"\"Download MNIST and save as HDF5 for SOEN training.\n    \n    Args:\n        output_path: Where to save the HDF5 file\n        normalize: Whether to normalize pixel values to [0, 1]\n        val_split: Fraction of training data to use for validation\n    \"\"\"\n    output_path = Path(output_path)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    \n    # Check if already exists\n    if output_path.exists():\n        print(f\"Dataset already exists at {output_path}\")\n        with h5py.File(output_path, 'r') as f:\n            print(f\"  Train samples: {len(f['train']['labels'])}\")\n            print(f\"  Val samples: {len(f['val']['labels'])}\")\n            print(f\"  Test samples: {len(f['test']['labels'])}\")\n        return output_path\n    \n    print(\"Downloading MNIST (without torchvision)...\")\n    \n    # Download MNIST files\n    train_images_file = download_mnist_file(\"train-images-idx3-ubyte.gz\")\n    train_labels_file = download_mnist_file(\"train-labels-idx1-ubyte.gz\")\n    test_images_file = download_mnist_file(\"t10k-images-idx3-ubyte.gz\")\n    test_labels_file = download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")\n    \n    # Read the data\n    train_images = read_mnist_images(train_images_file).astype(np.float32)\n    train_labels = read_mnist_labels(train_labels_file).astype(np.int64)\n    test_images = read_mnist_images(test_images_file).astype(np.float32)\n    test_labels = read_mnist_labels(test_labels_file).astype(np.int64)\n    \n    # Normalize to [0, 1]\n    if normalize:\n        train_images = train_images / 255.0\n        test_images = test_images / 255.0\n    \n    # Split training into train/val\n    n_train = len(train_images)\n    n_val = int(n_train * val_split)\n    \n    # Shuffle before splitting\n    np.random.seed(42)\n    indices = np.random.permutation(n_train)\n    val_indices = indices[:n_val]\n    train_indices = indices[n_val:]\n    \n    val_images = train_images[val_indices]\n    val_labels = train_labels[val_indices]\n    train_images = train_images[train_indices]\n    train_labels = train_labels[train_indices]\n    \n    # Images are already (N, 28, 28) which is (N, T, D) for our sequence format\n    print(f\"Train shape: {train_images.shape} (N, T=28 timesteps, D=28 features)\")\n    print(f\"Val shape: {val_images.shape}\")\n    print(f\"Test shape: {test_images.shape}\")\n    \n    # Save to HDF5\n    print(f\"\\nSaving to {output_path}...\")\n    with h5py.File(output_path, 'w') as f:\n        # Training set\n        train_grp = f.create_group('train')\n        train_grp.create_dataset('data', data=train_images, compression='gzip')\n        train_grp.create_dataset('labels', data=train_labels)\n        \n        # Validation set\n        val_grp = f.create_group('val')\n        val_grp.create_dataset('data', data=val_images, compression='gzip')\n        val_grp.create_dataset('labels', data=val_labels)\n        \n        # Test set\n        test_grp = f.create_group('test')\n        test_grp.create_dataset('data', data=test_images, compression='gzip')\n        test_grp.create_dataset('labels', data=test_labels)\n        \n        # Metadata\n        f.attrs['description'] = 'MNIST as sequences (28 timesteps x 28 features)'\n        f.attrs['num_classes'] = 10\n        f.attrs['seq_len'] = 28\n        f.attrs['feature_dim'] = 28\n    \n    print(\"Done!\")\n    print(f\"  Train: {len(train_labels)} samples\")\n    print(f\"  Val: {len(val_labels)} samples\")\n    print(f\"  Test: {len(test_labels)} samples\")\n    \n    return output_path\n\n# Prepare the dataset\ndata_path = prepare_mnist_hdf5()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the Dataset\n",
    "\n",
    "Let's see how MNIST looks when treated as sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mnist_samples(data_path, n_samples=10):\n",
    "    \"\"\"Visualize MNIST samples and their sequential representation.\"\"\"\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        images = np.array(f['train']['data'][:n_samples])\n",
    "        labels = np.array(f['train']['labels'][:n_samples])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(2*n_samples, 5))\n",
    "    fig.suptitle('MNIST Samples: Image View vs Sequential View', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Top row: Original image view\n",
    "        axes[0, i].imshow(images[i], cmap='gray')\n",
    "        axes[0, i].set_title(f'Label: {labels[i]}', fontsize=10)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Bottom row: Sequential view (heatmap of 28 timesteps x 28 features)\n",
    "        im = axes[1, i].imshow(images[i], cmap='viridis', aspect='auto')\n",
    "        axes[1, i].set_xlabel('Feature (pixel)', fontsize=8)\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('Time (row)', fontsize=8)\n",
    "    \n",
    "    axes[0, 0].set_ylabel('Image View', fontsize=10)\n",
    "    axes[1, 0].set_ylabel('Sequence View\\n(T=28, D=28)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show class distribution\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        all_labels = np.array(f['train']['labels'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    counts = np.bincount(all_labels)\n",
    "    ax.bar(range(10), counts, color='steelblue', edgecolor='black')\n",
    "    ax.set_xlabel('Digit Class', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title('Training Set Class Distribution', fontsize=14)\n",
    "    ax.set_xticks(range(10))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_mnist_samples(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine the Model Architecture\n",
    "\n",
    "Let's look at the SOEN model we'll be training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soen_toolkit.core.model_yaml import build_model_from_yaml\n",
    "\n",
    "# Load and inspect the model\n",
    "model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec.yaml\")\n",
    "model = build_model_from_yaml(model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MNIST SOEN MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(\"\\nLayer dimensions:\")\n",
    "for layer_id, dim in model.layer_nodes.items():\n",
    "    print(f\"  Layer {layer_id}: {dim} neurons\")\n",
    "\n",
    "print(\"\\nConnections:\")\n",
    "for name, param in model.connections.items():\n",
    "    print(f\"  {name}: {param.shape} (learnable: {param.requires_grad})\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "x_test = torch.randn(2, 28, 28)  # [batch=2, seq_len=28, features=28]\n",
    "with torch.no_grad():\n",
    "    output, states = model(x_test)\n",
    "print(f\"  Input shape: {x_test.shape}\")\n",
    "print(f\"  Output shape: {output.shape}\")\n",
    "print(\"  Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "Now let's train the SOEN model on MNIST using the training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soen_toolkit.training.trainers.experiment import run_from_config\n",
    "\n",
    "# Run training\n",
    "print(\"Starting MNIST SOEN training...\")\n",
    "print(\"This may take a while depending on your hardware.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "run_from_config(\"training/training_configs/mnist_soen.yaml\", script_dir=Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Trained Model\n",
    "\n",
    "Let's load the best checkpoint and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint():\n",
    "    \"\"\"Find and load the best checkpoint from training.\"\"\"\n",
    "    \n",
    "    # Find checkpoints\n",
    "    ckpt_patterns = [\n",
    "        \"training/temp/**/checkpoints/**/*.ckpt\",\n",
    "        \"training/temp/**/*.ckpt\",\n",
    "    ]\n",
    "    \n",
    "    all_ckpts = []\n",
    "    for pattern in ckpt_patterns:\n",
    "        all_ckpts.extend(glob.glob(pattern, recursive=True))\n",
    "    \n",
    "    if not all_ckpts:\n",
    "        print(\"No checkpoint found. Run training first.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get the most recent checkpoint\n",
    "    latest_ckpt = max(all_ckpts, key=lambda x: Path(x).stat().st_mtime)\n",
    "    print(f\"Loading checkpoint: {latest_ckpt}\")\n",
    "    \n",
    "    # Load model\n",
    "    model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec.yaml\")\n",
    "    model = build_model_from_yaml(model_path)\n",
    "    \n",
    "    # Load weights\n",
    "    ckpt = torch.load(latest_ckpt, map_location='cpu')\n",
    "    state_dict = ckpt.get('state_dict', ckpt)\n",
    "    \n",
    "    # Remove 'model.' prefix if present\n",
    "    clean_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('model.'):\n",
    "            clean_state_dict[k[6:]] = v\n",
    "        else:\n",
    "            clean_state_dict[k] = v\n",
    "    \n",
    "    model.load_state_dict(clean_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, latest_ckpt\n",
    "\n",
    "trained_model, ckpt_path = load_best_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, data_path, batch_size=128):\n",
    "    \"\"\"Evaluate model on the test set.\"\"\"\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"No model loaded.\")\n",
    "        return\n",
    "    \n",
    "    # Load test data\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    print(f\"Evaluating on {len(test_labels)} test samples...\")\n",
    "    \n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(test_data), batch_size)):\n",
    "            batch_data = test_data[i:i+batch_size]\n",
    "            x = torch.tensor(batch_data, dtype=torch.float32).to(device)\n",
    "            \n",
    "            output, _ = model(x)\n",
    "            \n",
    "            # Apply max pooling over time\n",
    "            if output.dim() == 3:\n",
    "                pooled = output.max(dim=1)[0]\n",
    "            else:\n",
    "                pooled = output\n",
    "            \n",
    "            probs = torch.softmax(pooled, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (all_preds == test_labels).mean()\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"TEST SET RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Correct: {(all_preds == test_labels).sum()}/{len(test_labels)}\")\n",
    "    \n",
    "    return all_preds, all_probs, accuracy\n",
    "\n",
    "if trained_model is not None:\n",
    "    predictions, probabilities, test_accuracy = evaluate_on_test_set(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_path, n_samples=20):\n",
    "    \"\"\"Visualize model predictions on random test samples.\"\"\"\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"No model loaded.\")\n",
    "        return\n",
    "    \n",
    "    # Load test data\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    # Random sample\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(test_data), n_samples, replace=False)\n",
    "    \n",
    "    samples = test_data[indices]\n",
    "    labels = test_labels[indices]\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(samples, dtype=torch.float32)\n",
    "        output, _ = model(x)\n",
    "        \n",
    "        if output.dim() == 3:\n",
    "            pooled = output.max(dim=1)[0]\n",
    "        else:\n",
    "            pooled = output\n",
    "        \n",
    "        probs = torch.softmax(pooled, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1).numpy()\n",
    "        confidence = probs.max(dim=1)[0].numpy()\n",
    "    \n",
    "    # Plot\n",
    "    n_cols = 5\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(2.5*n_cols, 3*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    fig.suptitle('MNIST Predictions (SOEN Model)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(samples[i], cmap='gray')\n",
    "        \n",
    "        is_correct = preds[i] == labels[i]\n",
    "        color = 'green' if is_correct else 'red'\n",
    "        symbol = '✓' if is_correct else '✗'\n",
    "        \n",
    "        ax.set_title(\n",
    "            f\"{symbol} Pred: {preds[i]} ({confidence[i]:.0%})\\nTrue: {labels[i]}\",\n",
    "            fontsize=9,\n",
    "            color=color,\n",
    "            fontweight='bold' if not is_correct else 'normal'\n",
    "        )\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    accuracy = (preds == labels).mean()\n",
    "    print(f\"\\nSample accuracy: {accuracy:.1%} ({(preds == labels).sum()}/{n_samples})\")\n",
    "\n",
    "if trained_model is not None:\n",
    "    visualize_predictions(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(predictions, true_labels):\n",
    "    \"\"\"Plot confusion matrix for predictions.\"\"\"\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    ax.set_xlabel('Predicted', fontsize=12)\n",
    "    ax.set_ylabel('True', fontsize=12)\n",
    "    ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for digit in range(10):\n",
    "        mask = true_labels == digit\n",
    "        class_acc = (predictions[mask] == digit).mean()\n",
    "        print(f\"  Digit {digit}: {class_acc:.1%}\")\n",
    "\n",
    "if trained_model is not None:\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    plot_confusion_matrix(predictions, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze SOEN Dynamics\n",
    "\n",
    "Let's visualize how the SingleDendrite layer processes the input over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_soen_dynamics(model, data_path, sample_idx=0):\n",
    "    \"\"\"Visualize the temporal dynamics of the SOEN hidden layer.\"\"\"\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"No model loaded.\")\n",
    "        return\n",
    "    \n",
    "    # Load a sample\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        sample = np.array(f['test']['data'][sample_idx:sample_idx+1])\n",
    "        label = np.array(f['test']['labels'][sample_idx])\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(sample, dtype=torch.float32)\n",
    "        output, all_states = model(x)\n",
    "        \n",
    "        # Get hidden layer states (Layer 1)\n",
    "        hidden_states = all_states[1]  # [batch, seq_len+1, hidden_dim]\n",
    "        hidden_states = hidden_states[0, 1:, :].numpy()  # Remove batch and initial state\n",
    "        \n",
    "        # Get output\n",
    "        if output.dim() == 3:\n",
    "            output_over_time = output[0].numpy()\n",
    "        else:\n",
    "            output_over_time = output[0].numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'SOEN Dynamics for Digit {label}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 1. Input image\n",
    "    axes[0, 0].imshow(sample[0], cmap='gray')\n",
    "    axes[0, 0].set_title('Input Image', fontsize=12)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # 2. Hidden layer activity over time\n",
    "    im = axes[0, 1].imshow(hidden_states.T, aspect='auto', cmap='viridis')\n",
    "    axes[0, 1].set_xlabel('Time (row)', fontsize=10)\n",
    "    axes[0, 1].set_ylabel('Hidden Neuron', fontsize=10)\n",
    "    axes[0, 1].set_title('Hidden Layer Activity (128 neurons)', fontsize=12)\n",
    "    plt.colorbar(im, ax=axes[0, 1], label='Activation')\n",
    "    \n",
    "    # 3. Mean hidden activity over time\n",
    "    mean_activity = hidden_states.mean(axis=1)\n",
    "    std_activity = hidden_states.std(axis=1)\n",
    "    time_steps = np.arange(len(mean_activity))\n",
    "    axes[1, 0].plot(time_steps, mean_activity, 'b-', linewidth=2, label='Mean')\n",
    "    axes[1, 0].fill_between(time_steps, \n",
    "                            mean_activity - std_activity,\n",
    "                            mean_activity + std_activity,\n",
    "                            alpha=0.3, label='±1 std')\n",
    "    axes[1, 0].set_xlabel('Time (row)', fontsize=10)\n",
    "    axes[1, 0].set_ylabel('Activation', fontsize=10)\n",
    "    axes[1, 0].set_title('Mean Hidden Layer Activity', fontsize=12)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Output class probabilities at final timestep\n",
    "    if output_over_time.ndim == 2:\n",
    "        final_output = output_over_time[-1]\n",
    "    else:\n",
    "        final_output = output_over_time\n",
    "    probs = np.exp(final_output) / np.exp(final_output).sum()  # Softmax\n",
    "    \n",
    "    bars = axes[1, 1].bar(range(10), probs, color='steelblue', edgecolor='black')\n",
    "    bars[label].set_color('green')  # Highlight true class\n",
    "    axes[1, 1].set_xlabel('Digit Class', fontsize=10)\n",
    "    axes[1, 1].set_ylabel('Probability', fontsize=10)\n",
    "    axes[1, 1].set_title(f'Output Probabilities (True: {label})', fontsize=12)\n",
    "    axes[1, 1].set_xticks(range(10))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if trained_model is not None:\n",
    "    # Visualize dynamics for a few samples\n",
    "    for idx in [0, 5, 10]:\n",
    "        visualize_soen_dynamics(trained_model, data_path, sample_idx=idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we:\n",
    "\n",
    "1. **Prepared MNIST** as a sequential dataset (28 timesteps × 28 features)\n",
    "2. **Built a SOEN model** with:\n",
    "   - Input layer (28D)\n",
    "   - SingleDendrite hidden layer (128D) with recurrent connections\n",
    "   - Linear output layer (10D) with **learnable** connections\n",
    "3. **Trained the model** using the SOEN training pipeline\n",
    "4. **Evaluated and visualized** the results\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- SOEN networks naturally process sequential data through temporal integration\n",
    "- The SingleDendrite layer accumulates evidence over time (each row of the image)\n",
    "- **Learnable output connections** are critical for effective training (from Tutorial 02)\n",
    "- The recurrent connections allow the network to maintain context across timesteps\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different hidden layer sizes (64, 256, 512)\n",
    "- Experiment with multiple hidden layers\n",
    "- Adjust the temporal parameters (gamma_plus, gamma_minus, dt)\n",
    "- Compare with traditional RNN/LSTM baselines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}