{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03 — MNIST with Gated SOEN (MultiplierNOCC)\n",
    "\n",
    "**Gated architecture** using MultiplierNOCC for selective memory.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Input (7) → Hidden (28, MultiplierNOCC) → Output (10)\n",
    "                    ↺ recurrent\n",
    "```\n",
    "\n",
    "## Why MultiplierNOCC Gating?\n",
    "\n",
    "MultiplierNOCC (No Collection Coils) has:\n",
    "- **Dual SQUID states** (s1, s2): Can selectively amplify or suppress signals\n",
    "- **Aggregated output** (m): Gated combination of states\n",
    "- **Learnable phi_y**: Secondary input that acts as a gate control\n",
    "\n",
    "This allows the network to:\n",
    "1. **Hold important patterns** across 112 timesteps\n",
    "2. **Suppress noise** or irrelevant inputs\n",
    "3. **Selectively integrate** temporal information\n",
    "\n",
    "## Hardware Compatibility\n",
    "\n",
    "| Layer | Neurons | Inputs/Neuron |\n",
    "|-------|---------|---------------|\n",
    "| Input | 7 | - |\n",
    "| Hidden (MultiplierNOCC) | 28 | 7 ✓ |\n",
    "| Output | 10 | 28 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TQDM_DISABLE\"] = \"0\"\n",
    "os.environ[\"TQDM_MININTERVAL\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "for parent in [notebook_dir] + list(notebook_dir.parents):\n",
    "    candidate = parent / \"src\"\n",
    "    if (candidate / \"soen_toolkit\").exists():\n",
    "        sys.path.insert(0, str(candidate))\n",
    "        break\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import glob\n",
    "import gzip\n",
    "import urllib.request\n",
    "import struct\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset (112×7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_file(filename, base_url=\"https://ossci-datasets.s3.amazonaws.com/mnist/\"):\n",
    "    data_dir = Path(\"./data/mnist\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filepath = data_dir / filename\n",
    "    if not filepath.exists():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    return filepath\n",
    "\n",
    "def read_mnist_images(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "\n",
    "def read_mnist_labels(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        magic, num = struct.unpack('>II', f.read(8))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "def prepare_mnist_112x7(output_path=\"training/datasets/mnist_seq112x7.hdf5\"):\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if output_path.exists():\n",
    "        print(f\"Dataset exists: {output_path}\")\n",
    "        with h5py.File(output_path, 'r') as f:\n",
    "            print(f\"  Shape: {f['train']['data'].shape}\")\n",
    "        return output_path\n",
    "    \n",
    "    print(\"Preparing MNIST (112×7 format)...\")\n",
    "    \n",
    "    train_img = read_mnist_images(download_mnist_file(\"train-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    train_lbl = read_mnist_labels(download_mnist_file(\"train-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    test_img = read_mnist_images(download_mnist_file(\"t10k-images-idx3-ubyte.gz\")).astype(np.float32) / 255.0\n",
    "    test_lbl = read_mnist_labels(download_mnist_file(\"t10k-labels-idx1-ubyte.gz\")).astype(np.int64)\n",
    "    \n",
    "    train_img = train_img.reshape(-1, 784).reshape(-1, 112, 7)\n",
    "    test_img = test_img.reshape(-1, 784).reshape(-1, 112, 7)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    idx = np.random.permutation(len(train_img))\n",
    "    n_val = int(len(train_img) * 0.1)\n",
    "    \n",
    "    val_img, val_lbl = train_img[idx[:n_val]], train_lbl[idx[:n_val]]\n",
    "    train_img, train_lbl = train_img[idx[n_val:]], train_lbl[idx[n_val:]]\n",
    "    \n",
    "    with h5py.File(output_path, 'w') as f:\n",
    "        for name, data, labels in [('train', train_img, train_lbl), \n",
    "                                    ('val', val_img, val_lbl), \n",
    "                                    ('test', test_img, test_lbl)]:\n",
    "            g = f.create_group(name)\n",
    "            g.create_dataset('data', data=data)\n",
    "            g.create_dataset('labels', data=labels)\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return output_path\n",
    "\n",
    "data_path = prepare_mnist_112x7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explain MultiplierNOCC Gating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_gating():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: SingleDendrite vs MultiplierNOCC comparison\n",
    "    ax = axes[0]\n",
    "    ax.text(0.5, 0.95, 'SingleDendrite vs MultiplierNOCC', ha='center', \n",
    "            fontsize=14, fontweight='bold', transform=ax.transAxes)\n",
    "    \n",
    "    comparison = \"\"\"\n",
    "    SingleDendrite (simple):\n",
    "    ─────────────────────────\n",
    "    • One state variable (s)\n",
    "    • Leaky integration: ds/dt = γ⁺g(φ) - γ⁻s\n",
    "    • Good for basic temporal processing\n",
    "    \n",
    "    MultiplierNOCC (gating):\n",
    "    ─────────────────────────\n",
    "    • Dual SQUID states (s1, s2)\n",
    "    • Secondary input φ_y (learnable gate)\n",
    "    • Aggregated output m = f(s1, s2, φ_y)\n",
    "    • Can selectively amplify/suppress\n",
    "    • Better for long-range dependencies\n",
    "    \"\"\"\n",
    "    ax.text(0.1, 0.8, comparison, fontsize=10, family='monospace',\n",
    "            transform=ax.transAxes, va='top')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Right: Gating diagram\n",
    "    ax = axes[1]\n",
    "    \n",
    "    # Draw gating circuit\n",
    "    ax.add_patch(plt.Rectangle((0.1, 0.3), 0.3, 0.4, fill=False, ec='blue', lw=2))\n",
    "    ax.text(0.25, 0.5, 's1, s2\\n(dual states)', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    ax.add_patch(plt.Circle((0.6, 0.5), 0.1, fill=False, ec='green', lw=2))\n",
    "    ax.text(0.6, 0.5, 'm', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Arrows\n",
    "    ax.annotate('', xy=(0.5, 0.5), xytext=(0.4, 0.5),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "    ax.annotate('', xy=(0.25, 0.3), xytext=(0.25, 0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "    ax.text(0.25, 0.05, 'φ (input)', ha='center', fontsize=10, color='red')\n",
    "    \n",
    "    ax.annotate('', xy=(0.6, 0.3), xytext=(0.6, 0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='purple', lw=1.5))\n",
    "    ax.text(0.6, 0.05, 'φ_y (gate)', ha='center', fontsize=10, color='purple')\n",
    "    \n",
    "    ax.annotate('', xy=(0.85, 0.5), xytext=(0.7, 0.5),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=2))\n",
    "    ax.text(0.9, 0.5, 'output', ha='left', va='center', fontsize=10, color='green')\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('MultiplierNOCC Gating Mechanism', fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nGating Benefits for 112-timestep sequences:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"• Selective memory: hold important features, forget noise\")\n",
    "    print(\"• Learnable φ_y: network learns what to gate\")\n",
    "    print(\"• Dual states: richer dynamics than single-state neurons\")\n",
    "    print(\"• Better gradient flow: multiplicative gating helps backprop\")\n",
    "\n",
    "explain_gating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soen_toolkit.core.model_yaml import build_model_from_yaml\n",
    "\n",
    "model_path = Path(\"training/test_models/model_specs/MNIST_SOENSpec_112x7_gated.yaml\")\n",
    "model = build_model_from_yaml(model_path)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GATED SOEN MODEL (MultiplierNOCC)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nLayers:\")\n",
    "for lid, dim in model.layer_nodes.items():\n",
    "    layer_type = model.layers_config[lid].layer_type if lid < len(model.layers_config) else \"Unknown\"\n",
    "    print(f\"  Layer {lid}: {dim} neurons ({layer_type})\")\n",
    "\n",
    "print(\"\\nConnections:\")\n",
    "for name, param in model.connections.items():\n",
    "    print(f\"  {name}: {list(param.shape)}\")\n",
    "\n",
    "print(\"\\nLearnable gate parameter (phi_y):\")\n",
    "for name, param in model.named_parameters():\n",
    "    if 'phi_y' in name:\n",
    "        print(f\"  {name}: shape={list(param.shape)}, requires_grad={param.requires_grad}\")\n",
    "\n",
    "print(\"\\nForward pass test...\")\n",
    "x = torch.randn(2, 112, 7)\n",
    "with torch.no_grad():\n",
    "    y, states = model(x)\n",
    "print(f\"  Input: {x.shape}\")\n",
    "print(f\"  Output: {y.shape}\")\n",
    "print(\"  Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SOEN_NO_PROGRESS_BAR\"] = \"1\"\n",
    "\n",
    "from soen_toolkit.training.trainers.experiment import run_from_config\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING GATED MODEL (MultiplierNOCC)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Hidden layer uses MultiplierNOCC for selective memory gating\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "run_from_config(\"training/training_configs/mnist_soen_112x7_gated.yaml\", script_dir=Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    patterns = [\"training/temp/**/checkpoints/**/*.ckpt\", \"training/temp/**/*.ckpt\"]\n",
    "    ckpts = []\n",
    "    for p in patterns:\n",
    "        ckpts.extend(glob.glob(p, recursive=True))\n",
    "    \n",
    "    gated_ckpts = [c for c in ckpts if 'gated' in c.lower() or 'nocc' in c.lower()]\n",
    "    if not gated_ckpts:\n",
    "        gated_ckpts = ckpts\n",
    "    \n",
    "    if not gated_ckpts:\n",
    "        print(\"No checkpoint found.\")\n",
    "        return None\n",
    "    \n",
    "    latest = max(gated_ckpts, key=lambda x: Path(x).stat().st_mtime)\n",
    "    print(f\"Loading: {latest}\")\n",
    "    \n",
    "    model = build_model_from_yaml(model_path)\n",
    "    ckpt = torch.load(latest, map_location='cpu')\n",
    "    state = ckpt.get('state_dict', ckpt)\n",
    "    clean = {k[6:] if k.startswith('model.') else k: v for k, v in state.items()}\n",
    "    model.load_state_dict(clean, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "trained_model = load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_path):\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        test_data = np.array(f['test']['data'])\n",
    "        test_labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(test_data), 128)):\n",
    "            x = torch.tensor(test_data[i:i+128], dtype=torch.float32)\n",
    "            y, _ = model(x)\n",
    "            if y.dim() == 3:\n",
    "                y = y.mean(dim=1)\n",
    "            all_preds.append(y.argmax(dim=1).numpy())\n",
    "    \n",
    "    preds = np.concatenate(all_preds)\n",
    "    acc = (preds == test_labels).mean()\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    return acc\n",
    "\n",
    "if trained_model:\n",
    "    evaluate(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, data_path, n=20):\n",
    "    if model is None:\n",
    "        return\n",
    "    \n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        data = np.array(f['test']['data'])\n",
    "        labels = np.array(f['test']['labels'])\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(len(data), n, replace=False)\n",
    "    samples, true = data[idx], labels[idx]\n",
    "    images = samples.reshape(n, 784).reshape(n, 28, 28)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.tensor(samples, dtype=torch.float32)\n",
    "        y, _ = model(x)\n",
    "        if y.dim() == 3:\n",
    "            y = y.mean(dim=1)\n",
    "        probs = torch.softmax(y, dim=1)\n",
    "        preds = probs.argmax(dim=1).numpy()\n",
    "        conf = probs.max(dim=1)[0].numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle('Predictions (Gated SOEN - MultiplierNOCC)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for i in range(n):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        ok = preds[i] == true[i]\n",
    "        axes[i].set_title(f\"{'✓' if ok else '✗'} {preds[i]} ({conf[i]:.0%})\\nTrue: {true[i]}\",\n",
    "                          color='green' if ok else 'red', fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Sample accuracy: {(preds == true).mean():.1%}\")\n",
    "\n",
    "if trained_model:\n",
    "    visualize_predictions(trained_model, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Aspect | SingleDendrite | MultiplierNOCC |\n",
    "|--------|----------------|----------------|\n",
    "| State variables | 1 (s) | 3 (s1, s2, m) |\n",
    "| Gating | None | Via φ_y |\n",
    "| Memory | Leaky integration | Selective memory |\n",
    "| Parameters | γ⁺, γ⁻ | α, β, β_out, φ_y |\n",
    "\n",
    "**Gating can help with long sequences (112 timesteps) by:**\n",
    "1. Selectively retaining important patterns\n",
    "2. Suppressing noise and irrelevant inputs\n",
    "3. Learning what to remember via φ_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
